{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<h1 dir=rtl align=center style=\"line-height:200%;font-family:vazir;color:#0099cc\">\n",
    "<font face=\"vazir\" color=\"#0099cc\">\n",
    "LibreChat\n",
    "</font>\n",
    "</h1>\n",
    "\n",
    "<p dir=rtl style=\"direction: rtl; text-align: justify; line-height:200%; font-family:vazir; font-size:medium\">\n",
    "<font face=\"vazir\" size=3>\n",
    "در این پروژه می‌خواهیم به بهانه‌ی مروری بر فصل‌های پیشین به طراحی یک ربات گفت‌وگو بپردازیم که براساس داده‌هایی که از منابع مختلف همچون فایل‌های <code>PDF</code> / <code>Epub</code>، صفحات ویکی‌پدیا، وب‌سایت‌ها و غیره جمع‌آوری می‌شوند به پرسش‌های کاربران پاسخ می‌دهد. این داده‌ها به فلسفه‌ی لینوکس، نرم‌افزار آزاد و چهره‌های بزرگی که در آن نقش داشته‌اند مربوط هستند و به همین دلیل نام لیبره‌چت (LibreChat) را برای آن انتخاب کرده‌ایم.\n",
    "<br>\n",
    "همان‌طور که احتمالاً خودتان حدس زده‌اید برای طراحی چنین رباتی نیاز است که یک معماری RAG را پیاده‌سازی کنید. با این حال، انتخاب و اختیار تمام جزئیات و گام‌های آن بر عهده‌ی خودتان است. مهم این است که مدل شما در نهایت بتواند به تعداد خوبی از پرسش‌هایی که در نظر گرفته‌ایم به‌درستی پاسخ دهد. برای آن‌که نتایج به‌دست‌آمده قابل داوری خودکار باشند خروجی‌های مدل نیاز است به‌شکل یک سری عبارات تک یا چند کلمه‌ای تجزیه و ساختاریافته شوند. در بخش تولید خروجی در این‌باره بیشتر صحبت خواهیم کرد و قالب مورد انتظار را شرح خواهیم داد.\n",
    "</font>\n",
    "</p>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<h2 dir=rtl align=right style=\"line-height:200%;font-family:vazir;color:#0099cc\">\n",
    "<font face=\"vazir\" color=\"#0099cc\">\n",
    "بارگیری داده‌ها\n",
    "</font>\n",
    "</h2>\n",
    "\n",
    "<p dir=rtl style=\"direction: rtl; text-align: justify; line-height:200%; font-family:vazir; font-size:medium\">\n",
    "<font face=\"vazir\">\n",
    "همان‌طور که اشاره شد در این پروژه قصد داریم از داده‌هایی با انواع متفاوت و از منابع گوناگون استفاده کنیم. بنابراین در ابتدا نیاز است به‌کمک توابع <code>LangChain</code> متناسب با هر نوع داده نسبت به خوانش ‌آن‌ها اقدام کنید تا تمام داده‌ها به‌شکل سند (<code>Document</code>) در بیایند و بتوانید آن‌ها را مشابه با همدیگر مدیریت کنید. در ادامه داده‌های مورد نیاز این پروژه را با توجه به نوع‌شان تفکیک کرده و ماهیت و منبع آن‌ها را شرح داده‌ایم.\n",
    "</font>\n",
    "</p>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<h3 dir=rtl align=right style=\"line-height:200%;font-family:vazir;color:#0099cc\">\n",
    "<font face=\"vazir\" color=\"#0099cc\">\n",
    "فایل <code>PDF</code>\n",
    "</font>\n",
    "</h3>\n",
    "\n",
    "<p dir=rtl style=\"direction: rtl; text-align: justify; line-height:200%; font-family:vazir; font-size:medium\">\n",
    "<font face=\"vazir\">\n",
    "فایل <code>PDF</code> کتابی با نام «فقط برای تفریح - داستان یک انقلاب اتفاقی» نوشته‌ی لینوس توروالدز، خالق لینوکس و دیوید دیاموند با ترجمه‌ای آزاد از <a href=\"https://jadi.net/\" target=\"_blank\">جادی</a> در پوشه‌ی داده‌های پروژه (<code>data</code>) قرار گرفته است. سعی کنید به‌کمک توابع مخصوص لنگ‌چین جهت خوانش فایل‌های <code>PDF</code> (<a href=\"https://python.langchain.com/v0.2/docs/how_to/document_loader_pdf/\" target=\"_blank\">لینک به مستندات</a>) متن این کتاب را به‌شکل سند استخراج کنید.\n",
    "</font>\n",
    "</p>\n",
    "\n",
    "<p dir=rtl style=\"direction: rtl; text-align: justify; line-height:200%; font-family:vazir; font-size:medium\">\n",
    "<font face=\"vazir\">\n",
    "<span style=\"color:green\"><b>راهنمایی:</b></span>\n",
    "توجه داشته باشید که هر کدام از توابعی که در <code>LangChain</code> جهت خوانش فایل <code>PDF</code> در نظر گرفته شده از یک کتابخانه‌ی مجزا استفاده می‌کند و معمولاً باید چندین مورد مختلف را آزمایش کرد تا موردی با کیفیت خروجی مطلوب را برگزید. با این حال، یک پیشنهاد می‌تواند استفاده از <code>PyPDFium2Loader</code> باشد. البته اگر می‌خواهید متن کتاب را هر چه بهتر و دقیق‌تر استخراج کنید می‌توانید به‌دلخواه از ابزارها و تکنیک‌های دیگری نیز بهره ببرید. پیشنهاد می‌کنیم با توجه خروجی به‌دست‌آمده و بررسی آن‌ها یک سری پیش‌پردازش‌های متنی را جهت بهبود آن‌ها اعمال کنید. چند ایده درباره‌ی پیش‌پردازش متن در صفحه‌ی پروژه در سامانه‌ی کوئرا نوشته شده است.\n",
    "</font>\n",
    "</p>\n",
    "\n",
    "<p dir=rtl style=\"direction: rtl; text-align: justify; line-height:200%; font-family:vazir; font-size:medium\">\n",
    "<font face=\"vazir\">\n",
    "<span style=\"color:orange\"><b>نکته:</b></span>\n",
    "ممکن است با جست‌وجوهای خود به نسخه‌های دیگری از این کتاب همچون فایل <code>Epub</code> نیز برخورد کنید. با این حال پیشنهاد می‌شود که در همین پروژه با چالش‌های خوانش یک فایل <code>PDF</code> فارسی (آن هم فایلی که دیجیتالی نوشته شده است) مواجه شوید تا بتوانید از تجربه‌ی خود در پروژه‌های شخصی‌تان بهره ببرید.\n",
    "</font>\n",
    "</p>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: langchain-community in /media/nayereh/F01C24171C23D77E1/ubuntu/mine_projects/LLMs/.venv/lib/python3.10/site-packages (0.3.27)\n",
      "Collecting pypdfium2\n",
      "  Downloading pypdfium2-4.30.1-py3-none-manylinux_2_17_x86_64.manylinux2014_x86_64.whl.metadata (48 kB)\n",
      "Requirement already satisfied: langchain-core<1.0.0,>=0.3.66 in /media/nayereh/F01C24171C23D77E1/ubuntu/mine_projects/LLMs/.venv/lib/python3.10/site-packages (from langchain-community) (0.3.69)\n",
      "Requirement already satisfied: langchain<1.0.0,>=0.3.26 in /media/nayereh/F01C24171C23D77E1/ubuntu/mine_projects/LLMs/.venv/lib/python3.10/site-packages (from langchain-community) (0.3.26)\n",
      "Requirement already satisfied: SQLAlchemy<3,>=1.4 in /media/nayereh/F01C24171C23D77E1/ubuntu/mine_projects/LLMs/.venv/lib/python3.10/site-packages (from langchain-community) (2.0.41)\n",
      "Requirement already satisfied: requests<3,>=2 in /media/nayereh/F01C24171C23D77E1/ubuntu/mine_projects/LLMs/.venv/lib/python3.10/site-packages (from langchain-community) (2.32.4)\n",
      "Requirement already satisfied: PyYAML>=5.3 in /media/nayereh/F01C24171C23D77E1/ubuntu/mine_projects/LLMs/.venv/lib/python3.10/site-packages (from langchain-community) (6.0.2)\n",
      "Requirement already satisfied: aiohttp<4.0.0,>=3.8.3 in /media/nayereh/F01C24171C23D77E1/ubuntu/mine_projects/LLMs/.venv/lib/python3.10/site-packages (from langchain-community) (3.12.14)\n",
      "Requirement already satisfied: tenacity!=8.4.0,<10,>=8.1.0 in /media/nayereh/F01C24171C23D77E1/ubuntu/mine_projects/LLMs/.venv/lib/python3.10/site-packages (from langchain-community) (9.1.2)\n",
      "Requirement already satisfied: dataclasses-json<0.7,>=0.5.7 in /media/nayereh/F01C24171C23D77E1/ubuntu/mine_projects/LLMs/.venv/lib/python3.10/site-packages (from langchain-community) (0.6.7)\n",
      "Requirement already satisfied: pydantic-settings<3.0.0,>=2.4.0 in /media/nayereh/F01C24171C23D77E1/ubuntu/mine_projects/LLMs/.venv/lib/python3.10/site-packages (from langchain-community) (2.10.1)\n",
      "Requirement already satisfied: langsmith>=0.1.125 in /media/nayereh/F01C24171C23D77E1/ubuntu/mine_projects/LLMs/.venv/lib/python3.10/site-packages (from langchain-community) (0.4.8)\n",
      "Requirement already satisfied: httpx-sse<1.0.0,>=0.4.0 in /media/nayereh/F01C24171C23D77E1/ubuntu/mine_projects/LLMs/.venv/lib/python3.10/site-packages (from langchain-community) (0.4.1)\n",
      "Requirement already satisfied: numpy>=1.26.2 in /media/nayereh/F01C24171C23D77E1/ubuntu/mine_projects/LLMs/.venv/lib/python3.10/site-packages (from langchain-community) (2.2.6)\n",
      "Requirement already satisfied: aiohappyeyeballs>=2.5.0 in /media/nayereh/F01C24171C23D77E1/ubuntu/mine_projects/LLMs/.venv/lib/python3.10/site-packages (from aiohttp<4.0.0,>=3.8.3->langchain-community) (2.6.1)\n",
      "Requirement already satisfied: aiosignal>=1.4.0 in /media/nayereh/F01C24171C23D77E1/ubuntu/mine_projects/LLMs/.venv/lib/python3.10/site-packages (from aiohttp<4.0.0,>=3.8.3->langchain-community) (1.4.0)\n",
      "Requirement already satisfied: async-timeout<6.0,>=4.0 in /media/nayereh/F01C24171C23D77E1/ubuntu/mine_projects/LLMs/.venv/lib/python3.10/site-packages (from aiohttp<4.0.0,>=3.8.3->langchain-community) (4.0.3)\n",
      "Requirement already satisfied: attrs>=17.3.0 in /media/nayereh/F01C24171C23D77E1/ubuntu/mine_projects/LLMs/.venv/lib/python3.10/site-packages (from aiohttp<4.0.0,>=3.8.3->langchain-community) (25.3.0)\n",
      "Requirement already satisfied: frozenlist>=1.1.1 in /media/nayereh/F01C24171C23D77E1/ubuntu/mine_projects/LLMs/.venv/lib/python3.10/site-packages (from aiohttp<4.0.0,>=3.8.3->langchain-community) (1.7.0)\n",
      "Requirement already satisfied: multidict<7.0,>=4.5 in /media/nayereh/F01C24171C23D77E1/ubuntu/mine_projects/LLMs/.venv/lib/python3.10/site-packages (from aiohttp<4.0.0,>=3.8.3->langchain-community) (6.6.3)\n",
      "Requirement already satisfied: propcache>=0.2.0 in /media/nayereh/F01C24171C23D77E1/ubuntu/mine_projects/LLMs/.venv/lib/python3.10/site-packages (from aiohttp<4.0.0,>=3.8.3->langchain-community) (0.3.2)\n",
      "Requirement already satisfied: yarl<2.0,>=1.17.0 in /media/nayereh/F01C24171C23D77E1/ubuntu/mine_projects/LLMs/.venv/lib/python3.10/site-packages (from aiohttp<4.0.0,>=3.8.3->langchain-community) (1.20.1)\n",
      "Requirement already satisfied: marshmallow<4.0.0,>=3.18.0 in /media/nayereh/F01C24171C23D77E1/ubuntu/mine_projects/LLMs/.venv/lib/python3.10/site-packages (from dataclasses-json<0.7,>=0.5.7->langchain-community) (3.26.1)\n",
      "Requirement already satisfied: typing-inspect<1,>=0.4.0 in /media/nayereh/F01C24171C23D77E1/ubuntu/mine_projects/LLMs/.venv/lib/python3.10/site-packages (from dataclasses-json<0.7,>=0.5.7->langchain-community) (0.9.0)\n",
      "Requirement already satisfied: langchain-text-splitters<1.0.0,>=0.3.8 in /media/nayereh/F01C24171C23D77E1/ubuntu/mine_projects/LLMs/.venv/lib/python3.10/site-packages (from langchain<1.0.0,>=0.3.26->langchain-community) (0.3.8)\n",
      "Requirement already satisfied: pydantic<3.0.0,>=2.7.4 in /media/nayereh/F01C24171C23D77E1/ubuntu/mine_projects/LLMs/.venv/lib/python3.10/site-packages (from langchain<1.0.0,>=0.3.26->langchain-community) (2.11.7)\n",
      "Requirement already satisfied: jsonpatch<2.0,>=1.33 in /media/nayereh/F01C24171C23D77E1/ubuntu/mine_projects/LLMs/.venv/lib/python3.10/site-packages (from langchain-core<1.0.0,>=0.3.66->langchain-community) (1.33)\n",
      "Requirement already satisfied: typing-extensions>=4.7 in /media/nayereh/F01C24171C23D77E1/ubuntu/mine_projects/LLMs/.venv/lib/python3.10/site-packages (from langchain-core<1.0.0,>=0.3.66->langchain-community) (4.14.1)\n",
      "Requirement already satisfied: packaging>=23.2 in /media/nayereh/F01C24171C23D77E1/ubuntu/mine_projects/LLMs/.venv/lib/python3.10/site-packages (from langchain-core<1.0.0,>=0.3.66->langchain-community) (25.0)\n",
      "Requirement already satisfied: jsonpointer>=1.9 in /media/nayereh/F01C24171C23D77E1/ubuntu/mine_projects/LLMs/.venv/lib/python3.10/site-packages (from jsonpatch<2.0,>=1.33->langchain-core<1.0.0,>=0.3.66->langchain-community) (3.0.0)\n",
      "Requirement already satisfied: annotated-types>=0.6.0 in /media/nayereh/F01C24171C23D77E1/ubuntu/mine_projects/LLMs/.venv/lib/python3.10/site-packages (from pydantic<3.0.0,>=2.7.4->langchain<1.0.0,>=0.3.26->langchain-community) (0.7.0)\n",
      "Requirement already satisfied: pydantic-core==2.33.2 in /media/nayereh/F01C24171C23D77E1/ubuntu/mine_projects/LLMs/.venv/lib/python3.10/site-packages (from pydantic<3.0.0,>=2.7.4->langchain<1.0.0,>=0.3.26->langchain-community) (2.33.2)\n",
      "Requirement already satisfied: typing-inspection>=0.4.0 in /media/nayereh/F01C24171C23D77E1/ubuntu/mine_projects/LLMs/.venv/lib/python3.10/site-packages (from pydantic<3.0.0,>=2.7.4->langchain<1.0.0,>=0.3.26->langchain-community) (0.4.1)\n",
      "Requirement already satisfied: python-dotenv>=0.21.0 in /media/nayereh/F01C24171C23D77E1/ubuntu/mine_projects/LLMs/.venv/lib/python3.10/site-packages (from pydantic-settings<3.0.0,>=2.4.0->langchain-community) (1.1.1)\n",
      "Requirement already satisfied: charset_normalizer<4,>=2 in /media/nayereh/F01C24171C23D77E1/ubuntu/mine_projects/LLMs/.venv/lib/python3.10/site-packages (from requests<3,>=2->langchain-community) (3.4.2)\n",
      "Requirement already satisfied: idna<4,>=2.5 in /media/nayereh/F01C24171C23D77E1/ubuntu/mine_projects/LLMs/.venv/lib/python3.10/site-packages (from requests<3,>=2->langchain-community) (3.10)\n",
      "Requirement already satisfied: urllib3<3,>=1.21.1 in /media/nayereh/F01C24171C23D77E1/ubuntu/mine_projects/LLMs/.venv/lib/python3.10/site-packages (from requests<3,>=2->langchain-community) (2.5.0)\n",
      "Requirement already satisfied: certifi>=2017.4.17 in /media/nayereh/F01C24171C23D77E1/ubuntu/mine_projects/LLMs/.venv/lib/python3.10/site-packages (from requests<3,>=2->langchain-community) (2025.7.14)\n",
      "Requirement already satisfied: greenlet>=1 in /media/nayereh/F01C24171C23D77E1/ubuntu/mine_projects/LLMs/.venv/lib/python3.10/site-packages (from SQLAlchemy<3,>=1.4->langchain-community) (3.2.3)\n",
      "Requirement already satisfied: mypy-extensions>=0.3.0 in /media/nayereh/F01C24171C23D77E1/ubuntu/mine_projects/LLMs/.venv/lib/python3.10/site-packages (from typing-inspect<1,>=0.4.0->dataclasses-json<0.7,>=0.5.7->langchain-community) (1.1.0)\n",
      "Requirement already satisfied: httpx<1,>=0.23.0 in /media/nayereh/F01C24171C23D77E1/ubuntu/mine_projects/LLMs/.venv/lib/python3.10/site-packages (from langsmith>=0.1.125->langchain-community) (0.28.1)\n",
      "Requirement already satisfied: orjson<4.0.0,>=3.9.14 in /media/nayereh/F01C24171C23D77E1/ubuntu/mine_projects/LLMs/.venv/lib/python3.10/site-packages (from langsmith>=0.1.125->langchain-community) (3.11.0)\n",
      "Requirement already satisfied: requests-toolbelt<2.0.0,>=1.0.0 in /media/nayereh/F01C24171C23D77E1/ubuntu/mine_projects/LLMs/.venv/lib/python3.10/site-packages (from langsmith>=0.1.125->langchain-community) (1.0.0)\n",
      "Requirement already satisfied: zstandard<0.24.0,>=0.23.0 in /media/nayereh/F01C24171C23D77E1/ubuntu/mine_projects/LLMs/.venv/lib/python3.10/site-packages (from langsmith>=0.1.125->langchain-community) (0.23.0)\n",
      "Requirement already satisfied: anyio in /media/nayereh/F01C24171C23D77E1/ubuntu/mine_projects/LLMs/.venv/lib/python3.10/site-packages (from httpx<1,>=0.23.0->langsmith>=0.1.125->langchain-community) (4.9.0)\n",
      "Requirement already satisfied: httpcore==1.* in /media/nayereh/F01C24171C23D77E1/ubuntu/mine_projects/LLMs/.venv/lib/python3.10/site-packages (from httpx<1,>=0.23.0->langsmith>=0.1.125->langchain-community) (1.0.9)\n",
      "Requirement already satisfied: h11>=0.16 in /media/nayereh/F01C24171C23D77E1/ubuntu/mine_projects/LLMs/.venv/lib/python3.10/site-packages (from httpcore==1.*->httpx<1,>=0.23.0->langsmith>=0.1.125->langchain-community) (0.16.0)\n",
      "Requirement already satisfied: exceptiongroup>=1.0.2 in /media/nayereh/F01C24171C23D77E1/ubuntu/mine_projects/LLMs/.venv/lib/python3.10/site-packages (from anyio->httpx<1,>=0.23.0->langsmith>=0.1.125->langchain-community) (1.3.0)\n",
      "Requirement already satisfied: sniffio>=1.1 in /media/nayereh/F01C24171C23D77E1/ubuntu/mine_projects/LLMs/.venv/lib/python3.10/site-packages (from anyio->httpx<1,>=0.23.0->langsmith>=0.1.125->langchain-community) (1.3.1)\n",
      "Downloading pypdfium2-4.30.1-py3-none-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (2.9 MB)\n",
      "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m2.9/2.9 MB\u001b[0m \u001b[31m4.5 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0ma \u001b[36m0:00:01\u001b[0m\n",
      "\u001b[?25hInstalling collected packages: pypdfium2\n",
      "Successfully installed pypdfium2-4.30.1\n"
     ]
    }
   ],
   "source": [
    "!pip install langchain-community pypdfium2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/media/nayereh/F01C24171C23D77E1/ubuntu/mine_projects/LLMs/.venv/lib/python3.10/site-packages/pypdfium2/_helpers/textpage.py:80: UserWarning: get_text_range() call with default params will be implicitly redirected to get_text_bounded()\n",
      "  warnings.warn(\"get_text_range() call with default params will be implicitly redirected to get_text_bounded()\")\n"
     ]
    }
   ],
   "source": [
    "# Don't forget to install the langchain-community and pypdfium2 packages\n",
    "from langchain_community.document_loaders import PyPDFium2Loader\n",
    "\n",
    "pdfloader = PyPDFium2Loader(\"data/justforfun_persian.pdf\")\n",
    "pdf_docs =  pdfloader.load() # Load the justforfun_persian.pdf file using a Langchain document loader"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Number of pages (loaded Document objects): 204\n"
     ]
    }
   ],
   "source": [
    "print(\"Number of pages (loaded Document objects):\", len(pdf_docs))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "تولد یͷ نرد، بخش دوم صفحۀ ١١\n",
      "و او مͬ خواست من را هم در این تجربه شریͷ کند. همچنین مͬ خواست من را به ریاضͬ\n",
      "علاقمند کند.\n",
      "پس من را روی زانو هایش مͬ نشاند و از من مͬ خواست تا برنامه هایی که با دقت روی کاغذ\n",
      "نوشته بود را برایش تایپ کنم. مͬ گفت خودش با کامپیوترها راحت نیست. نمͬ دانم آن محاسبات\n",
      "راجع به چه چیزی بودند و بعید مͬ دانم که آن موقع هیچ درکͬ از کاری که مͬ کردم هم داشته باشم\n",
      "ولͬ به هرحال آنجا بودم و به او کمͷ مͬ کردم. احتمالا کار از حالتͬ که او خودش به تنهایی\n",
      "برنامه ها را وارد مͬ کرد، خیلͬ بیشتر طول مͬ کشید. ولͬ کسͬ چه مͬ داند؟ من از همان کودکͬ به\n",
      "صفحه کلید عادت کرده بودم، چیزی که پدربزرگم هیچ وقت امͺان اش را نداشت. بعد از مدرسه\n",
      "یا هر موقع دیͽری که مادرم من را پیش پدربزرگم مͬ گذاشت، مشغول همین کار مͬ شدیم.\n",
      "بعد شروع کردم به خواندن راهنماهای کامپیوتر و وارد کردن برنامه های آماده شده. مثال ها\n",
      "شامل بازی های ساده ای بودند که خودتان مͬ توانستید آن ها را وارد کنید. اگر همه چیز را درست\n",
      "تایپ مͬ کردید، یͷ آقایی با گرافیͷ بد، روی صفحه راه مͬ رفت. بعد مͬ توانستید برنامه را عوض\n",
      "کنید تا آقای راه رونده، رنگش عوض شود. شما خودتان مͬ توانستید این کار را بͺنید.\n",
      "این بالاترین لذت بود.\n",
      "شروع کردم به نوشتن برنامه های خودم. اولین برنامه ای که نوشتم، اولین برنامه ای بود که هر\n",
      "کسͬ مͬ نویسد:\n",
      "10 PRINT \"HELLO\"\n",
      "20 GOTO 10\n",
      "این برنامه دقیقا همان کاری را مͬ کند که انتظار دارید بͺند. روی صفحه مͬ نویسد “سلام” و\n",
      "تا ابد به این کار ادامه مͬ دهد. یا حداقل تا وقتͬ که شما از شدت سر رفتن حوصله تان، برنامه را\n",
      "قطع کنید.\n",
      "اما این قدم اول است. بعضͬ ها همین جا متوقف مͬ شوند.برای آن ها این برنامه احمقانه ای\n",
      "است چون “چرا باید کسͬ علاقمند باشد به میلیون ها کلمه ‘سلام’ خیره شود؟” اما به هرحال این\n",
      "برنامه تقریبا همیشه اولین برنامه در راهنماهایی بود که آن روزها همراه کامپیوترهای شخصͬ داده\n",
      "مͬ شدند.\n",
      "نکته جادویی اینجا است که شما مͬ توانید این برنامه را تغییر دهید. خواهرم مͬ گوید که من\n",
      "یͷ تغییر ریشه ای در برنامه دادم تا نسخه دومͬ بسازم که به جای نوشتن “سلام”، روی صفحه\n",
      "بارها و بارها مͬ نوشت “سارا بهترین است.” در کل من برادر بزرگ تر مهربانͬ نبودم ولͬ این ژست\n",
      "برنامه نویس،ͬ تاثیر زیادی روی خواهرم گذاشت.\n",
      "من این جریان را یادم نیست. هر بار که یͷ برنامه مͬ نوشتم، آن را فراموش مͬ کردم و سراغ\n",
      "برنامه بعدی مͬ رفتم.\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# Take a look at a random page of the document \n",
    "print(pdf_docs[15].page_content)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "تولد یک نرد، بخش دوم صفحۀ ١١\n",
      "و او می خواست من را هم در این تجربه شریک کند. همچنین می خواست من را به ریاضͬ\n",
      "علاقمند کند.\n",
      "پس من را روی زانو هایش می نشاند و از من می خواست تا برنامه هایی که با دقت روی کاغذ\n",
      "نوشته بود را برایش تایپ کنم. می گفت خودش با کامپیوترها راحت نیست. نمی دانم آن محاسبات\n",
      "راجع به چه چیزی بودند و بعید می دانم که آن موقع هیچ درکی از کاری که می کردم هم داشته باشم\n",
      "ولی به هرحال آنجا بودم و به او کمک می کردم. احتمالا کار از حالتی که او خودش به تنهایی\n",
      "برنامه ها را وارد می کرد، خیلی بیشتر طول می کشید. ولی کسی چه می داند؟ من از همان کودکی به\n",
      "صفحه کلید عادت کرده بودم، چیزی که پدربزرگم هیچ وقت امͺان اش را نداشت. بعد از مدرسه\n",
      "یا هر موقع دیͽری که مادرم من را پیش پدربزرگم می گذاشت، مشغول همین کار می شدیم.\n",
      "بعد شروع کردم به خواندن راهنماهای کامپیوتر و وارد کردن برنامه های آماده شده. مثال ها\n",
      "شامل بازی های ساده ای بودند که خودتان می توانستید آن ها را وارد کنید. اگر همه چیز را درست\n",
      "تایپ می کردید، یک آقایی با گرافیک بد، روی صفحه راه می رفت. بعد می توانستید برنامه را عوض\n",
      "کنید تا آقای راه رونده، رنگش عوض شود. شما خودتان می توانستید این کار را بͺنید.\n",
      "این بالاترین لذت بود.\n",
      "شروع کردم به نوشتن برنامه های خودم. اولین برنامه ای که نوشتم، اولین برنامه ای بود که هر\n",
      "کسی می نویسد:\n",
      "10 PRINT \"HELLO\"\n",
      "20 GOTO 10\n",
      "این برنامه دقیقا همان کاری را می کند که انتظار دارید بͺند. روی صفحه می نویسد “سلام” و\n",
      "تا ابد به این کار ادامه می دهد. یا حداقل تا وقتی که شما از شدت سر رفتن حوصله تان، برنامه را\n",
      "قطع کنید.\n",
      "اما این قدم اول است. بعضی ها همین جا متوقف می شوند.برای آن ها این برنامه احمقانه ای\n",
      "است چون “چرا باید کسی علاقمند باشد به میلیون ها کلمه ‘سلام’ خیره شود؟” اما به هرحال این\n",
      "برنامه تقریبا همیشه اولین برنامه در راهنماهایی بود که آن روزها همراه کامپیوترهای شخصی داده\n",
      "می شدند.\n",
      "نکته جادویی اینجا است که شما می توانید این برنامه را تغییر دهید. خواهرم می گوید که من\n",
      "یک تغییر ریشه ای در برنامه دادم تا نسخه دومی بسازم که به جای نوشتن “سلام”، روی صفحه\n",
      "بارها و بارها می نوشت “سارا بهترین است.” در کل من برادر بزرگ تر مهربانی نبودم ولی این ژست\n",
      "برنامه نویس،ی تاثیر زیادی روی خواهرم گذاشت.\n",
      "من این جریان را یادم نیست. هر بار که یک برنامه می نوشتم، آن را فراموش می کردم و سراغ\n",
      "برنامه بعدی می رفتم.\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# TODO: Apply any necessary preprocessing to the document pages\n",
    "\n",
    "def replace_white_spaces(text):\n",
    "    text = text.replace(chr(876) + ' ', 'ی ')\n",
    "    text = text.replace(chr(876) + chr(13), 'ی ')\n",
    "    text = text.replace('ͷ', 'ک')  # Replace ͷ with ک\n",
    "    return text\n",
    "\n",
    "for i, page in enumerate(pdf_docs):\n",
    "    page.page_content = replace_white_spaces(page.page_content)\n",
    "\n",
    "print(pdf_docs[15].page_content)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "\n",
    "<h3 dir=rtl align=right style=\"line-height:200%;font-family:vazir;color:#0099cc\">\n",
    "<font face=\"vazir\" color=\"#0099cc\">\n",
    "لینک وب\n",
    "</font>\n",
    "</h3>\n",
    "\n",
    "<p dir=rtl style=\"direction: rtl; text-align: justify; line-height:200%; font-family:vazir; font-size:medium\">\n",
    "<font face=\"vazir\">\n",
    "محتوای دیگری که قصد استفاده از آن را داریم کتاب «لینوکس و زندگی» از <a href=\"https://jadi.net/\" target=\"_blank\">جادی</a> است که به‌صورت آزاد در دسترس است. با این حال، این کتاب نسخه‌ی <code>PDF</code> نداشته و می‌خواهیم آن را مستقیماً از بستر وب بخوانیم. بنابراین نیاز است به‌کمک توابع مرتبط لنگ‌چین، محتوای لینک <a href=\"https://linuxbook.ir/all.html\" target=\"_blank\"><code dir=ltr>https://linuxbook.ir/all.html</code></a> را بارگیری کنید. برای این کار می‌توانید از تابع <code>WebBaseLoader</code> کمک بگیرید.\n",
    "</font>\n",
    "</p>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Collecting beautifulsoup4\n",
      "  Downloading beautifulsoup4-4.13.4-py3-none-any.whl.metadata (3.8 kB)\n",
      "Collecting soupsieve>1.2 (from beautifulsoup4)\n",
      "  Downloading soupsieve-2.7-py3-none-any.whl.metadata (4.6 kB)\n",
      "Requirement already satisfied: typing-extensions>=4.0.0 in /media/nayereh/F01C24171C23D77E1/ubuntu/mine_projects/LLMs/.venv/lib/python3.10/site-packages (from beautifulsoup4) (4.14.1)\n",
      "Downloading beautifulsoup4-4.13.4-py3-none-any.whl (187 kB)\n",
      "Downloading soupsieve-2.7-py3-none-any.whl (36 kB)\n",
      "Installing collected packages: soupsieve, beautifulsoup4\n",
      "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m2/2\u001b[0m [beautifulsoup4]m [beautifulsoup4]\n",
      "\u001b[1A\u001b[2KSuccessfully installed beautifulsoup4-4.13.4 soupsieve-2.7\n"
     ]
    }
   ],
   "source": [
    "!pip install beautifulsoup4"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "USER_AGENT environment variable not set, consider setting it to identify your requests.\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "from langchain_community.document_loaders import WebBaseLoader\n",
    "\n",
    "# Set the User-Agent (you can customize this string to mimic a browser)\n",
    "os.environ[\"USER_AGENT\"] = \"Mozilla/5.0 (Windows NT 10.0; Win64; x64) AppleWebKit/537.36 (KHTML, like Gecko) Chrome/115.0.0.0 Safari/537.36\"\n",
    "\n",
    "webloader = WebBaseLoader(\"https://linuxbook.ir/all.html\")\n",
    "web_docs = webloader.load() # TODO: Load the https://linuxbook.ir/all.html page"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "لینوکس و زندگی | لینوکس و زندگی\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "Toggle navigation\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "لینوکس و زندگی\n",
      "\n",
      "\n",
      "\n",
      "روی جلد\n",
      "درباره\n",
      "دانلود\n",
      "حمایت\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "لینوکس و زندگی\n",
      "\n",
      "\n",
      "فهرست \n",
      "لینوکس و زندگی. نوشته جادی www.jadi.netبرای دسترسی به آخرین نسخه کتاب در فرمت‌های مختلف و همچنین حمایت مالی از پروژه کتاب‌هایی برای گیک‌ها، به سایت www.jadi.ir و بخش حمایت مراجعه کنید.درباره این کتاب \n",
      "این کتاب سعی می کنه به خواننده ایده‌هایی درمورد زندگی و لینوکس بده. چرا زندگی؟ چون لینوکس یک فلسفه است و براومده از یک جامعه و کسی که می خواد توش موفق باشه با\n"
     ]
    }
   ],
   "source": [
    "# Look at the first 512 characters of the page content\n",
    "print(web_docs[0].page_content[:512])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<h3 dir=rtl align=right style=\"line-height:200%;font-family:vazir;color:#0099cc\">\n",
    "<font face=\"vazir\" color=\"#0099cc\">\n",
    "صفحه‌ی ویکی‌پدیا\n",
    "</font>\n",
    "</h3>\n",
    "\n",
    "<p dir=rtl style=\"direction: rtl; text-align: justify; line-height:200%; font-family:vazir; font-size:medium\">\n",
    "<font face=\"vazir\">\n",
    "علاوه‌بر محتواهایی که تاکنون در دسترس ما قرار گرفت قصد داریم از محتوای موجود در صفحات ویکی‌پدیای مرتبط با آن‌ها نیز استفاده کنیم. در لیست زیر عنوان چند صفحه‌ی ویکی‌پدیا قرار داده شده که نیاز است با کمک توابعی همچون <code>WikipediaLoader</code> آن‌ها را بارگیری کنید.\n",
    "\n",
    "<ul dir=rtl>\n",
    "<li>ریچارد استالمن</li>\n",
    "<li>لینوس توروالدز</li>\n",
    "<li>لینوکس</li>\n",
    "<li>پروژه گنو</li>\n",
    "<li>نرم‌افزار آزاد</li>\n",
    "<li>بنیاد نرم‌افزار آزاد</li>\n",
    "</ul>\n",
    "</font>\n",
    "</p>\n",
    "\n",
    "<p dir=rtl style=\"direction: rtl; text-align: justify; line-height:200%; font-family:vazir; font-size:medium\">\n",
    "<font face=\"vazir\">\n",
    "<span style=\"color:red\"><b>توجه:</b></span>\n",
    "اگر چندین درخواست پشت همدیگر به <i>API</i> ویکی‌پدیا ارسال کنید ممکن است درخواست‌های شما مسدود شود و نیاز است بین درخواست‌های خود اندکی صبر کنید. برای این کار می‌توانید از <code>time.sleep</code> استفاده کرده و بین درخواست‌های خود چند ثانیه وقفه‌ی تصادفی ایجاد کنید. همچنین می‌توانید این کار را در یک حلقه انجام داده و مشخص کنید تا وقتی‌که صفحه‌ی مورد نظر بارگیری نشده چند ثانیه صبر کند و مجدد درخواست دهد.\n",
    "</font>\n",
    "</p>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Collecting wikipedia\n",
      "  Downloading wikipedia-1.4.0.tar.gz (27 kB)\n",
      "  Installing build dependencies ... \u001b[?25ldone\n",
      "\u001b[?25h  Getting requirements to build wheel ... \u001b[?25ldone\n",
      "\u001b[?25h  Preparing metadata (pyproject.toml) ... \u001b[?25ldone\n",
      "\u001b[?25hRequirement already satisfied: beautifulsoup4 in /media/nayereh/F01C24171C23D77E1/ubuntu/mine_projects/LLMs/.venv/lib/python3.10/site-packages (from wikipedia) (4.13.4)\n",
      "Requirement already satisfied: requests<3.0.0,>=2.0.0 in /media/nayereh/F01C24171C23D77E1/ubuntu/mine_projects/LLMs/.venv/lib/python3.10/site-packages (from wikipedia) (2.32.4)\n",
      "Requirement already satisfied: charset_normalizer<4,>=2 in /media/nayereh/F01C24171C23D77E1/ubuntu/mine_projects/LLMs/.venv/lib/python3.10/site-packages (from requests<3.0.0,>=2.0.0->wikipedia) (3.4.2)\n",
      "Requirement already satisfied: idna<4,>=2.5 in /media/nayereh/F01C24171C23D77E1/ubuntu/mine_projects/LLMs/.venv/lib/python3.10/site-packages (from requests<3.0.0,>=2.0.0->wikipedia) (3.10)\n",
      "Requirement already satisfied: urllib3<3,>=1.21.1 in /media/nayereh/F01C24171C23D77E1/ubuntu/mine_projects/LLMs/.venv/lib/python3.10/site-packages (from requests<3.0.0,>=2.0.0->wikipedia) (2.5.0)\n",
      "Requirement already satisfied: certifi>=2017.4.17 in /media/nayereh/F01C24171C23D77E1/ubuntu/mine_projects/LLMs/.venv/lib/python3.10/site-packages (from requests<3.0.0,>=2.0.0->wikipedia) (2025.7.14)\n",
      "Requirement already satisfied: soupsieve>1.2 in /media/nayereh/F01C24171C23D77E1/ubuntu/mine_projects/LLMs/.venv/lib/python3.10/site-packages (from beautifulsoup4->wikipedia) (2.7)\n",
      "Requirement already satisfied: typing-extensions>=4.0.0 in /media/nayereh/F01C24171C23D77E1/ubuntu/mine_projects/LLMs/.venv/lib/python3.10/site-packages (from beautifulsoup4->wikipedia) (4.14.1)\n",
      "Building wheels for collected packages: wikipedia\n",
      "  Building wheel for wikipedia (pyproject.toml) ... \u001b[?25ldone\n",
      "\u001b[?25h  Created wheel for wikipedia: filename=wikipedia-1.4.0-py3-none-any.whl size=11757 sha256=7d9bff24bde7bcd996fd10ff16cdd1b06f4bc576455152cc3add3fed7d46700e\n",
      "  Stored in directory: /home/nayereh/.cache/pip/wheels/5e/b6/c5/93f3dec388ae76edc830cb42901bb0232504dfc0df02fc50de\n",
      "Successfully built wikipedia\n",
      "Installing collected packages: wikipedia\n",
      "Successfully installed wikipedia-1.4.0\n"
     ]
    }
   ],
   "source": [
    "!pip install wikipedia"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "from langchain_community.document_loaders import WikipediaLoader\n",
    "import time, random\n",
    "\n",
    "wiki_titles = ['ریچارد استالمن', 'لینوس توروالدز', 'لینوکس', 'پروژه گنو', 'نرم‌افزار آزاد', 'بنیاد نرم‌افزار آزاد']\n",
    "wiki_docs = []\n",
    "for title in wiki_titles:\n",
    "    wiki_loader = WikipediaLoader(query=title, lang=\"fa\", load_max_docs=1)\n",
    "    wiki_docs.append(wiki_loader.load()[0]) # TODO: Load the Wikipedia pages for the titles in wiki_titles (set load_max_docs to 1)\n",
    "    time.sleep(random.uniform(0.5, 1.5))  # Add a random delay between 0.5 and 1.5 seconds"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Number of wikipedia pages (loaded Document objects): 6\n",
      "نرم‌افزار آزاد (به انگلیسی: free software) نرم‌افزاری است که به‌همراه کد منبع توزیع شده و با قوانینی منتشر می‌شود که آزادی استفاده، مطالعه، ویرایش و انتشار مجدد کاربران را تضمین می‌کند. نرم‌افزارهای آزاد معمولاً با همکاری برنامه‌نویس‌های داوطلب به‌عنوان یک پروژه به‌وجود می‌آیند. ایدهٔ اصلی نرم‌افزار آزاد بر مالکیت دستگاه‌های دیجیتالی توسط کاربران در مقابل سازندگان دستگاه‌ها دلالت دارد.\n",
      "نرم‌افزارهای آزاد با نرم‌افزارهای مالکیتی (مانند مایکروسافت ویندوز) که آزادی کاربر در استفاده، مطالعه، ویرایش یا انتشار مجدد را در درجه‌های مختلف محدود می‌کنند، متفاوت هستند. این محدودیت‌ها با در نظر گرفتن مجازات‌هایی قانونی برای کاربرانی که قوانین آن‌ها را نقض می‌کنند، به‌وجود می‌آیند. نرم‌افزارهای مالکیتی عموماً به صورت بسته‌های اجراپذیر دودویی و بدون دسترسی به کد منبع فروخته می‌شوند که جلوی ویرایش و وصله کردن نرم‌افزار توسط کاربر را می‌گیرد و او را برای به‌روزرسانی و پشتیبانی به شرکت نرم‌افزاری تولیدکننده وابسته می‌کنند. نرم‌افزارهای آزاد از نرم‌افزاری‌های رایگان که برای استفاده، از کاربر پولی دریافت نمی‌کنند، نیز متفاوت‌اند. این نوع نرم‌افزارها نیز معمولاً تمامی حقوق نرم‌افزار را برای تولیدکنندهٔ آن محفوظ داشته و جلوی مهندسی معکوس، ویرایش یا توزیع مجدد توسط کاربر را می‌گیرند. بنابراین موضوع اصلی نرم‌افزار آزاد، موضوع آزادی است و نه قیمت آن: کاربران آزادند که هر چه می‌خواهند با نرم‌افزار انجام دهند. این آزادی شامل انتشار مجدد نرم‌افزار به‌صورت رایگان یا با سود نیز می‌شود. یعنی نرم‌افزار آزاد می‌تواند به صورت رایگان یا در ازای دریافت مبلغی پول در اختیار کاربر قرار بگیرد.\n",
      "ریچارد استالمن در سال ۱۹۸۵ در زمانی که در حال آغاز پروژهٔ گنو و به‌وجود آوردن بنیاد نرم‌افزارهای آزاد بود، برای اولین بار از عبارت «نرم‌افزار آزاد» استفاده کرد. براساس تعریف بنیاد نرم‌افزارهای آزاد کاربران یک نرم‌افزارِ آزاد، آزاد هستند؛ چون به اجازه گرفتن نیازی ندارند؛ آن‌ها در انجام کارهای دل‌خواهشان (مانند حق نشر و کپی‌برداری) محدود نیستند؛ نیازی به موافقت با هیچ توافق‌نامه‌ای ندارند؛ و در همان ابتدا نیز با نداشتن کد منبع محدود نبوده‌اند.\n",
      "\n",
      "\n",
      "== تعریف ==\n",
      "\n",
      "\n",
      "=== بنیاد نرم‌افزار آزاد ===\n",
      "طبق تعریف نرم‌افزار آزاد توسط بنیاد نرم‌افزارهای آزاد، هر نرم‌افزاری که آزادی‌های زیر را برای کاربرانش فراهم کند به عنوان یک نرم‌افزار آزاد شناخته می‌شود:\n",
      "\n",
      "آزادی صفرم (آزادی اجرا): کاربران باید اجازه داشته باشند که نرم‌افزار مورد نظر را برای هر قصد و منظوری اجرا کنند.\n",
      "آزادی یکم (آزادی تغییر): کاربران باید اجازه داشته باشند نحوه کار نرم‌افزار را مطالعه کند و بتواند آن را مطابق با نیازهای خود تغییر دهند. برای رسیدن به این هدف، کدهای منبع نرم‌افزار باید در اختیار کاربران قرار گیرد.\n",
      "آزادی دوم (آزادی انتشار): کاربران باید اجازه داشته باشند نرم‌افزار را مجدداً منتشر کرده و در اختیار دیگران قرار دهند. این کار می‌تواند به صورت رایگان یا در ازای دریافت مبلغی پول صورت گیرد.\n",
      "آزادی سوم (آزادی توزیع): اگر کاربری، نرم‌افزار را تغییر داد، باید بتواند آن را مجدداً منتشر کرده و در اختیار دیگران قرار دهد. (در مورد نرم‌افزارهای کپی‌لفت، لازم است تا کدهای منبع نرم‌افزار تغییریافته نیز در اختیار کاربران دیگر قرار گیرد)\n",
      "در ابتدا فقط سه آزادی وجود داشت که از آزادی یکم شروع می‌شد و به آزادی سوم ختم می‌شد اما بعدها این مسئله مهم شد که بدون اجازه اجرای نرم‌افزار عملاً رسیدن به آزادی‌های دیگر ممکن نیست، پس آزادی صفرم یا آزادی اجرا به این شرایط اضافه شد.\n",
      "\n",
      "\n",
      "=== مؤسسه پیشگامان متن‌باز ===\n",
      "همچنین «مؤسسه پیشگامان متن‌باز» هم تعریف مشابهی از نرم‌افزار آزاد ارائه داده‌است. طبق تعریف این مؤسسه، نرم‌افزار بازمتن، تنها به معنی در دسترس ساختن کدمنبع نیست. علاوه بر این مجوز، باید ویژگی‌های زیر را هم داشته باشد:\n",
      "\n",
      "نرم‌افزار باید قابل توزیع مجدد باشد (به صورت رایگان، یا در ازای دریافت مبلغی پول)\n",
      "نرم‌افزار باید شامل کد منبع باشد و این کد منبع را باید بتوان تغییر داد و مجدداً منتشر کرد.\n",
      "مجوز باید اجازه ویرایش و تولید پروژه‌های انشقاقی را بدهد.\n",
      "مجوز می‌تواند تمهیداتی برای حفاظت از یکپارچگی کد منبع پدیدآورنده در نظر بگیرد.\n",
      "مجوز نباید بین افراد یا گروه‌ها تبعیض قائل شود.\n",
      "مجوز نباید تبعیضی در خصوص موارد استفاده اعمال کند.\n",
      "حقوق مرتبط با نرم‌افزار بایستی بدون نیاز به مجوزی دیگر به هر کسی که نرم‌افزار را دریافت می‌کند تسری یابد.\n",
      "مجوز نباید مختص به یک محصول خاص باشد.\n",
      "مجوز نباید نرم‌افزارهای دیگری که به همراه نرم‌افزار مورد نظر عرضه شده‌اند را محد\n"
     ]
    }
   ],
   "source": [
    "print(\"Number of wikipedia pages (loaded Document objects):\", len(wiki_docs))\n",
    "print(wiki_docs[4].page_content)\n",
    "# print(type(wiki_docs))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<h3 dir=rtl align=right style=\"line-height:200%;font-family:vazir;color:#0099cc\">\n",
    "<font face=\"vazir\" color=\"#0099cc\">\n",
    "فایل <code>HTML</code>\n",
    "</font>\n",
    "</h3>\n",
    "\n",
    "<p dir=rtl style=\"direction: rtl; text-align: justify; line-height:200%; font-family:vazir; font-size:medium\">\n",
    "<font face=\"vazir\">\n",
    "حال بیایید از وب‌سایت خود آقای استالمن هم کمک بگیریم و محتوای آن را در اختیار پروژه‌ی خود قرار دهیم. برای این کار لینک‌های داخلی وب‌سایت <a href=\"https://stallman.org\" target=\"_blank\"><code>https://stallman.org</code></a> را به‌کمک <i>Web Scraping</i> استخراج کرده‌ایم و فایل‌های <code>HTML</code> این صفحات را در پوشه‌ای به همین نام در مسیر داده‌های پروژه (<code>data</code>) ذخیره کرده‌ایم. کد مربوط به بخش استخراج این صفحات صرفاً جهت مطالعه‌ی بیشتر در اختیار شما قرار گرفته و در این مرحله تنها نیاز است که شما فایل‌های <code>HTML</code> را از پوشه‌ی مذکور بخوانید. برای این کار روش‌های متفاوتی وجود دارد اما یک راه استفاده از <code>DirectoryLoader</code> (<a href=\"https://python.langchain.com/v0.2/docs/how_to/document_loader_directory/\" target=\"_blank\">مطالعه‌ی مستندات</a>) و <code>BSHTMLLoader</code> (<a href=\"https://python.langchain.com/v0.2/docs/integrations/document_loaders/bshtml/#loader-features\"  target=\"_blank\">مطالعه‌ی مستندات</a>) به‌عنوان کلاس بارگیری‌کننده‌ی آن (آرگومان <code>loader_cls</code>) است.\n",
    "</font>\n",
    "</p>\n",
    "\n",
    "<details>\n",
    "<summary dir=rtl style=\"direction: rtl; text-align: justify; line-height:200%; font-family:vazir; font-size:medium\">مشاهده‌ی کد استخراج داده‌ها</summary>\n",
    "<br>\n",
    "\n",
    "```python\n",
    "\n",
    "# The following code is used to download the HTML content of the Stallman website\n",
    "\n",
    "import requests\n",
    "from bs4 import BeautifulSoup\n",
    "from urllib.parse import urljoin, urlparse\n",
    "import os\n",
    "\n",
    "def save_html(url, directory):\n",
    "    response = requests.get(url)\n",
    "    # Create a valid filename from the URL\n",
    "    filename = urlparse(url).path.strip('/').replace('/', '_') or 'index'\n",
    "    filepath = os.path.join(directory, f\"{filename}\")\n",
    "    \n",
    "    # Save the HTML content to a file\n",
    "    with open(filepath, 'w', encoding='utf-8') as file:\n",
    "        file.write(response.text)\n",
    "    print(f\"Saved: {filepath}\")\n",
    "\n",
    "def is_internal_link(href):\n",
    "    # Parse the href to get its components\n",
    "    parsed_href = urlparse(href)\n",
    "    \n",
    "    # Check if the link is internal\n",
    "    return (\n",
    "        (not href.startswith('#')) and # Check it is not an identifier\n",
    "        (not href.startswith('tel:')) and # Check it is not a telephone number\n",
    "        (href.endswith('.html')) and # Check it is not xml\n",
    "        (parsed_href.netloc == \"\" or  # Empty netloc indicates a relative link\n",
    "        \"stallman.org\" in parsed_href.netloc)  # Netloc contains stallman.org\n",
    "    )\n",
    "\n",
    "def extract_links(url):\n",
    "    response = requests.get(url)\n",
    "    soup = BeautifulSoup(response.text, 'html.parser')\n",
    "    links = set()\n",
    "    for a_tag in soup.find_all('a', href=True):\n",
    "        href = a_tag['href']\n",
    "        if is_internal_link(href):\n",
    "            full_url = urljoin(url, href)  # Create a full URL\n",
    "            links.add(full_url)\n",
    "    return links\n",
    "\n",
    "url = \"https://stallman.org\"\n",
    "links = extract_links(url)\n",
    "directory = \"html\"\n",
    "os.makedirs(directory, exist_ok=True)\n",
    "\n",
    "# Save each link's HTML content\n",
    "for link in links:\n",
    "    save_html(link, directory)\n",
    "\n",
    "```\n",
    "\n",
    "</details>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Collecting unstructured\n",
      "  Downloading unstructured-0.18.9-py3-none-any.whl.metadata (24 kB)\n",
      "Collecting chardet (from unstructured)\n",
      "  Downloading chardet-5.2.0-py3-none-any.whl.metadata (3.4 kB)\n",
      "Collecting filetype (from unstructured)\n",
      "  Downloading filetype-1.2.0-py2.py3-none-any.whl.metadata (6.5 kB)\n",
      "Collecting python-magic (from unstructured)\n",
      "  Downloading python_magic-0.4.27-py2.py3-none-any.whl.metadata (5.8 kB)\n",
      "Collecting lxml (from unstructured)\n",
      "  Downloading lxml-6.0.0-cp310-cp310-manylinux_2_27_x86_64.manylinux_2_28_x86_64.whl.metadata (6.6 kB)\n",
      "Collecting nltk (from unstructured)\n",
      "  Downloading nltk-3.9.1-py3-none-any.whl.metadata (2.9 kB)\n",
      "Requirement already satisfied: requests in /media/nayereh/F01C24171C23D77E1/ubuntu/mine_projects/LLMs/.venv/lib/python3.10/site-packages (from unstructured) (2.32.4)\n",
      "Requirement already satisfied: beautifulsoup4 in /media/nayereh/F01C24171C23D77E1/ubuntu/mine_projects/LLMs/.venv/lib/python3.10/site-packages (from unstructured) (4.13.4)\n",
      "Collecting emoji (from unstructured)\n",
      "  Downloading emoji-2.14.1-py3-none-any.whl.metadata (5.7 kB)\n",
      "Requirement already satisfied: dataclasses-json in /media/nayereh/F01C24171C23D77E1/ubuntu/mine_projects/LLMs/.venv/lib/python3.10/site-packages (from unstructured) (0.6.7)\n",
      "Collecting python-iso639 (from unstructured)\n",
      "  Downloading python_iso639-2025.2.18-py3-none-any.whl.metadata (14 kB)\n",
      "Collecting langdetect (from unstructured)\n",
      "  Downloading langdetect-1.0.9.tar.gz (981 kB)\n",
      "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m981.5/981.5 kB\u001b[0m \u001b[31m2.7 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0ma \u001b[36m0:00:01\u001b[0m\n",
      "\u001b[?25h  Installing build dependencies ... \u001b[?25ldone\n",
      "\u001b[?25h  Getting requirements to build wheel ... \u001b[?25ldone\n",
      "\u001b[?25h  Preparing metadata (pyproject.toml) ... \u001b[?25ldone\n",
      "\u001b[?25hRequirement already satisfied: numpy in /media/nayereh/F01C24171C23D77E1/ubuntu/mine_projects/LLMs/.venv/lib/python3.10/site-packages (from unstructured) (2.2.6)\n",
      "Collecting rapidfuzz (from unstructured)\n",
      "  Downloading rapidfuzz-3.13.0-cp310-cp310-manylinux_2_17_x86_64.manylinux2014_x86_64.whl.metadata (12 kB)\n",
      "Collecting backoff (from unstructured)\n",
      "  Downloading backoff-2.2.1-py3-none-any.whl.metadata (14 kB)\n",
      "Requirement already satisfied: typing-extensions in /media/nayereh/F01C24171C23D77E1/ubuntu/mine_projects/LLMs/.venv/lib/python3.10/site-packages (from unstructured) (4.14.1)\n",
      "Collecting unstructured-client (from unstructured)\n",
      "  Downloading unstructured_client-0.39.1-py3-none-any.whl.metadata (21 kB)\n",
      "Collecting wrapt (from unstructured)\n",
      "  Downloading wrapt-1.17.2-cp310-cp310-manylinux_2_5_x86_64.manylinux1_x86_64.manylinux_2_17_x86_64.manylinux2014_x86_64.whl.metadata (6.4 kB)\n",
      "Collecting tqdm (from unstructured)\n",
      "  Using cached tqdm-4.67.1-py3-none-any.whl.metadata (57 kB)\n",
      "Requirement already satisfied: psutil in /media/nayereh/F01C24171C23D77E1/ubuntu/mine_projects/LLMs/.venv/lib/python3.10/site-packages (from unstructured) (7.0.0)\n",
      "Collecting python-oxmsg (from unstructured)\n",
      "  Downloading python_oxmsg-0.0.2-py3-none-any.whl.metadata (5.0 kB)\n",
      "Collecting html5lib (from unstructured)\n",
      "  Downloading html5lib-1.1-py2.py3-none-any.whl.metadata (16 kB)\n",
      "Requirement already satisfied: soupsieve>1.2 in /media/nayereh/F01C24171C23D77E1/ubuntu/mine_projects/LLMs/.venv/lib/python3.10/site-packages (from beautifulsoup4->unstructured) (2.7)\n",
      "Requirement already satisfied: marshmallow<4.0.0,>=3.18.0 in /media/nayereh/F01C24171C23D77E1/ubuntu/mine_projects/LLMs/.venv/lib/python3.10/site-packages (from dataclasses-json->unstructured) (3.26.1)\n",
      "Requirement already satisfied: typing-inspect<1,>=0.4.0 in /media/nayereh/F01C24171C23D77E1/ubuntu/mine_projects/LLMs/.venv/lib/python3.10/site-packages (from dataclasses-json->unstructured) (0.9.0)\n",
      "Requirement already satisfied: packaging>=17.0 in /media/nayereh/F01C24171C23D77E1/ubuntu/mine_projects/LLMs/.venv/lib/python3.10/site-packages (from marshmallow<4.0.0,>=3.18.0->dataclasses-json->unstructured) (25.0)\n",
      "Requirement already satisfied: mypy-extensions>=0.3.0 in /media/nayereh/F01C24171C23D77E1/ubuntu/mine_projects/LLMs/.venv/lib/python3.10/site-packages (from typing-inspect<1,>=0.4.0->dataclasses-json->unstructured) (1.1.0)\n",
      "Requirement already satisfied: six>=1.9 in /media/nayereh/F01C24171C23D77E1/ubuntu/mine_projects/LLMs/.venv/lib/python3.10/site-packages (from html5lib->unstructured) (1.17.0)\n",
      "Collecting webencodings (from html5lib->unstructured)\n",
      "  Downloading webencodings-0.5.1-py2.py3-none-any.whl.metadata (2.1 kB)\n",
      "Collecting click (from nltk->unstructured)\n",
      "  Downloading click-8.2.1-py3-none-any.whl.metadata (2.5 kB)\n",
      "Collecting joblib (from nltk->unstructured)\n",
      "  Downloading joblib-1.5.1-py3-none-any.whl.metadata (5.6 kB)\n",
      "Collecting regex>=2021.8.3 (from nltk->unstructured)\n",
      "  Using cached regex-2024.11.6-cp310-cp310-manylinux_2_17_x86_64.manylinux2014_x86_64.whl.metadata (40 kB)\n",
      "Collecting olefile (from python-oxmsg->unstructured)\n",
      "  Downloading olefile-0.47-py2.py3-none-any.whl.metadata (9.7 kB)\n",
      "Requirement already satisfied: charset_normalizer<4,>=2 in /media/nayereh/F01C24171C23D77E1/ubuntu/mine_projects/LLMs/.venv/lib/python3.10/site-packages (from requests->unstructured) (3.4.2)\n",
      "Requirement already satisfied: idna<4,>=2.5 in /media/nayereh/F01C24171C23D77E1/ubuntu/mine_projects/LLMs/.venv/lib/python3.10/site-packages (from requests->unstructured) (3.10)\n",
      "Requirement already satisfied: urllib3<3,>=1.21.1 in /media/nayereh/F01C24171C23D77E1/ubuntu/mine_projects/LLMs/.venv/lib/python3.10/site-packages (from requests->unstructured) (2.5.0)\n",
      "Requirement already satisfied: certifi>=2017.4.17 in /media/nayereh/F01C24171C23D77E1/ubuntu/mine_projects/LLMs/.venv/lib/python3.10/site-packages (from requests->unstructured) (2025.7.14)\n",
      "Collecting aiofiles>=24.1.0 (from unstructured-client->unstructured)\n",
      "  Downloading aiofiles-24.1.0-py3-none-any.whl.metadata (10 kB)\n",
      "Collecting cryptography>=3.1 (from unstructured-client->unstructured)\n",
      "  Downloading cryptography-45.0.5-cp37-abi3-manylinux_2_34_x86_64.whl.metadata (5.7 kB)\n",
      "Requirement already satisfied: httpx>=0.27.0 in /media/nayereh/F01C24171C23D77E1/ubuntu/mine_projects/LLMs/.venv/lib/python3.10/site-packages (from unstructured-client->unstructured) (0.28.1)\n",
      "Requirement already satisfied: nest-asyncio>=1.6.0 in /media/nayereh/F01C24171C23D77E1/ubuntu/mine_projects/LLMs/.venv/lib/python3.10/site-packages (from unstructured-client->unstructured) (1.6.0)\n",
      "Requirement already satisfied: pydantic>=2.11.2 in /media/nayereh/F01C24171C23D77E1/ubuntu/mine_projects/LLMs/.venv/lib/python3.10/site-packages (from unstructured-client->unstructured) (2.11.7)\n",
      "Collecting pypdf>=4.0 (from unstructured-client->unstructured)\n",
      "  Downloading pypdf-5.8.0-py3-none-any.whl.metadata (7.1 kB)\n",
      "Requirement already satisfied: requests-toolbelt>=1.0.0 in /media/nayereh/F01C24171C23D77E1/ubuntu/mine_projects/LLMs/.venv/lib/python3.10/site-packages (from unstructured-client->unstructured) (1.0.0)\n",
      "Collecting cffi>=1.14 (from cryptography>=3.1->unstructured-client->unstructured)\n",
      "  Downloading cffi-1.17.1-cp310-cp310-manylinux_2_17_x86_64.manylinux2014_x86_64.whl.metadata (1.5 kB)\n",
      "Collecting pycparser (from cffi>=1.14->cryptography>=3.1->unstructured-client->unstructured)\n",
      "  Downloading pycparser-2.22-py3-none-any.whl.metadata (943 bytes)\n",
      "Requirement already satisfied: anyio in /media/nayereh/F01C24171C23D77E1/ubuntu/mine_projects/LLMs/.venv/lib/python3.10/site-packages (from httpx>=0.27.0->unstructured-client->unstructured) (4.9.0)\n",
      "Requirement already satisfied: httpcore==1.* in /media/nayereh/F01C24171C23D77E1/ubuntu/mine_projects/LLMs/.venv/lib/python3.10/site-packages (from httpx>=0.27.0->unstructured-client->unstructured) (1.0.9)\n",
      "Requirement already satisfied: h11>=0.16 in /media/nayereh/F01C24171C23D77E1/ubuntu/mine_projects/LLMs/.venv/lib/python3.10/site-packages (from httpcore==1.*->httpx>=0.27.0->unstructured-client->unstructured) (0.16.0)\n",
      "Requirement already satisfied: annotated-types>=0.6.0 in /media/nayereh/F01C24171C23D77E1/ubuntu/mine_projects/LLMs/.venv/lib/python3.10/site-packages (from pydantic>=2.11.2->unstructured-client->unstructured) (0.7.0)\n",
      "Requirement already satisfied: pydantic-core==2.33.2 in /media/nayereh/F01C24171C23D77E1/ubuntu/mine_projects/LLMs/.venv/lib/python3.10/site-packages (from pydantic>=2.11.2->unstructured-client->unstructured) (2.33.2)\n",
      "Requirement already satisfied: typing-inspection>=0.4.0 in /media/nayereh/F01C24171C23D77E1/ubuntu/mine_projects/LLMs/.venv/lib/python3.10/site-packages (from pydantic>=2.11.2->unstructured-client->unstructured) (0.4.1)\n",
      "Requirement already satisfied: exceptiongroup>=1.0.2 in /media/nayereh/F01C24171C23D77E1/ubuntu/mine_projects/LLMs/.venv/lib/python3.10/site-packages (from anyio->httpx>=0.27.0->unstructured-client->unstructured) (1.3.0)\n",
      "Requirement already satisfied: sniffio>=1.1 in /media/nayereh/F01C24171C23D77E1/ubuntu/mine_projects/LLMs/.venv/lib/python3.10/site-packages (from anyio->httpx>=0.27.0->unstructured-client->unstructured) (1.3.1)\n",
      "Downloading unstructured-0.18.9-py3-none-any.whl (1.8 MB)\n",
      "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m1.8/1.8 MB\u001b[0m \u001b[31m4.1 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0ma \u001b[36m0:00:01\u001b[0mm\n",
      "\u001b[?25hDownloading backoff-2.2.1-py3-none-any.whl (15 kB)\n",
      "Downloading chardet-5.2.0-py3-none-any.whl (199 kB)\n",
      "Downloading emoji-2.14.1-py3-none-any.whl (590 kB)\n",
      "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m590.6/590.6 kB\u001b[0m \u001b[31m4.0 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
      "\u001b[?25hDownloading filetype-1.2.0-py2.py3-none-any.whl (19 kB)\n",
      "Downloading html5lib-1.1-py2.py3-none-any.whl (112 kB)\n",
      "Downloading lxml-6.0.0-cp310-cp310-manylinux_2_27_x86_64.manylinux_2_28_x86_64.whl (5.3 MB)\n",
      "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m5.3/5.3 MB\u001b[0m \u001b[31m6.5 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0ma \u001b[36m0:00:01\u001b[0m\n",
      "\u001b[?25hDownloading nltk-3.9.1-py3-none-any.whl (1.5 MB)\n",
      "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m1.5/1.5 MB\u001b[0m \u001b[31m3.9 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0ma \u001b[36m0:00:01\u001b[0m\n",
      "\u001b[?25hUsing cached regex-2024.11.6-cp310-cp310-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (781 kB)\n",
      "Downloading click-8.2.1-py3-none-any.whl (102 kB)\n",
      "Downloading joblib-1.5.1-py3-none-any.whl (307 kB)\n",
      "Downloading python_iso639-2025.2.18-py3-none-any.whl (167 kB)\n",
      "Downloading python_magic-0.4.27-py2.py3-none-any.whl (13 kB)\n",
      "Downloading python_oxmsg-0.0.2-py3-none-any.whl (31 kB)\n",
      "Downloading olefile-0.47-py2.py3-none-any.whl (114 kB)\n",
      "Downloading rapidfuzz-3.13.0-cp310-cp310-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (3.1 MB)\n",
      "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m3.1/3.1 MB\u001b[0m \u001b[31m5.5 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0ma \u001b[36m0:00:01\u001b[0mm\n",
      "\u001b[?25hUsing cached tqdm-4.67.1-py3-none-any.whl (78 kB)\n",
      "Downloading unstructured_client-0.39.1-py3-none-any.whl (212 kB)\n",
      "Downloading aiofiles-24.1.0-py3-none-any.whl (15 kB)\n",
      "Downloading cryptography-45.0.5-cp37-abi3-manylinux_2_34_x86_64.whl (4.4 MB)\n",
      "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m4.4/4.4 MB\u001b[0m \u001b[31m4.6 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0ma \u001b[36m0:00:01\u001b[0m\n",
      "\u001b[?25hDownloading cffi-1.17.1-cp310-cp310-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (446 kB)\n",
      "Downloading pypdf-5.8.0-py3-none-any.whl (309 kB)\n",
      "Downloading pycparser-2.22-py3-none-any.whl (117 kB)\n",
      "Downloading webencodings-0.5.1-py2.py3-none-any.whl (11 kB)\n",
      "Downloading wrapt-1.17.2-cp310-cp310-manylinux_2_5_x86_64.manylinux1_x86_64.manylinux_2_17_x86_64.manylinux2014_x86_64.whl (82 kB)\n",
      "Building wheels for collected packages: langdetect\n",
      "  Building wheel for langdetect (pyproject.toml) ... \u001b[?25ldone\n",
      "\u001b[?25h  Created wheel for langdetect: filename=langdetect-1.0.9-py3-none-any.whl size=993332 sha256=663f4eb266153c13f677650f341cf9b2089603cf556501b851c7e48c197c3860\n",
      "  Stored in directory: /home/nayereh/.cache/pip/wheels/95/03/7d/59ea870c70ce4e5a370638b5462a7711ab78fba2f655d05106\n",
      "Successfully built langdetect\n",
      "Installing collected packages: webencodings, filetype, wrapt, tqdm, regex, rapidfuzz, python-magic, python-iso639, pypdf, pycparser, olefile, lxml, langdetect, joblib, html5lib, emoji, click, chardet, backoff, aiofiles, python-oxmsg, nltk, cffi, cryptography, unstructured-client, unstructured\n",
      "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m26/26\u001b[0m [unstructured][0m [unstructured]client]\n",
      "\u001b[1A\u001b[2KSuccessfully installed aiofiles-24.1.0 backoff-2.2.1 cffi-1.17.1 chardet-5.2.0 click-8.2.1 cryptography-45.0.5 emoji-2.14.1 filetype-1.2.0 html5lib-1.1 joblib-1.5.1 langdetect-1.0.9 lxml-6.0.0 nltk-3.9.1 olefile-0.47 pycparser-2.22 pypdf-5.8.0 python-iso639-2025.2.18 python-magic-0.4.27 python-oxmsg-0.0.2 rapidfuzz-3.13.0 regex-2024.11.6 tqdm-4.67.1 unstructured-0.18.9 unstructured-client-0.39.1 webencodings-0.5.1 wrapt-1.17.2\n"
     ]
    }
   ],
   "source": [
    "!pip install unstructured"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "short text: \"Richard Stallman's personal site.\". Defaulting to English.\n",
      "short text: \"https://stallman.org\". Defaulting to English.\n",
      "short text: \"Kreita pro vi\". Defaulting to English.\n",
      "short text: \"verkis Richard Stallman\". Defaulting to English.\n",
      "short text: \"tradukis Jaidyn Levesque\". Defaulting to English.\n",
      "short text: \"English Original\". Defaulting to English.\n",
      "short text: \"Richard Stallman's personal site.\". Defaulting to English.\n",
      "short text: \"https://stallman.org\". Defaulting to English.\n",
      "short text: \"Puns in Italian\". Defaulting to English.\n",
      "short text: \"Listing of Picture Thumbnails\". Defaulting to English.\n",
      "short text: \"Go back\". Defaulting to English.\n"
     ]
    }
   ],
   "source": [
    "from langchain_community.document_loaders import DirectoryLoader\n",
    "from langchain_community.document_loaders import BSHTMLLoader\n",
    "\n",
    "directoryLoader = DirectoryLoader(\"data/html/\", glob=\"*.html\")\n",
    "directories = directoryLoader.load()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Richard Stallman's personal site.\n",
      "\n",
      "https://stallman.org\n",
      "\n",
      "For current political commentary, see the daily political notes.\n",
      "\n",
      "RMS's Bio | The GNU Project\n",
      "\n",
      "What's bad about: Airbnb | Amazon | Amtrak | Ancestry | Apple | Change.org | ChatGPT | Cloudflare | Discord | Ebooks | Eventbrite | Evernote | Ex-Twitter | Facebook | FLIXbus | Frito-Lay | Frontier | Google | Gofundme | Grubhub | In-N-Out Burger | Intel | LinkedIn | Lyft | Meetup | Microsoft | Netflix | Patreon | Pay Toilets | Privatization | Skype | Slack | Spotify | Tesla | Threads | Ticketmaster | Uber | Wendy's | WhatsApp | Zoom |\n",
      "\n",
      "Reasons not to buy from Amazon\n",
      "\n",
      "If you want to order a book (or something else), don't buy it from Amazon. Amazon harms its customers, as well as workers, the national treasury, and many others that it affects.\n",
      "\n",
      "Here's a good (though long) overview of why Amazon's overall activity is harmful to society overall.\n",
      "\n",
      "This page lists alternatives to Amazon for buying various kinds of products. These sites may share some of Amazon's unethical practices: identifying each custoimer and requiring per to run nonfree software (JavaSccript code sent to the browser). I refuse to do those things, so I do not use use any of those sites. But they may not be evil in some of the ways that Amazon is.\n",
      "\n",
      "To avoid being the victim of digital injustice, buy from a physical store, paying cash, anonymously. That is what I do.\n",
      "\n",
      "For videos, you can get a DVD. It may have DRM (always an injustice in itself), but at least there is free software to break the DRM on DVDs. However, it is morally better to get a non-oppressive copy through sharing.\n",
      "\n",
      "For a printed book, order it directly from the publisher or through a local book store. A local independent book store lets me pay cash in advance to order a book, and not identify myself.\n",
      "\n",
      "If you want to use a URL to identify a book, please don't use an Amazon page! Doing so promotes Amazon.\n",
      "\n",
      "Robert Reich presents how Amazon uses its monopoly power to screw the independent sellers that find themselves effectively compelled to sell through Amazon -- and their customers too. The FTC is suing Amazon over this. Hooray for the FTC, but remember that Amazon surveillance is direct injustice to each customer, independent of its purely economic wrongs.\n",
      "\n",
      "Here are other specific reasons — plenty of them.\n",
      "\n",
      "Anticompetitive practices\n",
      "\n",
      "Size\n",
      "\n",
      "Sabotaging customers\n",
      "\n",
      "Limiting the use of cash\n",
      "\n",
      "Restricting and shafting customers\n",
      "\n",
      "Censorship\n",
      "\n",
      "Snooping\n",
      "\n",
      "Exploiting workers mercilessly\n",
      "\n",
      "Shafting others in the publishing world\n",
      "\n",
      "Dodging taxes\n",
      "\n",
      "Vendors\n",
      "\n",
      "Other reasons\n",
      "\n",
      "anticompetitive\n",
      "\n",
      "Robert Reich summarizes how Amazon uses its monopoly power to screw the independent sellers that find themselves effectively compelled to sell through Amazon &href; and their customers too. The FTC is suing Amazon over this.\n",
      "\n",
      "This video from More Perfect Union further explains some of the subtle and indirect ways Amazon utilizes its monopoly power, which you might not guess.\n",
      "\n",
      "Size\n",
      "\n",
      "Amazon is so close to being a monopoly for internet sales by most companies that it can gouge them. It drives many of them into bankruptcy.\n",
      "\n",
      "If you do internet purchases, making a point of not buying through Amazon is a way you can personally push back.\n",
      "\n",
      "*Amazon, Google parent Alphabet and Microsoft are being sued over images used to train their facial recognition technologies.*\n",
      "\n",
      "Amazon biases its searches to favor vendors that use Amazon for their shipping.\n",
      "\n",
      "If this isn't illegal, it ought to be. We should not allow a store as big as Amazon to have anything to do with order fulfillment, for its own sales or anyone else's.\n",
      "\n",
      "Amazon has so much power over the US retail economy that it imposes its power over all participants.\n",
      "\n",
      "If it is going to be a monopoly, it should be regulated like other monopolies. Or perhaps more.\n",
      "\n",
      "Amazon has so much market share that its sheer size distorts the market.\n",
      "\n",
      "We should not allow a company to have a share over around 10% of any market. If in a certain field a single dominant company is beneficial for society, that means it is a natural monopoly, and should be served by a regulated utility.\n",
      "\n",
      "Sabotaging Customers\n",
      "\n",
      "Amazon offered a \"30-day free trial\", and started paid subscriptions automatically at the end of it.\n",
      "\n",
      "This is clearly an attempt to trick customers — wrong in all cases no matter how many companies do it.\n",
      "\n",
      "Amazon's persistent blindness to certain fraudulent sales schemes makes it easy for fraudsters to invalidate Amazon's guarantee to purchasers.\n",
      "\n",
      "Amazon closes the accounts of customers that send back a substantial fraction of products they buy. It has the additional effect of stealing any credit balance.\n",
      "\n",
      "Amazon appears to have cooperated with the US government to intercept a Thinkpad keyboard purchased by a Tor developer. To install a spy device, presumably.\n",
      "\n",
      "Amazon delays order processing for customers that have not paid a subscription fee for \"prime\" delivery.\n",
      "\n",
      "Amazon locks in customers by getting them to pay in advance for \"free shipping\". Then it makes sellers raise their prices so they can pay to \"qualify for prime\", and to do that, they have to charge even higher prices in any other store.\n",
      "\n",
      "Limiting the use of Cash\n",
      "\n",
      "Amazon's new grocery stores do not accept cash. They impose the same surveillance as ordering online from Amazon.\n",
      "\n",
      "In addition, success of this would mean the loss of thousands of jobs.\n",
      "\n",
      "Restricting and Shafting Customers\n",
      "\n",
      "The ACLU's criticisms of Amazon's private internet, \"Sidewalk\".\n",
      "\n",
      "Amazon distributes ebooks in a way that strips users of many freedoms (PDF or html).\n",
      "\n",
      "Amazon's on-line music \"sales\" have some of the same problems as the ebooks: users are required to identify themselves and sign a contract that denies them the freedoms they would have with a CD.\n",
      "\n",
      "The Amazon Swindle has a back door that can erase books. We found out about this when Amazon remotely erased thousands of copies of 1984. In response to criticism, Amazon promised it would never do this again unless ordered to by the state, which I find not very comforting.\n",
      "\n",
      "Amazon did not keep that promise. In 2012 it wiped a user's Kindle and deleted her account, then offered her kafkaesque \"explanations\".\n",
      "\n",
      "The Swindle has a universal back door through which that Amazon can forcibly change the software. This is called \"auto-update\". It puts the user helplessly at Amazon's mercy.\n",
      "\n",
      "Amazon's book recommendations are not based honestly on algorithms that try to figure out what users might like. Publishers pay to have their books promoted this way.\n",
      "\n",
      "Amazon rents textbooks to students with a requirement not to take them across state lines.\n",
      "\n",
      "Amazon turns servile US public libraries into retail agents. Users have to register with Amazon and give their own email addresses. Then they get mail like this.\n",
      "\n",
      "Subject:       Your digital library loan expires soon\n",
      "Date:   Sat, 13 Sep 2014 ...\n",
      "From:   digital-noreply@amazon.com\n",
      "To:     LIBRARY-USER'S-EMAIL-ADDRESS\n",
      "\n",
      "\n",
      "\n",
      "        Your digital library loan will expire in 3 days\n",
      "\n",
      "Hello LIBRARY-USER'S-NAME\n",
      "Your digital library book will expire in 3 days. If you purchase\n",
      "/BOOK/ from the Kindle Store or borrow it again from your local\n",
      "library, all of your notes and highlights will be preserved.\n",
      "BOOK\n",
      "(Author) AUTHOR\n",
      "<http://www.amazon.com/gp/product/PAGE>\n",
      "\n",
      "Amazon \"sold\" someone Disney Christmas videos (via remote access, not a local copy); subsequently Amazon, at Disney's command, cut off access for Christmas. This demonstrates why we should not trust remote hosting for copies of published works. Insist on having your own copy which is yours.\n",
      "\n",
      "Amazon's service, that offers you an MP3 for CDs you bought there, respects your rights less than ripping the CDs yourself.\n",
      "\n",
      "Amazon's complex financial arrangements bypass UK credit card consumer protection.\n",
      "\n",
      "Amazon closes customers' accounts, which implies confiscating their money, if they return too many defective products.\n",
      "\n",
      "The company refuses even to discuss why.\n",
      "\n",
      "Amazon threatens to cut off customers if they return things more than occasionally. Amazon's customers nominally have the right to return merchandise — unless they exercise that right.\n",
      "\n",
      "The strange irony of the article is that it is totally defeatist. It shows why we need to defeat Amazon, but assumes that that is impossible. It shows becoming dependent on Amazon is dangerous and then refuses to believe people could ever refuse.\n",
      "\n",
      "You can't win by being defeatist. You can win by telling Amazon to drop dead.\n",
      "\n",
      "I have never bought anything from Amazon. And I never will. Amazon knows my name because a friend, believing this was helpful, decided to get something for me and told Amazon to send it to my address, an act which made me feel violated. I hope nothing like that will ever happen again.\n",
      "\n",
      "Censorship\n",
      "\n",
      "Amazon and Google have cut off domain-fronting, a feature used to enable people in tyrannical countries to reach communication systems that are banned there.\n",
      "\n",
      "Amazon has joined with the MPAA to campaign for repression of sharing on the net.\n",
      "\n",
      "Amazon cut off service to Wikileaks, claiming that whistleblowing violates its terms of service. It had no need to go to court to prove this, because if you rent a server from Amazon, you have no enforcible legal right to use it.\n",
      "\n",
      "Amazon stopped distribution of an ebook that exposed how ebook bestseller lists can be manipulated (and are therefore meaningless).\n",
      "\n",
      "Snooping\n",
      "\n",
      "Amazon regularly gives Ring door camera videos to the government without getting permission from the camera's nominal owner.\n",
      "\n",
      "This is a secondary wrong which makes those cameras a little more unjust. But they would be plenty unjust without this. When millions of people make videos of everyone that walks past their door, and hand the recordings over to a particular company to store, that's asking for abuse of the recordings. That kind of system should be prohibited.\n",
      "\n",
      "Basically, you should be required to set up the camera so that it only sees people when they approach your door, not when they pass by on the sidewalk.\n",
      "\n",
      "Amazon offers several new surveillance microphone products, meant to be carried around by people during daily life. That will enable them to listen to whoever the device's \"owner\" comes near.\n",
      "\n",
      "But don't worry — Amazon is learning how to talk the talk about privacy in a way that more people would find comforting.\n",
      "\n",
      "A voice command system that is safe for its owner would be one that runs only free software, and does the whole job locally, communicating with other sites only when asked to. With the software inside free, the owner of this device would truly own it.\n",
      "\n",
      "But even that would not respect the privacy of other people nearby. How to deal with that issue is not obvious.\n",
      "\n",
      "The Amazon Echo seems to have a universal back door, which means that Amazon could convert it into full-time listening device at any time.\n",
      "\n",
      "Since Amazon requires customers to identify themselves, it knows what each one has bought. That in itself is unacceptable, especially for books. I pay for books with cash only, and do not identify myself to any bookseller that takes note of which books I bought.\n",
      "\n",
      "The Kindle Swindle informs Amazon when the user reads books that didn't come from Amazon. It also tells Amazon which pages each user reads.\n",
      "\n",
      "The Amazon \"Smart\" TV is watching and listening all the time.\n",
      "\n",
      "Emo Phillips once made this joke: The other day a woman came up to me and said, \"Didn't I see you on television?\" I said, \"I don't know. You can't see out the other way.\" Evidently Amazon has made that joke obsolete.\n",
      "\n",
      "The Amazon Echo Dot is designed to accustom children to surveillance-based marketing from a young age.\n",
      "\n",
      "Amazon is in such a position of surveillance that it can exert substantial control over people's activities.\n",
      "\n",
      "This is dangerous, and we should not allow Amazon to continue to track people as it does.\n",
      "\n",
      "Facebook made a secret deal with Amazon to give Amazon access to Facebook's data about users. A plague on both of those companies!\n",
      "\n",
      "Amazon and Google want \"smart\" gadgets to report all activity to them.\n",
      "\n",
      "In other words, if you have a \"smart\" (read \"spy\") lightbulb with that proposed feature, and tell an Amazon or Google listening device about it, thenceforth any time you switched it on or off no matter how, it would send a report to Amazon or Google.\n",
      "\n",
      "Even today, the only way to make \"smart\" products safe is to ensure they cannot connect to anyone else's systems.\n",
      "\n",
      "Amazon keeps Alexa recordings and transcripts indefinitely.\n",
      "\n",
      "Amazonâs Ring Planned Neighborhood \"Watch Lists\" Built on Facial Recognition.*\n",
      "\n",
      "Amazon gets access to video from Ring devices.\n",
      "\n",
      "This was highlighted by the fact that some Ring employees who were authorized to look at the videos used that access for personal motives and were fired. There will always be employees who do this, and with Ring the uniformed thugs often can do it too, which is far more dangerous.\n",
      "\n",
      "Amazon is considering adding face recognition and license plate recognition to Ring surveillance cameras.\n",
      "\n",
      "Setting up a system capable of systematic recognition of faces — or license plates — should be illegal, outside of very narrow circumstances.\n",
      "\n",
      "*Amazon to Delivery Drivers: Agree to Be Spied On Biometrically or You're Fired.*\n",
      "\n",
      "Here's what data Amazon admits collecting from people that do business with it.\n",
      "\n",
      "How to stop it? That's easy. First, don't buy from Amazon. Second, ask your friends not to give Amazon your name, address, or anything else. If that has already happened, that doesn't mean you have to let it happen again!\n",
      "\n",
      "I can testify that it isn't hard, because I do that for _all_ online stores. The only exception I make is for prescriptions, since those have to be in my name.\n",
      "\n",
      "The extra level of boycott that I do against Amazon is that, if someone is going to buy something for me -- either as a gift, or as a favor which I'm going to reimburse -- I say, \"Please do _not_ get it from Amazon!\"\n",
      "\n",
      "Exploiting workers mercilessly\n",
      "\n",
      "Amazon warehouse workers have walked out of the job, saying that the wages are too low to live on, and that management is demanding that they work ever harder and faster, discarding safety precautions.\n",
      "\n",
      "Bezos intentionally made Amazon drive warehouse workers so hard that each week 3% quit. The aim was to make them work desperately hard. By 2024, Amazon will have hired and driven away all available workers.\n",
      "\n",
      "It could try giving its workers decent pay and working conditions. Then they might continue working for Amazon.\n",
      "\n",
      "Amazon warehouse workers have almost double the rate of work injuries typical in other warehouses.\n",
      "\n",
      "This adds to the many other reasons not to buy from Amazon.\n",
      "\n",
      "Amazon treats warehouse workers so badly that on the average they leave after 8 months\n",
      "\n",
      "*Amid Deadly Tornado, Texts Show Amazon Threatened to Fire Driver If Packages Not Delivered.*\n",
      "\n",
      "Amazon must eliminate the tight control that treats workers as robots, and injures them along the way.\n",
      "\n",
      "Amazon's drivers don't have access to toilets while they work, so they have to pee in bottles in the truck. Amazon claimed this is not so, but an internal memo shows it was lying.\n",
      "\n",
      "Remote work has led to a great jump in remote surveillance of workers. They can be monitored far more than they were in the office.\n",
      "\n",
      "Amazon is putting cameras in delivery vans to monitor drivers. I hope the drivers go on a camera strike, all covering the cameras on the same day.\n",
      "\n",
      "*Amazon Hired Koch-Backed Anti-Union Consultant to Fight Alabama Warehouse Organizing.*\n",
      "\n",
      "Leaked 2019 documents detail how Amazon spies on environmentalists and workers' organizing.\n",
      "\n",
      "This includes using predictive policing to inflitrate possible union hot-spots and smear or harass employees who are liable to speak up about those issues.\n",
      "\n",
      "Amazon's warehouse robots impose a high pace of work on the humans that still work there. Apparently Amazon has cut their numbers too far.\n",
      "\n",
      "Revealed: Amazon Employees Are Left to Suffer After Workplace Injuries.\n",
      "\n",
      "Amazon warehouse workers say they are forced to speed up and ignore safety rules.\n",
      "\n",
      "Amazon seems to organize some of its warehouse workers to say good things about their work. Remarkably similar good things.\n",
      "\n",
      "Is Amazon paying them? Threatening them?\n",
      "\n",
      "Hello, Alexa, were you made in a Chinese sweatshop?\n",
      "\n",
      "Working in an Amazon warehouse is like being in prison with a sentence of hard and hurried labor.\n",
      "\n",
      "The workers don't have breaks even enough to go to the toilet.\n",
      "\n",
      "The workers in Amazon's warehouses are so remote-controlled that they are effectively robots human brains inside.\n",
      "\n",
      "Amazon Workers Sleep in Tents Near Firm's Scottish Depot to Avoid Travel Costs.\n",
      "\n",
      "Amazon works its warehouse staff to the point of sickness and even death.\n",
      "\n",
      "When workers at Amazon are injured, Amazon shafts them.\n",
      "\n",
      "Amazon's shipping in the US is done in a sweatshop with paramedics standing by for workers who pass out from the heat.\n",
      "\n",
      "Workers in an Amazon warehouse and shipping center walk all day under the orders of a computer, and are forbidden even to speak to each other.\n",
      "\n",
      "A stress expert, looking at an undercover report about an Amazon warehouse, says these conditions make physical and mental illness more likely.\n",
      "\n",
      "Working for Amazon makes staff physically and mentally ill.\n",
      "\n",
      "Amazon pressures its \"self-employed\" delivery drivers to drive without seat belts; they aren't given time to go to the toilet so they have to piss and defacate in the car.\n",
      "\n",
      "This is perhaps not as bad for the individual as being unemployed, which is what they will become when Amazon gets driverless delivery vans. But that does not make it acceptable.\n",
      "\n",
      "Amazon pays Mechanical Turk workers as little as 2 dollars an hour, making the excuse that they are \"independent contractors\".\n",
      "\n",
      "More on the horrible treatment of its workers.\n",
      "\n",
      "When James Bloodworth investigated the Amazon warehouse by working in it, he found that no workers lasted the 9 months required to become regular employees.\n",
      "\n",
      "It's not enough for the workers to do their jobs; they are also required to spout the ideology of devotion to the company.\n",
      "\n",
      "As of 2018, 1/3 of Amazon employees in Arizona get food stamps, their pay is so low. In some other states, it's only 1/9 that get food stamps.\n",
      "\n",
      "Amazon's office workers are better paid but they have to work 80 hours a week. That's even more time than I spend volunteering!\n",
      "\n",
      "Only a union could stop Amazon's persistent mistreatment of its workers.\n",
      "\n",
      "Someone with very little will-power has decided to resist Amazon because of how it underpays workers.\n",
      "\n",
      "US Postal Service workers deliver lots of packages for Amazon, especially on Sundays. You can imagine how they are mistreated: some \"part time\" workers have to go weeks without a day off. The speedup is so intense that following the official safety procedures is not feasible.\n",
      "\n",
      "Amazon doesn't take responsibility for those problems.\n",
      "\n",
      "*'Amazon Putting Lives of Workers at Risk': Omar and Sanders Press Bezos on Alarming Lack of Coronavirus Protections.*\n",
      "\n",
      "Amazon fired the worker who organized Amazon warehouse workers to go on strike demanding equipment to avoid transmitting Covid-19, as well as decent pay.\n",
      "\n",
      "Amazon advertised for staff to interfere with union organizing.\n",
      "\n",
      "Amazon later said that ad was posted \"in error\", which probably means the hiring was supposed to be done quietly. Amazon has long made a practice of monitoring staff's discussions about unionization.\n",
      "\n",
      "\"Tips\" to Doordash and Amazon food delivery workers go to the company rather than to the worker, they cancel out the whole of the worker's base pay.\n",
      "\n",
      "The article seems to err in equating this to tipping of waiters. They are not the same system. Yes, the waiter's base pay is below minimum wage — but the restaurant does not claw back that base pay when the waiter gets a tip, as Doordash and Amazon do.\n",
      "\n",
      "If you are thinking of buying a holiday present from Amazon, look at the crushing treatment of workers that you'd be supporting.\n",
      "\n",
      "Amazon's harsh working conditions and workloads result in a rate of injury 50% higher than in competing companies.\n",
      "\n",
      "Shafting others in the publishing world\n",
      "\n",
      "Amazon squeezes small publishers. For instance, Amazon cut off Swindle sales for an independent book distributor in order to press for bigger discounts. (The article ends by promoting ebooks for another platform, the Shnook from Barnes and Noble. While that company is not as nasty to small publishers, its ebooks do violate your freedom in most of the same ways.)\n",
      "\n",
      "Amazon doesn't just compete with independent book stores, it arrogantly seeks to destroy them. Independent book stores urge people not to buy from Amazon.\n",
      "\n",
      "Amazon appears to treat self-published authors well, but it can unilaterally cut the price of their books. And when it does, the authors are the ones who lose.\n",
      "\n",
      "Amazon is lowering the pay for short self-published works by changing to pay per page read (sometimes as low as $0.006 per page).\n",
      "\n",
      "Amazon is bad for books and writing.\n",
      "\n",
      "Amazon is demonstrating its dangerous power by punishing one publisher with all sorts of unofficial discouragements to buy.\n",
      "\n",
      "We should not allow any bookstore to be as big as Amazon.\n",
      "\n",
      "Amazon's hardball tactics against a publisher show its dangerous power.\n",
      "\n",
      "Not that Hachette deserves any sympathy. The point is that we need to break Amazon's power.\n",
      "\n",
      "Dodging taxes\n",
      "\n",
      "All hail Jeff Bezos the philanthropist! The rest of us will just keep paying our taxes.*\n",
      "\n",
      "Bezos thanked Manchin for blocking a tax increase on corporations.\n",
      "\n",
      "At least 10% of Amazon's success is due to avoiding the taxes that physical book stores pay.\n",
      "\n",
      "Amazon's tax avoidance means it sucks money out of your country's economy.\n",
      "\n",
      "Amazon charges publishers for 20% sales tax in the UK even though the tax it pays is 3%.\n",
      "\n",
      "UK independent bookstores condemn Amazon for not paying taxes as they do.\n",
      "\n",
      "Amazon reorganized its EU structure in 2015 so it will pay a little tax on its sales to EU countries, but not much.\n",
      "\n",
      "Amazon bullied Seattle into retracting a tax increase by threatening to abandon expansion plans there. Seattle caved in, but Amazon has cancelled the plans anyway.\n",
      "\n",
      "Amazon is not merely an snooping abusive monopolist. It is a cheating snooping abusive monopolist.\n",
      "\n",
      "Vendors\n",
      "\n",
      "(2023) Amazon's new anti-competitive requirement: sellers who don't pay for Amazon to ship their products are now required to pay for not doing so.\n",
      "\n",
      "Campaigners are suing Amazon for a practice promoting \"special offers\" that are not actually better deals for the customer, but are presented to give the impression that they are better deals.\n",
      "\n",
      "\"Gators\" are companies that buy many small manufacturers that sell on Amazon.\n",
      "\n",
      "The gator is better placed to stand up to Amazon's bullying than a small manufacturer, but the result is a second layer of oligopoly.\n",
      "\n",
      "*Amazon bullies partners and vendors, says antitrust subcommittee.*\n",
      "\n",
      "Amazon sometimes chooses an expensive vendor by default — when the vendor pays for this preference.\n",
      "\n",
      "Other reasons\n",
      "\n",
      "Amazon is suing to eliminate the National Labor Relations Board.\n",
      "\n",
      "Amazon has published guides to identifying mushrooms which were written by language models that have no intelligence and could lead people to poison themselves.\n",
      "\n",
      "Please do not refer to such bullshit-generator systems as \"artificial intelligence\"!\n",
      "\n",
      "The Federal Trade Commission accuses Amazon of tricking millions of customers into subscribing to Amazon Prime, using a dark pattern, and then using another dark pattern to impede them from cancelling.\n",
      "\n",
      "I Want You Back: Getting My Personal Data From Amazon Was Weeks of Confusion and Tedium.* It uses a dark pattern to make it slow and inconvenient.\n",
      "\n",
      "Amazon collaborated actively with Chinese propaganda to get authorization to sell in China.\n",
      "\n",
      "Amazon's lobbying, and funds to buy legislators, has killed many US state bills to increase privacy requirements.\n",
      "\n",
      "*Amazon's apparent embrace of plastic packaging is hindering its commitment to help the fight against [climate disaster].*\n",
      "\n",
      "Amazon has a special store for selling \"eco-friendly products\".\n",
      "\n",
      "This is sadly ironic, because buying them via Amazon is not eco-friendly.\n",
      "\n",
      "Amazon is creating subsidiaries that act like \"third-party\" sellers, to compete with the real third-party sellers.\n",
      "\n",
      "This is one more example of how Amazon cooperates with various other parties so as to get more power, then betrays them. Amazon has done wrong to readers, authors, bookstores, as well as its workers. And now to the companies that accepted it as a nearly-monopolistic market.\n",
      "\n",
      "Amazon has been caught cheating against companies that sell through Amazon, by using data about their sales to compete with them.\n",
      "\n",
      "Due to a paywall, I cannot access the article that reported on this, and even if I saw a copy I would not post a reference to it. But I am confident that it would not have reported this without convincing evidence.\n",
      "\n",
      "Amazon supports Breitbart, the right-wing extremist site, by advertising there.\n",
      "\n",
      "Amazon in Germany hired \"security\" guards from a company of Nazi sympathizers to repress foreign workers. Reporters came to cover this, and the guards tried to arrest them and take their cameras.\n",
      "\n",
      "After a bug in software Amazon's servers used caused Amazon to sell many products for one penny, Amazon takes no responsibility and dumped the loss on the sellers.\n",
      "\n",
      "Amazon was a member of ALEC. ALEC is the right-wing lobbying group that promotes voter-suppression laws and \"shoot first\" laws, as well as attacks against wages and working conditions in the US.\n",
      "\n",
      "Amazon quit ALEC after public pressure in May 2012, but I am sure it still supports the same nasty policies and is waiting for a new tool to achieve them.\n",
      "\n",
      "A study found that people who read novels on the Amazon Swindle remember less of the the events in the novel.\n",
      "\n",
      "I think issues like this are less important than the injustice of the Swindle.\n",
      "\n",
      "Amazon heavily promotes medical quackery.\n",
      "\n",
      "When people return products to Amazon, in many cases Amazon doesn't bother to unpack them and put them on the shelf. It puts them in the trash.\n",
      "\n",
      "Amazon has made it painfully difficult to terminate membership in Amazon Prime.\n",
      "\n",
      "Amazon collects data about everything a user does while looking at amazon.com, and uses this to compete unfairly with the independent companies that sell across amazon.com.\n",
      "\n",
      "Copyright (C) 2011-2022 Richard Stallman\n",
      "\n",
      "Verbatim copying and redistribution of this entire page are permitted, provided this notice is preserved\n"
     ]
    }
   ],
   "source": [
    "print(directories[2].page_content)\n",
    "html_docs = directories # TODO: Load the HTML files in the html directory"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Number of pages (loaded Document objects): 179\n"
     ]
    }
   ],
   "source": [
    "print(\"Number of pages (loaded Document objects):\", len(html_docs))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<h2 dir=rtl align=right style=\"line-height:200%;font-family:vazir;color:#0099cc\">\n",
    "<font face=\"vazir\" color=\"#0099cc\">\n",
    "جداسازی اسناد\n",
    "</font>\n",
    "</h2>\n",
    "\n",
    "<p dir=rtl style=\"direction: rtl; text-align: justify; line-height:200%; font-family:vazir; font-size:medium\">\n",
    "<font face=\"vazir\">\n",
    "احتمالاً طبق بررسی اسناد متوجه شده‌اید که برخی از آن‌ها ممکن است طولانی باشند و بهتر است که آن‌ها را به قطعات کوچک‌تری بشکنیم. پس در این مرحله با استفاده از روش‌های جداسازی اسناد به شکستن آن‌ها بپردازید. اگر می‌خواهید این کار را بر روی تمام اسناد خود انجام دهید می‌توانید ابتدا تمام آن‌ها در یک لیست واحد ریخته و سپس تابع مورد نظر را اعمال کنید.\n",
    "</font>\n",
    "</p>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The number of splitted documents: 6053\n"
     ]
    }
   ],
   "source": [
    "from langchain_text_splitters import RecursiveCharacterTextSplitter\n",
    "\n",
    "all_docs = pdf_docs + web_docs + wiki_docs + html_docs\n",
    "\n",
    "recursive_splitter = RecursiveCharacterTextSplitter(chunk_size=500, chunk_overlap=50)\n",
    "splitted_docs = recursive_splitter.split_documents(all_docs) # TODO: Split the documents into smaller chunks\n",
    "\n",
    "print('The number of splitted documents:', len(splitted_docs))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<h2 dir=rtl align=right style=\"line-height:200%;font-family:vazir;color:#0099cc\">\n",
    "<font face=\"vazir\" color=\"#0099cc\">\n",
    "تعبیه‌سازی و مخزن برداری\n",
    "</font>\n",
    "</h2>\n",
    "\n",
    "<p dir=rtl style=\"direction: rtl; text-align: justify; line-height:200%; font-family:vazir; font-size:medium\">\n",
    "<font face=\"vazir\">\n",
    "برای آن‌که بتوانیم اسناد مرتبط با پرسش کاربر را پیدا کردیم یا به‌اصطلاح جست‌وجوی معنایی انجام دهیم نیاز است که آن‌ها را به‌شکل بردارهای عددی تعبیه کرده و در یک مخزن برداری ذخیره کنیم. در این مرحله می‌توانید از هر مدل تعبیه‌سازی که می‌خواهید استفاده کنید. با این حال به چندزبانه بودن اسناد توجه داشته باشید و ترجیحاً از یک مدل چندزبانه استفاده کنید یا این‌که تکنیکی برای رفع این چالش بیابید.\n",
    "</font>\n",
    "</p>\n",
    "\n",
    "<p dir=rtl style=\"direction: rtl; text-align: justify; line-height:200%; font-family:vazir; font-size:medium\">\n",
    "<font face=\"vazir\">\n",
    "<span style=\"color:orange\"><b>نکته‌ی ۱:</b></span>\n",
    "اگر قصد دارید از مدل‌های تعبیه‌ساز <i>Cohere</i> استفاده کنید به محدودیت تعداد درخواست ماهانه توجه داشته باشید. ممکن است که اگر چند مرحله این بخش را تکرار کنید حد مجاز تعداد درخواست را رد کنید. یک راه‌حل این است که در صورت وقوع محدودیت از یک حساب جدید استفاده کنید یا این‌که در زمان پیاده‌سازی اولیه و آزمایش کدهای خود از یک مدل دیگر همچون مدل‌های موجود در هاگینگ‌فیس بهره ببرید و وقتی‌که مطمئن شدید همه‌چیز به‌درستی کار می‌کند به‌سراغ آزمایش این مدل بروید.\n",
    "</font>\n",
    "</p>\n",
    "\n",
    "<p dir=rtl style=\"direction: rtl; text-align: justify; line-height:200%; font-family:vazir; font-size:medium\">\n",
    "<font face=\"vazir\">\n",
    "<span style=\"color:orange\"><b>نکته‌ی ۲:</b></span>\n",
    "اگر تصمیم گرفتید که از مدل‌های هاگینگ‌فیس بهره ببرید اکیداً پیشنهاد می‌کنیم که کدهای خود را بر بستر گوگل کولب اجرا کنید تا با مشکلات نصب کتابخانه‌ها و همچنین محدودیت‌های سخت‌افزاری مواجه نشوید. در این‌صورت فراموش نکنید که قابلیت <code>GPU</code> کولب را فعال کرده باشید.\n",
    "</font>\n",
    "</p>\n",
    "\n",
    "<p dir=rtl style=\"direction: rtl; text-align: justify; line-height:200%; font-family:vazir; font-size:medium\">\n",
    "<font face=\"vazir\">\n",
    "<span style=\"color:red\"><b>توجه:</b></span>\n",
    "در هنگام ساخت مخزن برداری فراموش نکنید که آرگومان <code>persist_directory</code> را مقداردهی کرده باشید تا مطمئن شوید که اسناد و تعبیه‌ها ذخیره می‌شوند. در این‌صورت دیگر در استفاده‌های بعدی از کدهای‌تان نیاز به تعبیه‌سازی مجدد اسناد نخواهید داشت.\n",
    "</font>\n",
    "</p>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "import getpass\n",
    "import os\n",
    "\n",
    "os.environ[\"COHERE_API_KEY\"] = getpass.getpass()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: cohere in /media/nayereh/F01C24171C23D77E1/ubuntu/mine_projects/LLMs/.venv/lib/python3.10/site-packages (5.16.1)\n",
      "Requirement already satisfied: langchain-cohere in /media/nayereh/F01C24171C23D77E1/ubuntu/mine_projects/LLMs/.venv/lib/python3.10/site-packages (0.4.4)\n",
      "Requirement already satisfied: fastavro<2.0.0,>=1.9.4 in /media/nayereh/F01C24171C23D77E1/ubuntu/mine_projects/LLMs/.venv/lib/python3.10/site-packages (from cohere) (1.11.1)\n",
      "Requirement already satisfied: httpx>=0.21.2 in /media/nayereh/F01C24171C23D77E1/ubuntu/mine_projects/LLMs/.venv/lib/python3.10/site-packages (from cohere) (0.28.1)\n",
      "Requirement already satisfied: httpx-sse==0.4.0 in /media/nayereh/F01C24171C23D77E1/ubuntu/mine_projects/LLMs/.venv/lib/python3.10/site-packages (from cohere) (0.4.0)\n",
      "Requirement already satisfied: pydantic>=1.9.2 in /media/nayereh/F01C24171C23D77E1/ubuntu/mine_projects/LLMs/.venv/lib/python3.10/site-packages (from cohere) (2.11.7)\n",
      "Requirement already satisfied: pydantic-core<3.0.0,>=2.18.2 in /media/nayereh/F01C24171C23D77E1/ubuntu/mine_projects/LLMs/.venv/lib/python3.10/site-packages (from cohere) (2.33.2)\n",
      "Requirement already satisfied: requests<3.0.0,>=2.0.0 in /media/nayereh/F01C24171C23D77E1/ubuntu/mine_projects/LLMs/.venv/lib/python3.10/site-packages (from cohere) (2.32.4)\n",
      "Requirement already satisfied: tokenizers<1,>=0.15 in /media/nayereh/F01C24171C23D77E1/ubuntu/mine_projects/LLMs/.venv/lib/python3.10/site-packages (from cohere) (0.21.2)\n",
      "Requirement already satisfied: types-requests<3.0.0,>=2.0.0 in /media/nayereh/F01C24171C23D77E1/ubuntu/mine_projects/LLMs/.venv/lib/python3.10/site-packages (from cohere) (2.32.4.20250611)\n",
      "Requirement already satisfied: typing_extensions>=4.0.0 in /media/nayereh/F01C24171C23D77E1/ubuntu/mine_projects/LLMs/.venv/lib/python3.10/site-packages (from cohere) (4.14.1)\n",
      "Requirement already satisfied: charset_normalizer<4,>=2 in /media/nayereh/F01C24171C23D77E1/ubuntu/mine_projects/LLMs/.venv/lib/python3.10/site-packages (from requests<3.0.0,>=2.0.0->cohere) (3.4.2)\n",
      "Requirement already satisfied: idna<4,>=2.5 in /media/nayereh/F01C24171C23D77E1/ubuntu/mine_projects/LLMs/.venv/lib/python3.10/site-packages (from requests<3.0.0,>=2.0.0->cohere) (3.10)\n",
      "Requirement already satisfied: urllib3<3,>=1.21.1 in /media/nayereh/F01C24171C23D77E1/ubuntu/mine_projects/LLMs/.venv/lib/python3.10/site-packages (from requests<3.0.0,>=2.0.0->cohere) (2.5.0)\n",
      "Requirement already satisfied: certifi>=2017.4.17 in /media/nayereh/F01C24171C23D77E1/ubuntu/mine_projects/LLMs/.venv/lib/python3.10/site-packages (from requests<3.0.0,>=2.0.0->cohere) (2025.7.14)\n",
      "Requirement already satisfied: huggingface-hub<1.0,>=0.16.4 in /media/nayereh/F01C24171C23D77E1/ubuntu/mine_projects/LLMs/.venv/lib/python3.10/site-packages (from tokenizers<1,>=0.15->cohere) (0.33.4)\n",
      "Requirement already satisfied: filelock in /media/nayereh/F01C24171C23D77E1/ubuntu/mine_projects/LLMs/.venv/lib/python3.10/site-packages (from huggingface-hub<1.0,>=0.16.4->tokenizers<1,>=0.15->cohere) (3.18.0)\n",
      "Requirement already satisfied: fsspec>=2023.5.0 in /media/nayereh/F01C24171C23D77E1/ubuntu/mine_projects/LLMs/.venv/lib/python3.10/site-packages (from huggingface-hub<1.0,>=0.16.4->tokenizers<1,>=0.15->cohere) (2025.7.0)\n",
      "Requirement already satisfied: packaging>=20.9 in /media/nayereh/F01C24171C23D77E1/ubuntu/mine_projects/LLMs/.venv/lib/python3.10/site-packages (from huggingface-hub<1.0,>=0.16.4->tokenizers<1,>=0.15->cohere) (25.0)\n",
      "Requirement already satisfied: pyyaml>=5.1 in /media/nayereh/F01C24171C23D77E1/ubuntu/mine_projects/LLMs/.venv/lib/python3.10/site-packages (from huggingface-hub<1.0,>=0.16.4->tokenizers<1,>=0.15->cohere) (6.0.2)\n",
      "Requirement already satisfied: tqdm>=4.42.1 in /media/nayereh/F01C24171C23D77E1/ubuntu/mine_projects/LLMs/.venv/lib/python3.10/site-packages (from huggingface-hub<1.0,>=0.16.4->tokenizers<1,>=0.15->cohere) (4.67.1)\n",
      "Requirement already satisfied: hf-xet<2.0.0,>=1.1.2 in /media/nayereh/F01C24171C23D77E1/ubuntu/mine_projects/LLMs/.venv/lib/python3.10/site-packages (from huggingface-hub<1.0,>=0.16.4->tokenizers<1,>=0.15->cohere) (1.1.5)\n",
      "Requirement already satisfied: langchain-community<0.4.0,>=0.3.0 in /media/nayereh/F01C24171C23D77E1/ubuntu/mine_projects/LLMs/.venv/lib/python3.10/site-packages (from langchain-cohere) (0.3.27)\n",
      "Requirement already satisfied: langchain-core<0.4.0,>=0.3.27 in /media/nayereh/F01C24171C23D77E1/ubuntu/mine_projects/LLMs/.venv/lib/python3.10/site-packages (from langchain-cohere) (0.3.69)\n",
      "Requirement already satisfied: types-pyyaml<7.0.0.0,>=6.0.12.20240917 in /media/nayereh/F01C24171C23D77E1/ubuntu/mine_projects/LLMs/.venv/lib/python3.10/site-packages (from langchain-cohere) (6.0.12.20250516)\n",
      "Requirement already satisfied: langchain<1.0.0,>=0.3.26 in /media/nayereh/F01C24171C23D77E1/ubuntu/mine_projects/LLMs/.venv/lib/python3.10/site-packages (from langchain-community<0.4.0,>=0.3.0->langchain-cohere) (0.3.26)\n",
      "Requirement already satisfied: SQLAlchemy<3,>=1.4 in /media/nayereh/F01C24171C23D77E1/ubuntu/mine_projects/LLMs/.venv/lib/python3.10/site-packages (from langchain-community<0.4.0,>=0.3.0->langchain-cohere) (2.0.41)\n",
      "Requirement already satisfied: aiohttp<4.0.0,>=3.8.3 in /media/nayereh/F01C24171C23D77E1/ubuntu/mine_projects/LLMs/.venv/lib/python3.10/site-packages (from langchain-community<0.4.0,>=0.3.0->langchain-cohere) (3.12.14)\n",
      "Requirement already satisfied: tenacity!=8.4.0,<10,>=8.1.0 in /media/nayereh/F01C24171C23D77E1/ubuntu/mine_projects/LLMs/.venv/lib/python3.10/site-packages (from langchain-community<0.4.0,>=0.3.0->langchain-cohere) (9.1.2)\n",
      "Requirement already satisfied: dataclasses-json<0.7,>=0.5.7 in /media/nayereh/F01C24171C23D77E1/ubuntu/mine_projects/LLMs/.venv/lib/python3.10/site-packages (from langchain-community<0.4.0,>=0.3.0->langchain-cohere) (0.6.7)\n",
      "Requirement already satisfied: pydantic-settings<3.0.0,>=2.4.0 in /media/nayereh/F01C24171C23D77E1/ubuntu/mine_projects/LLMs/.venv/lib/python3.10/site-packages (from langchain-community<0.4.0,>=0.3.0->langchain-cohere) (2.10.1)\n",
      "Requirement already satisfied: langsmith>=0.1.125 in /media/nayereh/F01C24171C23D77E1/ubuntu/mine_projects/LLMs/.venv/lib/python3.10/site-packages (from langchain-community<0.4.0,>=0.3.0->langchain-cohere) (0.4.8)\n",
      "Requirement already satisfied: numpy>=1.26.2 in /media/nayereh/F01C24171C23D77E1/ubuntu/mine_projects/LLMs/.venv/lib/python3.10/site-packages (from langchain-community<0.4.0,>=0.3.0->langchain-cohere) (2.2.6)\n",
      "Requirement already satisfied: aiohappyeyeballs>=2.5.0 in /media/nayereh/F01C24171C23D77E1/ubuntu/mine_projects/LLMs/.venv/lib/python3.10/site-packages (from aiohttp<4.0.0,>=3.8.3->langchain-community<0.4.0,>=0.3.0->langchain-cohere) (2.6.1)\n",
      "Requirement already satisfied: aiosignal>=1.4.0 in /media/nayereh/F01C24171C23D77E1/ubuntu/mine_projects/LLMs/.venv/lib/python3.10/site-packages (from aiohttp<4.0.0,>=3.8.3->langchain-community<0.4.0,>=0.3.0->langchain-cohere) (1.4.0)\n",
      "Requirement already satisfied: async-timeout<6.0,>=4.0 in /media/nayereh/F01C24171C23D77E1/ubuntu/mine_projects/LLMs/.venv/lib/python3.10/site-packages (from aiohttp<4.0.0,>=3.8.3->langchain-community<0.4.0,>=0.3.0->langchain-cohere) (4.0.3)\n",
      "Requirement already satisfied: attrs>=17.3.0 in /media/nayereh/F01C24171C23D77E1/ubuntu/mine_projects/LLMs/.venv/lib/python3.10/site-packages (from aiohttp<4.0.0,>=3.8.3->langchain-community<0.4.0,>=0.3.0->langchain-cohere) (25.3.0)\n",
      "Requirement already satisfied: frozenlist>=1.1.1 in /media/nayereh/F01C24171C23D77E1/ubuntu/mine_projects/LLMs/.venv/lib/python3.10/site-packages (from aiohttp<4.0.0,>=3.8.3->langchain-community<0.4.0,>=0.3.0->langchain-cohere) (1.7.0)\n",
      "Requirement already satisfied: multidict<7.0,>=4.5 in /media/nayereh/F01C24171C23D77E1/ubuntu/mine_projects/LLMs/.venv/lib/python3.10/site-packages (from aiohttp<4.0.0,>=3.8.3->langchain-community<0.4.0,>=0.3.0->langchain-cohere) (6.6.3)\n",
      "Requirement already satisfied: propcache>=0.2.0 in /media/nayereh/F01C24171C23D77E1/ubuntu/mine_projects/LLMs/.venv/lib/python3.10/site-packages (from aiohttp<4.0.0,>=3.8.3->langchain-community<0.4.0,>=0.3.0->langchain-cohere) (0.3.2)\n",
      "Requirement already satisfied: yarl<2.0,>=1.17.0 in /media/nayereh/F01C24171C23D77E1/ubuntu/mine_projects/LLMs/.venv/lib/python3.10/site-packages (from aiohttp<4.0.0,>=3.8.3->langchain-community<0.4.0,>=0.3.0->langchain-cohere) (1.20.1)\n",
      "Requirement already satisfied: marshmallow<4.0.0,>=3.18.0 in /media/nayereh/F01C24171C23D77E1/ubuntu/mine_projects/LLMs/.venv/lib/python3.10/site-packages (from dataclasses-json<0.7,>=0.5.7->langchain-community<0.4.0,>=0.3.0->langchain-cohere) (3.26.1)\n",
      "Requirement already satisfied: typing-inspect<1,>=0.4.0 in /media/nayereh/F01C24171C23D77E1/ubuntu/mine_projects/LLMs/.venv/lib/python3.10/site-packages (from dataclasses-json<0.7,>=0.5.7->langchain-community<0.4.0,>=0.3.0->langchain-cohere) (0.9.0)\n",
      "Requirement already satisfied: langchain-text-splitters<1.0.0,>=0.3.8 in /media/nayereh/F01C24171C23D77E1/ubuntu/mine_projects/LLMs/.venv/lib/python3.10/site-packages (from langchain<1.0.0,>=0.3.26->langchain-community<0.4.0,>=0.3.0->langchain-cohere) (0.3.8)\n",
      "Requirement already satisfied: jsonpatch<2.0,>=1.33 in /media/nayereh/F01C24171C23D77E1/ubuntu/mine_projects/LLMs/.venv/lib/python3.10/site-packages (from langchain-core<0.4.0,>=0.3.27->langchain-cohere) (1.33)\n",
      "Requirement already satisfied: jsonpointer>=1.9 in /media/nayereh/F01C24171C23D77E1/ubuntu/mine_projects/LLMs/.venv/lib/python3.10/site-packages (from jsonpatch<2.0,>=1.33->langchain-core<0.4.0,>=0.3.27->langchain-cohere) (3.0.0)\n",
      "Requirement already satisfied: annotated-types>=0.6.0 in /media/nayereh/F01C24171C23D77E1/ubuntu/mine_projects/LLMs/.venv/lib/python3.10/site-packages (from pydantic>=1.9.2->cohere) (0.7.0)\n",
      "Requirement already satisfied: typing-inspection>=0.4.0 in /media/nayereh/F01C24171C23D77E1/ubuntu/mine_projects/LLMs/.venv/lib/python3.10/site-packages (from pydantic>=1.9.2->cohere) (0.4.1)\n",
      "Requirement already satisfied: python-dotenv>=0.21.0 in /media/nayereh/F01C24171C23D77E1/ubuntu/mine_projects/LLMs/.venv/lib/python3.10/site-packages (from pydantic-settings<3.0.0,>=2.4.0->langchain-community<0.4.0,>=0.3.0->langchain-cohere) (1.1.1)\n",
      "Requirement already satisfied: greenlet>=1 in /media/nayereh/F01C24171C23D77E1/ubuntu/mine_projects/LLMs/.venv/lib/python3.10/site-packages (from SQLAlchemy<3,>=1.4->langchain-community<0.4.0,>=0.3.0->langchain-cohere) (3.2.3)\n",
      "Requirement already satisfied: mypy-extensions>=0.3.0 in /media/nayereh/F01C24171C23D77E1/ubuntu/mine_projects/LLMs/.venv/lib/python3.10/site-packages (from typing-inspect<1,>=0.4.0->dataclasses-json<0.7,>=0.5.7->langchain-community<0.4.0,>=0.3.0->langchain-cohere) (1.1.0)\n",
      "Requirement already satisfied: anyio in /media/nayereh/F01C24171C23D77E1/ubuntu/mine_projects/LLMs/.venv/lib/python3.10/site-packages (from httpx>=0.21.2->cohere) (4.9.0)\n",
      "Requirement already satisfied: httpcore==1.* in /media/nayereh/F01C24171C23D77E1/ubuntu/mine_projects/LLMs/.venv/lib/python3.10/site-packages (from httpx>=0.21.2->cohere) (1.0.9)\n",
      "Requirement already satisfied: h11>=0.16 in /media/nayereh/F01C24171C23D77E1/ubuntu/mine_projects/LLMs/.venv/lib/python3.10/site-packages (from httpcore==1.*->httpx>=0.21.2->cohere) (0.16.0)\n",
      "Requirement already satisfied: orjson<4.0.0,>=3.9.14 in /media/nayereh/F01C24171C23D77E1/ubuntu/mine_projects/LLMs/.venv/lib/python3.10/site-packages (from langsmith>=0.1.125->langchain-community<0.4.0,>=0.3.0->langchain-cohere) (3.11.0)\n",
      "Requirement already satisfied: requests-toolbelt<2.0.0,>=1.0.0 in /media/nayereh/F01C24171C23D77E1/ubuntu/mine_projects/LLMs/.venv/lib/python3.10/site-packages (from langsmith>=0.1.125->langchain-community<0.4.0,>=0.3.0->langchain-cohere) (1.0.0)\n",
      "Requirement already satisfied: zstandard<0.24.0,>=0.23.0 in /media/nayereh/F01C24171C23D77E1/ubuntu/mine_projects/LLMs/.venv/lib/python3.10/site-packages (from langsmith>=0.1.125->langchain-community<0.4.0,>=0.3.0->langchain-cohere) (0.23.0)\n",
      "Requirement already satisfied: exceptiongroup>=1.0.2 in /media/nayereh/F01C24171C23D77E1/ubuntu/mine_projects/LLMs/.venv/lib/python3.10/site-packages (from anyio->httpx>=0.21.2->cohere) (1.3.0)\n",
      "Requirement already satisfied: sniffio>=1.1 in /media/nayereh/F01C24171C23D77E1/ubuntu/mine_projects/LLMs/.venv/lib/python3.10/site-packages (from anyio->httpx>=0.21.2->cohere) (1.3.1)\n"
     ]
    }
   ],
   "source": [
    "!pip install --upgrade cohere langchain-cohere"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "nt9wg84wNjGfVEwC9ysQuAVdEJlT9bDYjtMeMA8g\n"
     ]
    }
   ],
   "source": [
    "cohere_api_key = os.environ[\"COHERE_API_KEY\"]\n",
    "print(cohere_api_key)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {},
   "outputs": [],
   "source": [
    "from langchain.embeddings import CohereEmbeddings\n",
    "\n",
    "embeddings = CohereEmbeddings(\n",
    "    cohere_api_key=cohere_api_key,\n",
    "    model = \"embed-english-light-v3.0\",\n",
    "    max_retries = 5,\n",
    "    request_timeout = 20,\n",
    "    user_agent=\"langchain\"\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[0.05206299, 0.010536194, -0.04348755, -0.076293945, -0.042877197, -0.030517578, 0.012672424, -0.03265381, 0.043029785, 0.048919678, -0.032196045, 0.020812988, 0.06378174, 0.0027923584, 0.03475952, 0.013137817, 0.074523926, 0.023803711, -0.059417725, 0.042877197, 0.026123047, -0.09857178, -0.024520874, 0.07678223, 0.032287598, 0.008178711, -0.05911255, -0.04336548, 0.025650024, 0.08337402, 0.09564209, -0.009513855, 0.03237915, -0.045654297, 0.0066986084, 0.030426025, -0.022476196, 0.004459381, -0.039489746, -0.045928955, 0.010978699, -0.025650024, 0.01373291, 0.015419006, 0.0041122437, 0.117614746, 0.04208374, 0.054351807, -0.101379395, -0.037139893, -0.031280518, 0.03564453, 0.021026611, -0.029525757, 0.023513794, 0.015403748, -0.013961792, -0.0131073, -0.031982422, 0.024261475, -0.045318604, -0.0076293945, 0.036376953, 0.014930725, 0.08325195, 0.09527588, -0.07751465, -0.08477783, 0.040893555, -0.034576416, 0.04724121, 0.055786133, -0.031051636, 0.01737976, -0.0127334595, 0.014602661, -0.021392822, -0.15405273, -0.070251465, -0.05633545, 0.023925781, 0.027526855, 0.03213501, -0.050598145, -0.05657959, 0.02331543, 0.030715942, -0.04989624, 0.02078247, 0.06414795, 0.08972168, 0.07977295, -0.031051636, -0.032836914, -0.041229248, 0.018798828, -0.022491455, 0.037628174, -0.022338867, -0.008590698, 0.00070667267, -0.037963867, -0.08178711, 0.032165527, -0.032470703, 0.04660034, -0.0050086975, -0.07208252, 0.023071289, -0.012886047, 0.07836914, -0.032226562, 0.04434204, -0.029754639, 0.030593872, 0.020080566, -0.12585449, -0.024978638, 0.03314209, -0.091308594, 0.069885254, 0.03338623, 0.010795593, 0.005908966, 0.01651001, 0.009140015, -0.06878662, 0.03100586, 0.1315918, -0.029144287, 0.00082206726, -0.014854431, -0.004234314, 0.008705139, -0.041870117, 0.035949707, 0.02494812, 0.037841797, 0.010818481, 0.005405426, 0.0625, 0.0496521, -0.056365967, 0.020263672, 0.005794525, 0.04208374, -0.0051116943, 0.045776367, 0.015335083, -0.07543945, -0.047607422, -0.057678223, 0.06890869, 0.042144775, -0.10217285, 0.07397461, -0.059020996, 0.0061302185, -0.03878784, 0.019744873, -0.0045776367, -0.045410156, 0.027404785, -0.10760498, -0.013961792, 0.04751587, -0.049072266, -0.027923584, 0.054351807, -0.057891846, 0.053649902, -0.0055274963, 0.06549072, 0.022369385, -0.012023926, 0.026916504, 0.015899658, -0.00072717667, 0.060455322, 0.034698486, 0.025314331, -0.039276123, -0.070251465, -0.013771057, 0.05026245, -0.009727478, -0.03591919, 0.025299072, 0.028793335, 0.10595703, 0.012069702, 0.09033203, 0.051086426, -0.05493164, -0.045288086, -0.035369873, -0.034820557, -0.009933472, 0.043792725, 0.009429932, 0.0670166, 0.051940918, 0.045043945, 0.020355225, -0.03753662, 0.002149582, -0.01423645, -0.16955566, -0.06097412, 0.02558899, -0.0413208, -0.09136963, -0.076049805, 0.04724121, -0.086242676, -0.030471802, -0.030517578, 0.010391235, -0.033447266, -0.11279297, 0.005378723, 7.3850155e-05, -0.07788086, 0.010734558, -0.031951904, 0.02217102, 0.099975586, -0.059753418, 0.030166626, 0.008796692, 0.056274414, -0.113220215, -0.06652832, -0.032440186, 0.033081055, 0.09503174, 0.065979004, -0.009788513, 0.010353088, -0.034454346, 0.075683594, 0.015571594, -0.0019340515, -0.031585693, -0.017562866, -0.109069824, 0.012649536, 0.07122803, -0.0077209473, 0.0049552917, -0.03164673, 0.008628845, -0.11273193, 0.013572693, 0.05178833, 0.032073975, 0.016616821, 0.06335449, 0.009407043, -0.03982544, -0.06536865, -0.15344238, 0.00065135956, 0.015823364, -0.009033203, 0.04699707, -0.028381348, 0.035369873, -0.07867432, 0.0051231384, 0.025604248, 0.089416504, -0.030715942, 0.012176514, 0.0206604, 0.0066070557, 0.080322266, 0.05154419, -0.0071868896, -0.008399963, 0.085754395, -0.09454346, -0.03591919, -0.016937256, 0.021194458, 0.13061523, -0.048339844, -0.0569458, 0.0061950684, -0.03265381, -0.048095703, -0.042022705, -0.0043563843, 0.024093628, 0.0635376, -0.007701874, -0.038116455, 0.011512756, 0.04119873, 0.042022705, -0.017623901, -0.0473938, 0.046020508, 0.11065674, -0.0107803345, -0.023513794, -0.0231781, -0.0028381348, -0.013252258, 0.04156494, 0.034118652, 0.019546509, -0.033996582, -0.061676025, 0.07751465, 0.016921997, -0.013313293, -0.08068848, 0.0003669262, 0.027633667, -0.021453857, -0.027297974, -0.024978638, -0.10424805, 0.018188477, 0.07489014, 0.013946533, 0.011787415, -0.044189453, -0.023971558, 0.016067505, 0.005290985, -0.03353882, -0.05505371, 0.09667969, -0.058288574, -0.08526611, 0.010147095, -0.0574646, -0.026260376, 0.03744507, 0.08050537, 0.0037612915, 0.08441162, 0.056030273, 0.008834839, -0.030532837, 0.02708435, 0.051116943, 0.017593384, -0.057128906, -0.11468506, 0.0004658699, -0.02470398, -0.09741211, -0.0067253113, -0.08001709, 0.06542969, 0.0791626, 0.0031757355, -0.07165527, -0.10272217, -0.028442383, -0.05807495, 0.025558472, 0.017593384, 0.014221191, 0.019454956, 0.08001709, -0.067871094, 0.06958008, 0.0030822754, -0.0088272095, 0.023071289, 0.019760132, -0.064697266, -0.040802002, -0.008117676, 0.005706787, 0.09106445, 0.010147095, 0.03866577, 0.12634277, 0.013290405]\n"
     ]
    }
   ],
   "source": [
    "print(embeddings.embed_query(\"Test this sentence.\"))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Collecting langchain_chroma\n",
      "  Downloading langchain_chroma-0.2.4-py3-none-any.whl.metadata (1.1 kB)\n",
      "Requirement already satisfied: langchain-core>=0.3.60 in /media/nayereh/F01C24171C23D77E1/ubuntu/mine_projects/LLMs/.venv/lib/python3.10/site-packages (from langchain_chroma) (0.3.69)\n",
      "Requirement already satisfied: numpy>=1.26.0 in /media/nayereh/F01C24171C23D77E1/ubuntu/mine_projects/LLMs/.venv/lib/python3.10/site-packages (from langchain_chroma) (2.2.6)\n",
      "Requirement already satisfied: chromadb>=1.0.9 in /media/nayereh/F01C24171C23D77E1/ubuntu/mine_projects/LLMs/.venv/lib/python3.10/site-packages (from langchain_chroma) (1.0.15)\n",
      "Requirement already satisfied: build>=1.0.3 in /media/nayereh/F01C24171C23D77E1/ubuntu/mine_projects/LLMs/.venv/lib/python3.10/site-packages (from chromadb>=1.0.9->langchain_chroma) (1.2.2.post1)\n",
      "Requirement already satisfied: pydantic>=1.9 in /media/nayereh/F01C24171C23D77E1/ubuntu/mine_projects/LLMs/.venv/lib/python3.10/site-packages (from chromadb>=1.0.9->langchain_chroma) (2.11.7)\n",
      "Requirement already satisfied: pybase64>=1.4.1 in /media/nayereh/F01C24171C23D77E1/ubuntu/mine_projects/LLMs/.venv/lib/python3.10/site-packages (from chromadb>=1.0.9->langchain_chroma) (1.4.1)\n",
      "Requirement already satisfied: uvicorn>=0.18.3 in /media/nayereh/F01C24171C23D77E1/ubuntu/mine_projects/LLMs/.venv/lib/python3.10/site-packages (from uvicorn[standard]>=0.18.3->chromadb>=1.0.9->langchain_chroma) (0.35.0)\n",
      "Requirement already satisfied: posthog<6.0.0,>=2.4.0 in /media/nayereh/F01C24171C23D77E1/ubuntu/mine_projects/LLMs/.venv/lib/python3.10/site-packages (from chromadb>=1.0.9->langchain_chroma) (5.4.0)\n",
      "Requirement already satisfied: typing-extensions>=4.5.0 in /media/nayereh/F01C24171C23D77E1/ubuntu/mine_projects/LLMs/.venv/lib/python3.10/site-packages (from chromadb>=1.0.9->langchain_chroma) (4.14.1)\n",
      "Requirement already satisfied: onnxruntime>=1.14.1 in /media/nayereh/F01C24171C23D77E1/ubuntu/mine_projects/LLMs/.venv/lib/python3.10/site-packages (from chromadb>=1.0.9->langchain_chroma) (1.22.1)\n",
      "Requirement already satisfied: opentelemetry-api>=1.2.0 in /media/nayereh/F01C24171C23D77E1/ubuntu/mine_projects/LLMs/.venv/lib/python3.10/site-packages (from chromadb>=1.0.9->langchain_chroma) (1.35.0)\n",
      "Requirement already satisfied: opentelemetry-exporter-otlp-proto-grpc>=1.2.0 in /media/nayereh/F01C24171C23D77E1/ubuntu/mine_projects/LLMs/.venv/lib/python3.10/site-packages (from chromadb>=1.0.9->langchain_chroma) (1.35.0)\n",
      "Requirement already satisfied: opentelemetry-sdk>=1.2.0 in /media/nayereh/F01C24171C23D77E1/ubuntu/mine_projects/LLMs/.venv/lib/python3.10/site-packages (from chromadb>=1.0.9->langchain_chroma) (1.35.0)\n",
      "Requirement already satisfied: tokenizers>=0.13.2 in /media/nayereh/F01C24171C23D77E1/ubuntu/mine_projects/LLMs/.venv/lib/python3.10/site-packages (from chromadb>=1.0.9->langchain_chroma) (0.21.2)\n",
      "Requirement already satisfied: pypika>=0.48.9 in /media/nayereh/F01C24171C23D77E1/ubuntu/mine_projects/LLMs/.venv/lib/python3.10/site-packages (from chromadb>=1.0.9->langchain_chroma) (0.48.9)\n",
      "Requirement already satisfied: tqdm>=4.65.0 in /media/nayereh/F01C24171C23D77E1/ubuntu/mine_projects/LLMs/.venv/lib/python3.10/site-packages (from chromadb>=1.0.9->langchain_chroma) (4.67.1)\n",
      "Requirement already satisfied: overrides>=7.3.1 in /media/nayereh/F01C24171C23D77E1/ubuntu/mine_projects/LLMs/.venv/lib/python3.10/site-packages (from chromadb>=1.0.9->langchain_chroma) (7.7.0)\n",
      "Requirement already satisfied: importlib-resources in /media/nayereh/F01C24171C23D77E1/ubuntu/mine_projects/LLMs/.venv/lib/python3.10/site-packages (from chromadb>=1.0.9->langchain_chroma) (6.5.2)\n",
      "Requirement already satisfied: grpcio>=1.58.0 in /media/nayereh/F01C24171C23D77E1/ubuntu/mine_projects/LLMs/.venv/lib/python3.10/site-packages (from chromadb>=1.0.9->langchain_chroma) (1.73.1)\n",
      "Requirement already satisfied: bcrypt>=4.0.1 in /media/nayereh/F01C24171C23D77E1/ubuntu/mine_projects/LLMs/.venv/lib/python3.10/site-packages (from chromadb>=1.0.9->langchain_chroma) (4.3.0)\n",
      "Requirement already satisfied: typer>=0.9.0 in /media/nayereh/F01C24171C23D77E1/ubuntu/mine_projects/LLMs/.venv/lib/python3.10/site-packages (from chromadb>=1.0.9->langchain_chroma) (0.16.0)\n",
      "Requirement already satisfied: kubernetes>=28.1.0 in /media/nayereh/F01C24171C23D77E1/ubuntu/mine_projects/LLMs/.venv/lib/python3.10/site-packages (from chromadb>=1.0.9->langchain_chroma) (33.1.0)\n",
      "Requirement already satisfied: tenacity>=8.2.3 in /media/nayereh/F01C24171C23D77E1/ubuntu/mine_projects/LLMs/.venv/lib/python3.10/site-packages (from chromadb>=1.0.9->langchain_chroma) (9.1.2)\n",
      "Requirement already satisfied: pyyaml>=6.0.0 in /media/nayereh/F01C24171C23D77E1/ubuntu/mine_projects/LLMs/.venv/lib/python3.10/site-packages (from chromadb>=1.0.9->langchain_chroma) (6.0.2)\n",
      "Requirement already satisfied: mmh3>=4.0.1 in /media/nayereh/F01C24171C23D77E1/ubuntu/mine_projects/LLMs/.venv/lib/python3.10/site-packages (from chromadb>=1.0.9->langchain_chroma) (5.1.0)\n",
      "Requirement already satisfied: orjson>=3.9.12 in /media/nayereh/F01C24171C23D77E1/ubuntu/mine_projects/LLMs/.venv/lib/python3.10/site-packages (from chromadb>=1.0.9->langchain_chroma) (3.11.0)\n",
      "Requirement already satisfied: httpx>=0.27.0 in /media/nayereh/F01C24171C23D77E1/ubuntu/mine_projects/LLMs/.venv/lib/python3.10/site-packages (from chromadb>=1.0.9->langchain_chroma) (0.28.1)\n",
      "Requirement already satisfied: rich>=10.11.0 in /media/nayereh/F01C24171C23D77E1/ubuntu/mine_projects/LLMs/.venv/lib/python3.10/site-packages (from chromadb>=1.0.9->langchain_chroma) (14.0.0)\n",
      "Requirement already satisfied: jsonschema>=4.19.0 in /media/nayereh/F01C24171C23D77E1/ubuntu/mine_projects/LLMs/.venv/lib/python3.10/site-packages (from chromadb>=1.0.9->langchain_chroma) (4.25.0)\n",
      "Requirement already satisfied: requests<3.0,>=2.7 in /media/nayereh/F01C24171C23D77E1/ubuntu/mine_projects/LLMs/.venv/lib/python3.10/site-packages (from posthog<6.0.0,>=2.4.0->chromadb>=1.0.9->langchain_chroma) (2.32.4)\n",
      "Requirement already satisfied: six>=1.5 in /media/nayereh/F01C24171C23D77E1/ubuntu/mine_projects/LLMs/.venv/lib/python3.10/site-packages (from posthog<6.0.0,>=2.4.0->chromadb>=1.0.9->langchain_chroma) (1.17.0)\n",
      "Requirement already satisfied: python-dateutil>=2.2 in /media/nayereh/F01C24171C23D77E1/ubuntu/mine_projects/LLMs/.venv/lib/python3.10/site-packages (from posthog<6.0.0,>=2.4.0->chromadb>=1.0.9->langchain_chroma) (2.9.0.post0)\n",
      "Requirement already satisfied: backoff>=1.10.0 in /media/nayereh/F01C24171C23D77E1/ubuntu/mine_projects/LLMs/.venv/lib/python3.10/site-packages (from posthog<6.0.0,>=2.4.0->chromadb>=1.0.9->langchain_chroma) (2.2.1)\n",
      "Requirement already satisfied: distro>=1.5.0 in /media/nayereh/F01C24171C23D77E1/ubuntu/mine_projects/LLMs/.venv/lib/python3.10/site-packages (from posthog<6.0.0,>=2.4.0->chromadb>=1.0.9->langchain_chroma) (1.9.0)\n",
      "Requirement already satisfied: charset_normalizer<4,>=2 in /media/nayereh/F01C24171C23D77E1/ubuntu/mine_projects/LLMs/.venv/lib/python3.10/site-packages (from requests<3.0,>=2.7->posthog<6.0.0,>=2.4.0->chromadb>=1.0.9->langchain_chroma) (3.4.2)\n",
      "Requirement already satisfied: idna<4,>=2.5 in /media/nayereh/F01C24171C23D77E1/ubuntu/mine_projects/LLMs/.venv/lib/python3.10/site-packages (from requests<3.0,>=2.7->posthog<6.0.0,>=2.4.0->chromadb>=1.0.9->langchain_chroma) (3.10)\n",
      "Requirement already satisfied: urllib3<3,>=1.21.1 in /media/nayereh/F01C24171C23D77E1/ubuntu/mine_projects/LLMs/.venv/lib/python3.10/site-packages (from requests<3.0,>=2.7->posthog<6.0.0,>=2.4.0->chromadb>=1.0.9->langchain_chroma) (2.5.0)\n",
      "Requirement already satisfied: certifi>=2017.4.17 in /media/nayereh/F01C24171C23D77E1/ubuntu/mine_projects/LLMs/.venv/lib/python3.10/site-packages (from requests<3.0,>=2.7->posthog<6.0.0,>=2.4.0->chromadb>=1.0.9->langchain_chroma) (2025.7.14)\n",
      "Requirement already satisfied: packaging>=19.1 in /media/nayereh/F01C24171C23D77E1/ubuntu/mine_projects/LLMs/.venv/lib/python3.10/site-packages (from build>=1.0.3->chromadb>=1.0.9->langchain_chroma) (25.0)\n",
      "Requirement already satisfied: pyproject_hooks in /media/nayereh/F01C24171C23D77E1/ubuntu/mine_projects/LLMs/.venv/lib/python3.10/site-packages (from build>=1.0.3->chromadb>=1.0.9->langchain_chroma) (1.2.0)\n",
      "Requirement already satisfied: tomli>=1.1.0 in /media/nayereh/F01C24171C23D77E1/ubuntu/mine_projects/LLMs/.venv/lib/python3.10/site-packages (from build>=1.0.3->chromadb>=1.0.9->langchain_chroma) (2.2.1)\n",
      "Requirement already satisfied: anyio in /media/nayereh/F01C24171C23D77E1/ubuntu/mine_projects/LLMs/.venv/lib/python3.10/site-packages (from httpx>=0.27.0->chromadb>=1.0.9->langchain_chroma) (4.9.0)\n",
      "Requirement already satisfied: httpcore==1.* in /media/nayereh/F01C24171C23D77E1/ubuntu/mine_projects/LLMs/.venv/lib/python3.10/site-packages (from httpx>=0.27.0->chromadb>=1.0.9->langchain_chroma) (1.0.9)\n",
      "Requirement already satisfied: h11>=0.16 in /media/nayereh/F01C24171C23D77E1/ubuntu/mine_projects/LLMs/.venv/lib/python3.10/site-packages (from httpcore==1.*->httpx>=0.27.0->chromadb>=1.0.9->langchain_chroma) (0.16.0)\n",
      "Requirement already satisfied: attrs>=22.2.0 in /media/nayereh/F01C24171C23D77E1/ubuntu/mine_projects/LLMs/.venv/lib/python3.10/site-packages (from jsonschema>=4.19.0->chromadb>=1.0.9->langchain_chroma) (25.3.0)\n",
      "Requirement already satisfied: jsonschema-specifications>=2023.03.6 in /media/nayereh/F01C24171C23D77E1/ubuntu/mine_projects/LLMs/.venv/lib/python3.10/site-packages (from jsonschema>=4.19.0->chromadb>=1.0.9->langchain_chroma) (2025.4.1)\n",
      "Requirement already satisfied: referencing>=0.28.4 in /media/nayereh/F01C24171C23D77E1/ubuntu/mine_projects/LLMs/.venv/lib/python3.10/site-packages (from jsonschema>=4.19.0->chromadb>=1.0.9->langchain_chroma) (0.36.2)\n",
      "Requirement already satisfied: rpds-py>=0.7.1 in /media/nayereh/F01C24171C23D77E1/ubuntu/mine_projects/LLMs/.venv/lib/python3.10/site-packages (from jsonschema>=4.19.0->chromadb>=1.0.9->langchain_chroma) (0.26.0)\n",
      "Requirement already satisfied: google-auth>=1.0.1 in /media/nayereh/F01C24171C23D77E1/ubuntu/mine_projects/LLMs/.venv/lib/python3.10/site-packages (from kubernetes>=28.1.0->chromadb>=1.0.9->langchain_chroma) (2.40.3)\n",
      "Requirement already satisfied: websocket-client!=0.40.0,!=0.41.*,!=0.42.*,>=0.32.0 in /media/nayereh/F01C24171C23D77E1/ubuntu/mine_projects/LLMs/.venv/lib/python3.10/site-packages (from kubernetes>=28.1.0->chromadb>=1.0.9->langchain_chroma) (1.8.0)\n",
      "Requirement already satisfied: requests-oauthlib in /media/nayereh/F01C24171C23D77E1/ubuntu/mine_projects/LLMs/.venv/lib/python3.10/site-packages (from kubernetes>=28.1.0->chromadb>=1.0.9->langchain_chroma) (2.0.0)\n",
      "Requirement already satisfied: oauthlib>=3.2.2 in /media/nayereh/F01C24171C23D77E1/ubuntu/mine_projects/LLMs/.venv/lib/python3.10/site-packages (from kubernetes>=28.1.0->chromadb>=1.0.9->langchain_chroma) (3.3.1)\n",
      "Requirement already satisfied: durationpy>=0.7 in /media/nayereh/F01C24171C23D77E1/ubuntu/mine_projects/LLMs/.venv/lib/python3.10/site-packages (from kubernetes>=28.1.0->chromadb>=1.0.9->langchain_chroma) (0.10)\n",
      "Requirement already satisfied: cachetools<6.0,>=2.0.0 in /media/nayereh/F01C24171C23D77E1/ubuntu/mine_projects/LLMs/.venv/lib/python3.10/site-packages (from google-auth>=1.0.1->kubernetes>=28.1.0->chromadb>=1.0.9->langchain_chroma) (5.5.2)\n",
      "Requirement already satisfied: pyasn1-modules>=0.2.1 in /media/nayereh/F01C24171C23D77E1/ubuntu/mine_projects/LLMs/.venv/lib/python3.10/site-packages (from google-auth>=1.0.1->kubernetes>=28.1.0->chromadb>=1.0.9->langchain_chroma) (0.4.2)\n",
      "Requirement already satisfied: rsa<5,>=3.1.4 in /media/nayereh/F01C24171C23D77E1/ubuntu/mine_projects/LLMs/.venv/lib/python3.10/site-packages (from google-auth>=1.0.1->kubernetes>=28.1.0->chromadb>=1.0.9->langchain_chroma) (4.9.1)\n",
      "Requirement already satisfied: pyasn1>=0.1.3 in /media/nayereh/F01C24171C23D77E1/ubuntu/mine_projects/LLMs/.venv/lib/python3.10/site-packages (from rsa<5,>=3.1.4->google-auth>=1.0.1->kubernetes>=28.1.0->chromadb>=1.0.9->langchain_chroma) (0.6.1)\n",
      "Requirement already satisfied: langsmith>=0.3.45 in /media/nayereh/F01C24171C23D77E1/ubuntu/mine_projects/LLMs/.venv/lib/python3.10/site-packages (from langchain-core>=0.3.60->langchain_chroma) (0.4.8)\n",
      "Requirement already satisfied: jsonpatch<2.0,>=1.33 in /media/nayereh/F01C24171C23D77E1/ubuntu/mine_projects/LLMs/.venv/lib/python3.10/site-packages (from langchain-core>=0.3.60->langchain_chroma) (1.33)\n",
      "Requirement already satisfied: jsonpointer>=1.9 in /media/nayereh/F01C24171C23D77E1/ubuntu/mine_projects/LLMs/.venv/lib/python3.10/site-packages (from jsonpatch<2.0,>=1.33->langchain-core>=0.3.60->langchain_chroma) (3.0.0)\n",
      "Requirement already satisfied: requests-toolbelt<2.0.0,>=1.0.0 in /media/nayereh/F01C24171C23D77E1/ubuntu/mine_projects/LLMs/.venv/lib/python3.10/site-packages (from langsmith>=0.3.45->langchain-core>=0.3.60->langchain_chroma) (1.0.0)\n",
      "Requirement already satisfied: zstandard<0.24.0,>=0.23.0 in /media/nayereh/F01C24171C23D77E1/ubuntu/mine_projects/LLMs/.venv/lib/python3.10/site-packages (from langsmith>=0.3.45->langchain-core>=0.3.60->langchain_chroma) (0.23.0)\n",
      "Requirement already satisfied: annotated-types>=0.6.0 in /media/nayereh/F01C24171C23D77E1/ubuntu/mine_projects/LLMs/.venv/lib/python3.10/site-packages (from pydantic>=1.9->chromadb>=1.0.9->langchain_chroma) (0.7.0)\n",
      "Requirement already satisfied: pydantic-core==2.33.2 in /media/nayereh/F01C24171C23D77E1/ubuntu/mine_projects/LLMs/.venv/lib/python3.10/site-packages (from pydantic>=1.9->chromadb>=1.0.9->langchain_chroma) (2.33.2)\n",
      "Requirement already satisfied: typing-inspection>=0.4.0 in /media/nayereh/F01C24171C23D77E1/ubuntu/mine_projects/LLMs/.venv/lib/python3.10/site-packages (from pydantic>=1.9->chromadb>=1.0.9->langchain_chroma) (0.4.1)\n",
      "Requirement already satisfied: coloredlogs in /media/nayereh/F01C24171C23D77E1/ubuntu/mine_projects/LLMs/.venv/lib/python3.10/site-packages (from onnxruntime>=1.14.1->chromadb>=1.0.9->langchain_chroma) (15.0.1)\n",
      "Requirement already satisfied: flatbuffers in /media/nayereh/F01C24171C23D77E1/ubuntu/mine_projects/LLMs/.venv/lib/python3.10/site-packages (from onnxruntime>=1.14.1->chromadb>=1.0.9->langchain_chroma) (25.2.10)\n",
      "Requirement already satisfied: protobuf in /media/nayereh/F01C24171C23D77E1/ubuntu/mine_projects/LLMs/.venv/lib/python3.10/site-packages (from onnxruntime>=1.14.1->chromadb>=1.0.9->langchain_chroma) (6.31.1)\n",
      "Requirement already satisfied: sympy in /media/nayereh/F01C24171C23D77E1/ubuntu/mine_projects/LLMs/.venv/lib/python3.10/site-packages (from onnxruntime>=1.14.1->chromadb>=1.0.9->langchain_chroma) (1.14.0)\n",
      "Requirement already satisfied: importlib-metadata<8.8.0,>=6.0 in /media/nayereh/F01C24171C23D77E1/ubuntu/mine_projects/LLMs/.venv/lib/python3.10/site-packages (from opentelemetry-api>=1.2.0->chromadb>=1.0.9->langchain_chroma) (6.11.0)\n",
      "Requirement already satisfied: zipp>=0.5 in /media/nayereh/F01C24171C23D77E1/ubuntu/mine_projects/LLMs/.venv/lib/python3.10/site-packages (from importlib-metadata<8.8.0,>=6.0->opentelemetry-api>=1.2.0->chromadb>=1.0.9->langchain_chroma) (3.23.0)\n",
      "Requirement already satisfied: googleapis-common-protos~=1.57 in /media/nayereh/F01C24171C23D77E1/ubuntu/mine_projects/LLMs/.venv/lib/python3.10/site-packages (from opentelemetry-exporter-otlp-proto-grpc>=1.2.0->chromadb>=1.0.9->langchain_chroma) (1.70.0)\n",
      "Requirement already satisfied: opentelemetry-exporter-otlp-proto-common==1.35.0 in /media/nayereh/F01C24171C23D77E1/ubuntu/mine_projects/LLMs/.venv/lib/python3.10/site-packages (from opentelemetry-exporter-otlp-proto-grpc>=1.2.0->chromadb>=1.0.9->langchain_chroma) (1.35.0)\n",
      "Requirement already satisfied: opentelemetry-proto==1.35.0 in /media/nayereh/F01C24171C23D77E1/ubuntu/mine_projects/LLMs/.venv/lib/python3.10/site-packages (from opentelemetry-exporter-otlp-proto-grpc>=1.2.0->chromadb>=1.0.9->langchain_chroma) (1.35.0)\n",
      "Requirement already satisfied: opentelemetry-semantic-conventions==0.56b0 in /media/nayereh/F01C24171C23D77E1/ubuntu/mine_projects/LLMs/.venv/lib/python3.10/site-packages (from opentelemetry-sdk>=1.2.0->chromadb>=1.0.9->langchain_chroma) (0.56b0)\n",
      "Requirement already satisfied: markdown-it-py>=2.2.0 in /media/nayereh/F01C24171C23D77E1/ubuntu/mine_projects/LLMs/.venv/lib/python3.10/site-packages (from rich>=10.11.0->chromadb>=1.0.9->langchain_chroma) (3.0.0)\n",
      "Requirement already satisfied: pygments<3.0.0,>=2.13.0 in /media/nayereh/F01C24171C23D77E1/ubuntu/mine_projects/LLMs/.venv/lib/python3.10/site-packages (from rich>=10.11.0->chromadb>=1.0.9->langchain_chroma) (2.19.2)\n",
      "Requirement already satisfied: mdurl~=0.1 in /media/nayereh/F01C24171C23D77E1/ubuntu/mine_projects/LLMs/.venv/lib/python3.10/site-packages (from markdown-it-py>=2.2.0->rich>=10.11.0->chromadb>=1.0.9->langchain_chroma) (0.1.2)\n",
      "Requirement already satisfied: huggingface-hub<1.0,>=0.16.4 in /media/nayereh/F01C24171C23D77E1/ubuntu/mine_projects/LLMs/.venv/lib/python3.10/site-packages (from tokenizers>=0.13.2->chromadb>=1.0.9->langchain_chroma) (0.33.4)\n",
      "Requirement already satisfied: filelock in /media/nayereh/F01C24171C23D77E1/ubuntu/mine_projects/LLMs/.venv/lib/python3.10/site-packages (from huggingface-hub<1.0,>=0.16.4->tokenizers>=0.13.2->chromadb>=1.0.9->langchain_chroma) (3.18.0)\n",
      "Requirement already satisfied: fsspec>=2023.5.0 in /media/nayereh/F01C24171C23D77E1/ubuntu/mine_projects/LLMs/.venv/lib/python3.10/site-packages (from huggingface-hub<1.0,>=0.16.4->tokenizers>=0.13.2->chromadb>=1.0.9->langchain_chroma) (2025.7.0)\n",
      "Requirement already satisfied: hf-xet<2.0.0,>=1.1.2 in /media/nayereh/F01C24171C23D77E1/ubuntu/mine_projects/LLMs/.venv/lib/python3.10/site-packages (from huggingface-hub<1.0,>=0.16.4->tokenizers>=0.13.2->chromadb>=1.0.9->langchain_chroma) (1.1.5)\n",
      "Requirement already satisfied: click>=8.0.0 in /media/nayereh/F01C24171C23D77E1/ubuntu/mine_projects/LLMs/.venv/lib/python3.10/site-packages (from typer>=0.9.0->chromadb>=1.0.9->langchain_chroma) (8.2.1)\n",
      "Requirement already satisfied: shellingham>=1.3.0 in /media/nayereh/F01C24171C23D77E1/ubuntu/mine_projects/LLMs/.venv/lib/python3.10/site-packages (from typer>=0.9.0->chromadb>=1.0.9->langchain_chroma) (1.5.4)\n",
      "Requirement already satisfied: httptools>=0.6.3 in /media/nayereh/F01C24171C23D77E1/ubuntu/mine_projects/LLMs/.venv/lib/python3.10/site-packages (from uvicorn[standard]>=0.18.3->chromadb>=1.0.9->langchain_chroma) (0.6.4)\n",
      "Requirement already satisfied: python-dotenv>=0.13 in /media/nayereh/F01C24171C23D77E1/ubuntu/mine_projects/LLMs/.venv/lib/python3.10/site-packages (from uvicorn[standard]>=0.18.3->chromadb>=1.0.9->langchain_chroma) (1.1.1)\n",
      "Requirement already satisfied: uvloop>=0.15.1 in /media/nayereh/F01C24171C23D77E1/ubuntu/mine_projects/LLMs/.venv/lib/python3.10/site-packages (from uvicorn[standard]>=0.18.3->chromadb>=1.0.9->langchain_chroma) (0.21.0)\n",
      "Requirement already satisfied: watchfiles>=0.13 in /media/nayereh/F01C24171C23D77E1/ubuntu/mine_projects/LLMs/.venv/lib/python3.10/site-packages (from uvicorn[standard]>=0.18.3->chromadb>=1.0.9->langchain_chroma) (1.1.0)\n",
      "Requirement already satisfied: websockets>=10.4 in /media/nayereh/F01C24171C23D77E1/ubuntu/mine_projects/LLMs/.venv/lib/python3.10/site-packages (from uvicorn[standard]>=0.18.3->chromadb>=1.0.9->langchain_chroma) (15.0.1)\n",
      "Requirement already satisfied: exceptiongroup>=1.0.2 in /media/nayereh/F01C24171C23D77E1/ubuntu/mine_projects/LLMs/.venv/lib/python3.10/site-packages (from anyio->httpx>=0.27.0->chromadb>=1.0.9->langchain_chroma) (1.3.0)\n",
      "Requirement already satisfied: sniffio>=1.1 in /media/nayereh/F01C24171C23D77E1/ubuntu/mine_projects/LLMs/.venv/lib/python3.10/site-packages (from anyio->httpx>=0.27.0->chromadb>=1.0.9->langchain_chroma) (1.3.1)\n",
      "Requirement already satisfied: humanfriendly>=9.1 in /media/nayereh/F01C24171C23D77E1/ubuntu/mine_projects/LLMs/.venv/lib/python3.10/site-packages (from coloredlogs->onnxruntime>=1.14.1->chromadb>=1.0.9->langchain_chroma) (10.0)\n",
      "Requirement already satisfied: mpmath<1.4,>=1.1.0 in /media/nayereh/F01C24171C23D77E1/ubuntu/mine_projects/LLMs/.venv/lib/python3.10/site-packages (from sympy->onnxruntime>=1.14.1->chromadb>=1.0.9->langchain_chroma) (1.3.0)\n",
      "Downloading langchain_chroma-0.2.4-py3-none-any.whl (11 kB)\n",
      "Installing collected packages: langchain_chroma\n",
      "Successfully installed langchain_chroma-0.2.4\n"
     ]
    }
   ],
   "source": [
    "!pip install langchain_chroma"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Retrying langchain_community.embeddings.cohere.CohereEmbeddings.embed_with_retry.<locals>._embed_with_retry in 4.0 seconds as it raised TooManyRequestsError: headers: {'access-control-expose-headers': 'X-Debug-Trace-ID', 'cache-control': 'no-cache, no-store, no-transform, must-revalidate, private, max-age=0', 'content-type': 'application/json', 'expires': 'Thu, 01 Jan 1970 00:00:00 GMT', 'pragma': 'no-cache', 'vary': 'Origin', 'x-accel-expires': '0', 'x-debug-trace-id': 'f2c4fa9a79f5547fc30474597a028f60', 'x-endpoint-monthly-call-limit': '1000', 'x-trial-endpoint-call-limit': '100', 'x-trial-endpoint-call-remaining': '86', 'date': 'Mon, 21 Jul 2025 10:22:17 GMT', 'content-length': '124', 'x-envoy-upstream-service-time': '1445', 'server': 'envoy', 'via': '1.1 google', 'alt-svc': 'h3=\":443\"; ma=2592000,h3-29=\":443\"; ma=2592000'}, status_code: 429, body: {'id': '4eba2831-732a-428b-a584-a8aa9fa44a02', 'message': 'trial token rate limit exceeded, limit is 100000 tokens per minute'}.\n",
      "Retrying langchain_community.embeddings.cohere.CohereEmbeddings.embed_with_retry.<locals>._embed_with_retry in 4.0 seconds as it raised TooManyRequestsError: headers: {'access-control-expose-headers': 'X-Debug-Trace-ID', 'cache-control': 'no-cache, no-store, no-transform, must-revalidate, private, max-age=0', 'content-type': 'application/json', 'expires': 'Thu, 01 Jan 1970 00:00:00 GMT', 'pragma': 'no-cache', 'vary': 'Origin', 'x-accel-expires': '0', 'x-debug-trace-id': '50fa5505a856e83612bf72929f08e266', 'x-endpoint-monthly-call-limit': '1000', 'x-trial-endpoint-call-limit': '100', 'x-trial-endpoint-call-remaining': '82', 'date': 'Mon, 21 Jul 2025 10:22:23 GMT', 'content-length': '124', 'x-envoy-upstream-service-time': '505', 'server': 'envoy', 'via': '1.1 google', 'alt-svc': 'h3=\":443\"; ma=2592000,h3-29=\":443\"; ma=2592000'}, status_code: 429, body: {'id': '6d50b297-87c6-497d-8bb0-714cfee07c76', 'message': 'trial token rate limit exceeded, limit is 100000 tokens per minute'}.\n",
      "Retrying langchain_community.embeddings.cohere.CohereEmbeddings.embed_with_retry.<locals>._embed_with_retry in 4.0 seconds as it raised TooManyRequestsError: headers: {'access-control-expose-headers': 'X-Debug-Trace-ID', 'cache-control': 'no-cache, no-store, no-transform, must-revalidate, private, max-age=0', 'content-type': 'application/json', 'expires': 'Thu, 01 Jan 1970 00:00:00 GMT', 'pragma': 'no-cache', 'vary': 'Origin', 'x-accel-expires': '0', 'x-debug-trace-id': '05bea3c6c8c33a6ea1a7676f2aecf06f', 'x-endpoint-monthly-call-limit': '1000', 'x-trial-endpoint-call-limit': '100', 'x-trial-endpoint-call-remaining': '84', 'date': 'Mon, 21 Jul 2025 10:22:28 GMT', 'content-length': '124', 'x-envoy-upstream-service-time': '371', 'server': 'envoy', 'via': '1.1 google', 'alt-svc': 'h3=\":443\"; ma=2592000,h3-29=\":443\"; ma=2592000'}, status_code: 429, body: {'id': 'cae8f37b-afd8-4b81-b0c7-03b04e2817db', 'message': 'trial token rate limit exceeded, limit is 100000 tokens per minute'}.\n",
      "Retrying langchain_community.embeddings.cohere.CohereEmbeddings.embed_with_retry.<locals>._embed_with_retry in 8.0 seconds as it raised TooManyRequestsError: headers: {'access-control-expose-headers': 'X-Debug-Trace-ID', 'cache-control': 'no-cache, no-store, no-transform, must-revalidate, private, max-age=0', 'content-type': 'application/json', 'expires': 'Thu, 01 Jan 1970 00:00:00 GMT', 'pragma': 'no-cache', 'vary': 'Origin', 'x-accel-expires': '0', 'x-debug-trace-id': '37bd0c3641c2f838aa042c175706b96a', 'x-endpoint-monthly-call-limit': '1000', 'x-trial-endpoint-call-limit': '100', 'x-trial-endpoint-call-remaining': '81', 'date': 'Mon, 21 Jul 2025 10:22:34 GMT', 'content-length': '124', 'x-envoy-upstream-service-time': '474', 'server': 'envoy', 'via': '1.1 google', 'alt-svc': 'h3=\":443\"; ma=2592000,h3-29=\":443\"; ma=2592000'}, status_code: 429, body: {'id': 'fbc36fc5-ebb5-410f-abcd-7be683f9b163', 'message': 'trial token rate limit exceeded, limit is 100000 tokens per minute'}.\n"
     ]
    },
    {
     "ename": "TooManyRequestsError",
     "evalue": "headers: {'access-control-expose-headers': 'X-Debug-Trace-ID', 'cache-control': 'no-cache, no-store, no-transform, must-revalidate, private, max-age=0', 'content-type': 'application/json', 'expires': 'Thu, 01 Jan 1970 00:00:00 GMT', 'pragma': 'no-cache', 'vary': 'Origin', 'x-accel-expires': '0', 'x-debug-trace-id': '1f5dacff4e3a4b05c61391ad491f13ec', 'x-endpoint-monthly-call-limit': '1000', 'x-trial-endpoint-call-limit': '100', 'x-trial-endpoint-call-remaining': '78', 'date': 'Mon, 21 Jul 2025 10:22:44 GMT', 'content-length': '124', 'x-envoy-upstream-service-time': '518', 'server': 'envoy', 'via': '1.1 google', 'alt-svc': 'h3=\":443\"; ma=2592000,h3-29=\":443\"; ma=2592000'}, status_code: 429, body: {'id': '00cd6509-11f2-45c5-a2af-965d0da25669', 'message': 'trial token rate limit exceeded, limit is 100000 tokens per minute'}",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mTooManyRequestsError\u001b[0m                      Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[49], line 5\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[38;5;66;03m# TODO: Make a vectorstore and add the documents to it\u001b[39;00m\n\u001b[1;32m      2\u001b[0m \u001b[38;5;66;03m# Don't forget to install langchain-chroma package\u001b[39;00m\n\u001b[1;32m      3\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;21;01mlangchain_chroma\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;28;01mimport\u001b[39;00m Chroma\n\u001b[0;32m----> 5\u001b[0m vector_store \u001b[38;5;241m=\u001b[39m \u001b[43mChroma\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mfrom_documents\u001b[49m\u001b[43m(\u001b[49m\n\u001b[1;32m      6\u001b[0m \u001b[43m    \u001b[49m\u001b[43mdocuments\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43m \u001b[49m\u001b[43mall_docs\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m      7\u001b[0m \u001b[43m    \u001b[49m\u001b[43membedding\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43m \u001b[49m\u001b[43membeddings\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m      8\u001b[0m \u001b[43m    \u001b[49m\u001b[43mcollection_name\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43m \u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mlibrechat\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m,\u001b[49m\n\u001b[1;32m      9\u001b[0m \u001b[43m    \u001b[49m\u001b[43mpersist_directory\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43m \u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43m./collections\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m,\u001b[49m\n\u001b[1;32m     10\u001b[0m \u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m/media/nayereh/F01C24171C23D77E1/ubuntu/mine_projects/LLMs/.venv/lib/python3.10/site-packages/langchain_chroma/vectorstores.py:1234\u001b[0m, in \u001b[0;36mChroma.from_documents\u001b[0;34m(cls, documents, embedding, ids, collection_name, persist_directory, client_settings, client, collection_metadata, **kwargs)\u001b[0m\n\u001b[1;32m   1232\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m ids \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n\u001b[1;32m   1233\u001b[0m     ids \u001b[38;5;241m=\u001b[39m [doc\u001b[38;5;241m.\u001b[39mid \u001b[38;5;28;01mif\u001b[39;00m doc\u001b[38;5;241m.\u001b[39mid \u001b[38;5;28;01melse\u001b[39;00m \u001b[38;5;28mstr\u001b[39m(uuid\u001b[38;5;241m.\u001b[39muuid4()) \u001b[38;5;28;01mfor\u001b[39;00m doc \u001b[38;5;129;01min\u001b[39;00m documents]\n\u001b[0;32m-> 1234\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mcls\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mfrom_texts\u001b[49m\u001b[43m(\u001b[49m\n\u001b[1;32m   1235\u001b[0m \u001b[43m    \u001b[49m\u001b[43mtexts\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mtexts\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   1236\u001b[0m \u001b[43m    \u001b[49m\u001b[43membedding\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43membedding\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   1237\u001b[0m \u001b[43m    \u001b[49m\u001b[43mmetadatas\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mmetadatas\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   1238\u001b[0m \u001b[43m    \u001b[49m\u001b[43mids\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mids\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   1239\u001b[0m \u001b[43m    \u001b[49m\u001b[43mcollection_name\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mcollection_name\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   1240\u001b[0m \u001b[43m    \u001b[49m\u001b[43mpersist_directory\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mpersist_directory\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   1241\u001b[0m \u001b[43m    \u001b[49m\u001b[43mclient_settings\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mclient_settings\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   1242\u001b[0m \u001b[43m    \u001b[49m\u001b[43mclient\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mclient\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   1243\u001b[0m \u001b[43m    \u001b[49m\u001b[43mcollection_metadata\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mcollection_metadata\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   1244\u001b[0m \u001b[43m    \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   1245\u001b[0m \u001b[43m\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m/media/nayereh/F01C24171C23D77E1/ubuntu/mine_projects/LLMs/.venv/lib/python3.10/site-packages/langchain_chroma/vectorstores.py:1187\u001b[0m, in \u001b[0;36mChroma.from_texts\u001b[0;34m(cls, texts, embedding, metadatas, ids, collection_name, persist_directory, client_settings, client, collection_metadata, **kwargs)\u001b[0m\n\u001b[1;32m   1179\u001b[0m     \u001b[38;5;28;01mfrom\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;21;01mchromadb\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mutils\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mbatch_utils\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;28;01mimport\u001b[39;00m create_batches\n\u001b[1;32m   1181\u001b[0m     \u001b[38;5;28;01mfor\u001b[39;00m batch \u001b[38;5;129;01min\u001b[39;00m create_batches(\n\u001b[1;32m   1182\u001b[0m         api\u001b[38;5;241m=\u001b[39mchroma_collection\u001b[38;5;241m.\u001b[39m_client,\n\u001b[1;32m   1183\u001b[0m         ids\u001b[38;5;241m=\u001b[39mids,\n\u001b[1;32m   1184\u001b[0m         metadatas\u001b[38;5;241m=\u001b[39mmetadatas,  \u001b[38;5;66;03m# type: ignore\u001b[39;00m\n\u001b[1;32m   1185\u001b[0m         documents\u001b[38;5;241m=\u001b[39mtexts,\n\u001b[1;32m   1186\u001b[0m     ):\n\u001b[0;32m-> 1187\u001b[0m         \u001b[43mchroma_collection\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43madd_texts\u001b[49m\u001b[43m(\u001b[49m\n\u001b[1;32m   1188\u001b[0m \u001b[43m            \u001b[49m\u001b[43mtexts\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mbatch\u001b[49m\u001b[43m[\u001b[49m\u001b[38;5;241;43m3\u001b[39;49m\u001b[43m]\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43;01mif\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[43mbatch\u001b[49m\u001b[43m[\u001b[49m\u001b[38;5;241;43m3\u001b[39;49m\u001b[43m]\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43;01melse\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[43m[\u001b[49m\u001b[43m]\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   1189\u001b[0m \u001b[43m            \u001b[49m\u001b[43mmetadatas\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mbatch\u001b[49m\u001b[43m[\u001b[49m\u001b[38;5;241;43m2\u001b[39;49m\u001b[43m]\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43;01mif\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[43mbatch\u001b[49m\u001b[43m[\u001b[49m\u001b[38;5;241;43m2\u001b[39;49m\u001b[43m]\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43;01melse\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[38;5;28;43;01mNone\u001b[39;49;00m\u001b[43m,\u001b[49m\u001b[43m  \u001b[49m\u001b[38;5;66;43;03m# type: ignore\u001b[39;49;00m\n\u001b[1;32m   1190\u001b[0m \u001b[43m            \u001b[49m\u001b[43mids\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mbatch\u001b[49m\u001b[43m[\u001b[49m\u001b[38;5;241;43m0\u001b[39;49m\u001b[43m]\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   1191\u001b[0m \u001b[43m        \u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m   1192\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[1;32m   1193\u001b[0m     chroma_collection\u001b[38;5;241m.\u001b[39madd_texts(texts\u001b[38;5;241m=\u001b[39mtexts, metadatas\u001b[38;5;241m=\u001b[39mmetadatas, ids\u001b[38;5;241m=\u001b[39mids)\n",
      "File \u001b[0;32m/media/nayereh/F01C24171C23D77E1/ubuntu/mine_projects/LLMs/.venv/lib/python3.10/site-packages/langchain_chroma/vectorstores.py:527\u001b[0m, in \u001b[0;36mChroma.add_texts\u001b[0;34m(self, texts, metadatas, ids, **kwargs)\u001b[0m\n\u001b[1;32m    525\u001b[0m texts \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mlist\u001b[39m(texts)\n\u001b[1;32m    526\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_embedding_function \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n\u001b[0;32m--> 527\u001b[0m     embeddings \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_embedding_function\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43membed_documents\u001b[49m\u001b[43m(\u001b[49m\u001b[43mtexts\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    528\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m metadatas:\n\u001b[1;32m    529\u001b[0m     \u001b[38;5;66;03m# fill metadatas with empty dicts if somebody\u001b[39;00m\n\u001b[1;32m    530\u001b[0m     \u001b[38;5;66;03m# did not specify metadata for all texts\u001b[39;00m\n\u001b[1;32m    531\u001b[0m     length_diff \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mlen\u001b[39m(texts) \u001b[38;5;241m-\u001b[39m \u001b[38;5;28mlen\u001b[39m(metadatas)\n",
      "File \u001b[0;32m/media/nayereh/F01C24171C23D77E1/ubuntu/mine_projects/LLMs/.venv/lib/python3.10/site-packages/langchain_community/embeddings/cohere.py:139\u001b[0m, in \u001b[0;36mCohereEmbeddings.embed_documents\u001b[0;34m(self, texts)\u001b[0m\n\u001b[1;32m    130\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;21membed_documents\u001b[39m(\u001b[38;5;28mself\u001b[39m, texts: List[\u001b[38;5;28mstr\u001b[39m]) \u001b[38;5;241m-\u001b[39m\u001b[38;5;241m>\u001b[39m List[List[\u001b[38;5;28mfloat\u001b[39m]]:\n\u001b[1;32m    131\u001b[0m \u001b[38;5;250m    \u001b[39m\u001b[38;5;124;03m\"\"\"Embed a list of document texts.\u001b[39;00m\n\u001b[1;32m    132\u001b[0m \n\u001b[1;32m    133\u001b[0m \u001b[38;5;124;03m    Args:\u001b[39;00m\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m    137\u001b[0m \u001b[38;5;124;03m        List of embeddings, one for each text.\u001b[39;00m\n\u001b[1;32m    138\u001b[0m \u001b[38;5;124;03m    \"\"\"\u001b[39;00m\n\u001b[0;32m--> 139\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43membed\u001b[49m\u001b[43m(\u001b[49m\u001b[43mtexts\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43minput_type\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43msearch_document\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m/media/nayereh/F01C24171C23D77E1/ubuntu/mine_projects/LLMs/.venv/lib/python3.10/site-packages/langchain_community/embeddings/cohere.py:109\u001b[0m, in \u001b[0;36mCohereEmbeddings.embed\u001b[0;34m(self, texts, input_type)\u001b[0m\n\u001b[1;32m    106\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;21membed\u001b[39m(\n\u001b[1;32m    107\u001b[0m     \u001b[38;5;28mself\u001b[39m, texts: List[\u001b[38;5;28mstr\u001b[39m], \u001b[38;5;241m*\u001b[39m, input_type: Optional[\u001b[38;5;28mstr\u001b[39m] \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mNone\u001b[39;00m\n\u001b[1;32m    108\u001b[0m ) \u001b[38;5;241m-\u001b[39m\u001b[38;5;241m>\u001b[39m List[List[\u001b[38;5;28mfloat\u001b[39m]]:\n\u001b[0;32m--> 109\u001b[0m     embeddings \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43membed_with_retry\u001b[49m\u001b[43m(\u001b[49m\n\u001b[1;32m    110\u001b[0m \u001b[43m        \u001b[49m\u001b[43mmodel\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mmodel\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    111\u001b[0m \u001b[43m        \u001b[49m\u001b[43mtexts\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mtexts\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    112\u001b[0m \u001b[43m        \u001b[49m\u001b[43minput_type\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43minput_type\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    113\u001b[0m \u001b[43m        \u001b[49m\u001b[43mtruncate\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mtruncate\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    114\u001b[0m \u001b[43m    \u001b[49m\u001b[43m)\u001b[49m\u001b[38;5;241m.\u001b[39membeddings\n\u001b[1;32m    115\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m [\u001b[38;5;28mlist\u001b[39m(\u001b[38;5;28mmap\u001b[39m(\u001b[38;5;28mfloat\u001b[39m, e)) \u001b[38;5;28;01mfor\u001b[39;00m e \u001b[38;5;129;01min\u001b[39;00m embeddings]\n",
      "File \u001b[0;32m/media/nayereh/F01C24171C23D77E1/ubuntu/mine_projects/LLMs/.venv/lib/python3.10/site-packages/langchain_community/embeddings/cohere.py:94\u001b[0m, in \u001b[0;36mCohereEmbeddings.embed_with_retry\u001b[0;34m(self, **kwargs)\u001b[0m\n\u001b[1;32m     90\u001b[0m \u001b[38;5;129m@retry_decorator\u001b[39m\n\u001b[1;32m     91\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;21m_embed_with_retry\u001b[39m(\u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs: Any) \u001b[38;5;241m-\u001b[39m\u001b[38;5;241m>\u001b[39m Any:\n\u001b[1;32m     92\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mclient\u001b[38;5;241m.\u001b[39membed(\u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)\n\u001b[0;32m---> 94\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43m_embed_with_retry\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m/media/nayereh/F01C24171C23D77E1/ubuntu/mine_projects/LLMs/.venv/lib/python3.10/site-packages/tenacity/__init__.py:338\u001b[0m, in \u001b[0;36mBaseRetrying.wraps.<locals>.wrapped_f\u001b[0;34m(*args, **kw)\u001b[0m\n\u001b[1;32m    336\u001b[0m copy \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mcopy()\n\u001b[1;32m    337\u001b[0m wrapped_f\u001b[38;5;241m.\u001b[39mstatistics \u001b[38;5;241m=\u001b[39m copy\u001b[38;5;241m.\u001b[39mstatistics  \u001b[38;5;66;03m# type: ignore[attr-defined]\u001b[39;00m\n\u001b[0;32m--> 338\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mcopy\u001b[49m\u001b[43m(\u001b[49m\u001b[43mf\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkw\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m/media/nayereh/F01C24171C23D77E1/ubuntu/mine_projects/LLMs/.venv/lib/python3.10/site-packages/tenacity/__init__.py:477\u001b[0m, in \u001b[0;36mRetrying.__call__\u001b[0;34m(self, fn, *args, **kwargs)\u001b[0m\n\u001b[1;32m    475\u001b[0m retry_state \u001b[38;5;241m=\u001b[39m RetryCallState(retry_object\u001b[38;5;241m=\u001b[39m\u001b[38;5;28mself\u001b[39m, fn\u001b[38;5;241m=\u001b[39mfn, args\u001b[38;5;241m=\u001b[39margs, kwargs\u001b[38;5;241m=\u001b[39mkwargs)\n\u001b[1;32m    476\u001b[0m \u001b[38;5;28;01mwhile\u001b[39;00m \u001b[38;5;28;01mTrue\u001b[39;00m:\n\u001b[0;32m--> 477\u001b[0m     do \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43miter\u001b[49m\u001b[43m(\u001b[49m\u001b[43mretry_state\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mretry_state\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    478\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28misinstance\u001b[39m(do, DoAttempt):\n\u001b[1;32m    479\u001b[0m         \u001b[38;5;28;01mtry\u001b[39;00m:\n",
      "File \u001b[0;32m/media/nayereh/F01C24171C23D77E1/ubuntu/mine_projects/LLMs/.venv/lib/python3.10/site-packages/tenacity/__init__.py:378\u001b[0m, in \u001b[0;36mBaseRetrying.iter\u001b[0;34m(self, retry_state)\u001b[0m\n\u001b[1;32m    376\u001b[0m result \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mNone\u001b[39;00m\n\u001b[1;32m    377\u001b[0m \u001b[38;5;28;01mfor\u001b[39;00m action \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39miter_state\u001b[38;5;241m.\u001b[39mactions:\n\u001b[0;32m--> 378\u001b[0m     result \u001b[38;5;241m=\u001b[39m \u001b[43maction\u001b[49m\u001b[43m(\u001b[49m\u001b[43mretry_state\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    379\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m result\n",
      "File \u001b[0;32m/media/nayereh/F01C24171C23D77E1/ubuntu/mine_projects/LLMs/.venv/lib/python3.10/site-packages/tenacity/__init__.py:420\u001b[0m, in \u001b[0;36mBaseRetrying._post_stop_check_actions.<locals>.exc_check\u001b[0;34m(rs)\u001b[0m\n\u001b[1;32m    418\u001b[0m retry_exc \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mretry_error_cls(fut)\n\u001b[1;32m    419\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mreraise:\n\u001b[0;32m--> 420\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m \u001b[43mretry_exc\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mreraise\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    421\u001b[0m \u001b[38;5;28;01mraise\u001b[39;00m retry_exc \u001b[38;5;28;01mfrom\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;21;01mfut\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mexception\u001b[39;00m()\n",
      "File \u001b[0;32m/media/nayereh/F01C24171C23D77E1/ubuntu/mine_projects/LLMs/.venv/lib/python3.10/site-packages/tenacity/__init__.py:187\u001b[0m, in \u001b[0;36mRetryError.reraise\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m    185\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;21mreraise\u001b[39m(\u001b[38;5;28mself\u001b[39m) \u001b[38;5;241m-\u001b[39m\u001b[38;5;241m>\u001b[39m t\u001b[38;5;241m.\u001b[39mNoReturn:\n\u001b[1;32m    186\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mlast_attempt\u001b[38;5;241m.\u001b[39mfailed:\n\u001b[0;32m--> 187\u001b[0m         \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mlast_attempt\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mresult\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    188\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;28mself\u001b[39m\n",
      "File \u001b[0;32m/usr/lib/python3.10/concurrent/futures/_base.py:451\u001b[0m, in \u001b[0;36mFuture.result\u001b[0;34m(self, timeout)\u001b[0m\n\u001b[1;32m    449\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m CancelledError()\n\u001b[1;32m    450\u001b[0m \u001b[38;5;28;01melif\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_state \u001b[38;5;241m==\u001b[39m FINISHED:\n\u001b[0;32m--> 451\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m__get_result\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    453\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_condition\u001b[38;5;241m.\u001b[39mwait(timeout)\n\u001b[1;32m    455\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_state \u001b[38;5;129;01min\u001b[39;00m [CANCELLED, CANCELLED_AND_NOTIFIED]:\n",
      "File \u001b[0;32m/usr/lib/python3.10/concurrent/futures/_base.py:403\u001b[0m, in \u001b[0;36mFuture.__get_result\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m    401\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_exception:\n\u001b[1;32m    402\u001b[0m     \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[0;32m--> 403\u001b[0m         \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_exception\n\u001b[1;32m    404\u001b[0m     \u001b[38;5;28;01mfinally\u001b[39;00m:\n\u001b[1;32m    405\u001b[0m         \u001b[38;5;66;03m# Break a reference cycle with the exception in self._exception\u001b[39;00m\n\u001b[1;32m    406\u001b[0m         \u001b[38;5;28mself\u001b[39m \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mNone\u001b[39;00m\n",
      "File \u001b[0;32m/media/nayereh/F01C24171C23D77E1/ubuntu/mine_projects/LLMs/.venv/lib/python3.10/site-packages/tenacity/__init__.py:480\u001b[0m, in \u001b[0;36mRetrying.__call__\u001b[0;34m(self, fn, *args, **kwargs)\u001b[0m\n\u001b[1;32m    478\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28misinstance\u001b[39m(do, DoAttempt):\n\u001b[1;32m    479\u001b[0m     \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[0;32m--> 480\u001b[0m         result \u001b[38;5;241m=\u001b[39m \u001b[43mfn\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    481\u001b[0m     \u001b[38;5;28;01mexcept\u001b[39;00m \u001b[38;5;167;01mBaseException\u001b[39;00m:  \u001b[38;5;66;03m# noqa: B902\u001b[39;00m\n\u001b[1;32m    482\u001b[0m         retry_state\u001b[38;5;241m.\u001b[39mset_exception(sys\u001b[38;5;241m.\u001b[39mexc_info())  \u001b[38;5;66;03m# type: ignore[arg-type]\u001b[39;00m\n",
      "File \u001b[0;32m/media/nayereh/F01C24171C23D77E1/ubuntu/mine_projects/LLMs/.venv/lib/python3.10/site-packages/langchain_community/embeddings/cohere.py:92\u001b[0m, in \u001b[0;36mCohereEmbeddings.embed_with_retry.<locals>._embed_with_retry\u001b[0;34m(**kwargs)\u001b[0m\n\u001b[1;32m     90\u001b[0m \u001b[38;5;129m@retry_decorator\u001b[39m\n\u001b[1;32m     91\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;21m_embed_with_retry\u001b[39m(\u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs: Any) \u001b[38;5;241m-\u001b[39m\u001b[38;5;241m>\u001b[39m Any:\n\u001b[0;32m---> 92\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mclient\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43membed\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m/media/nayereh/F01C24171C23D77E1/ubuntu/mine_projects/LLMs/.venv/lib/python3.10/site-packages/cohere/client.py:208\u001b[0m, in \u001b[0;36membed\u001b[0;34m(self, texts, images, model, input_type, embedding_types, truncate, request_options, batching)\u001b[0m\n\u001b[1;32m    144\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;21mgenerate\u001b[39m(\n\u001b[1;32m    145\u001b[0m     \u001b[38;5;28mself\u001b[39m,\n\u001b[1;32m    146\u001b[0m     prompt: Optional[\u001b[38;5;28mstr\u001b[39m] \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mNone\u001b[39;00m,\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m    162\u001b[0m     stream: \u001b[38;5;28mbool\u001b[39m \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mFalse\u001b[39;00m,\n\u001b[1;32m    163\u001b[0m ) \u001b[38;5;241m-\u001b[39m\u001b[38;5;241m>\u001b[39m Union[Generations, StreamingGenerations]:\n\u001b[1;32m    164\u001b[0m \u001b[38;5;250m    \u001b[39m\u001b[38;5;124;03m\"\"\"Generate endpoint.\u001b[39;00m\n\u001b[1;32m    165\u001b[0m \u001b[38;5;124;03m    See https://docs.cohere.ai/reference/generate for advanced arguments\u001b[39;00m\n\u001b[1;32m    166\u001b[0m \n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m    200\u001b[0m \u001b[38;5;124;03m            >>>     print(token)\u001b[39;00m\n\u001b[1;32m    201\u001b[0m \u001b[38;5;124;03m    \"\"\"\u001b[39;00m\n\u001b[1;32m    202\u001b[0m     json_body \u001b[38;5;241m=\u001b[39m {\n\u001b[1;32m    203\u001b[0m         \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mmodel\u001b[39m\u001b[38;5;124m\"\u001b[39m: model,\n\u001b[1;32m    204\u001b[0m         \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mprompt\u001b[39m\u001b[38;5;124m\"\u001b[39m: prompt,\n\u001b[1;32m    205\u001b[0m         \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mprompt_vars\u001b[39m\u001b[38;5;124m\"\u001b[39m: prompt_vars,\n\u001b[1;32m    206\u001b[0m         \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mpreset\u001b[39m\u001b[38;5;124m\"\u001b[39m: preset,\n\u001b[1;32m    207\u001b[0m         \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mnum_generations\u001b[39m\u001b[38;5;124m\"\u001b[39m: num_generations,\n\u001b[0;32m--> 208\u001b[0m         \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mmax_tokens\u001b[39m\u001b[38;5;124m\"\u001b[39m: max_tokens,\n\u001b[1;32m    209\u001b[0m         \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mtemperature\u001b[39m\u001b[38;5;124m\"\u001b[39m: temperature,\n\u001b[1;32m    210\u001b[0m         \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mk\u001b[39m\u001b[38;5;124m\"\u001b[39m: k,\n\u001b[1;32m    211\u001b[0m         \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mp\u001b[39m\u001b[38;5;124m\"\u001b[39m: p,\n\u001b[1;32m    212\u001b[0m         \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mfrequency_penalty\u001b[39m\u001b[38;5;124m\"\u001b[39m: frequency_penalty,\n\u001b[1;32m    213\u001b[0m         \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mpresence_penalty\u001b[39m\u001b[38;5;124m\"\u001b[39m: presence_penalty,\n\u001b[1;32m    214\u001b[0m         \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mend_sequences\u001b[39m\u001b[38;5;124m\"\u001b[39m: end_sequences,\n\u001b[1;32m    215\u001b[0m         \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mstop_sequences\u001b[39m\u001b[38;5;124m\"\u001b[39m: stop_sequences,\n\u001b[1;32m    216\u001b[0m         \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mreturn_likelihoods\u001b[39m\u001b[38;5;124m\"\u001b[39m: return_likelihoods,\n\u001b[1;32m    217\u001b[0m         \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mtruncate\u001b[39m\u001b[38;5;124m\"\u001b[39m: truncate,\n\u001b[1;32m    218\u001b[0m         \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mlogit_bias\u001b[39m\u001b[38;5;124m\"\u001b[39m: logit_bias,\n\u001b[1;32m    219\u001b[0m         \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mstream\u001b[39m\u001b[38;5;124m\"\u001b[39m: stream,\n\u001b[1;32m    220\u001b[0m     }\n\u001b[1;32m    221\u001b[0m     response \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_request(cohere\u001b[38;5;241m.\u001b[39mGENERATE_URL, json\u001b[38;5;241m=\u001b[39mjson_body, stream\u001b[38;5;241m=\u001b[39mstream)\n\u001b[1;32m    222\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m stream:\n",
      "File \u001b[0;32m/media/nayereh/F01C24171C23D77E1/ubuntu/mine_projects/LLMs/.venv/lib/python3.10/site-packages/cohere/client.py:208\u001b[0m, in \u001b[0;36m<listcomp>\u001b[0;34m(.0)\u001b[0m\n\u001b[1;32m    144\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;21mgenerate\u001b[39m(\n\u001b[1;32m    145\u001b[0m     \u001b[38;5;28mself\u001b[39m,\n\u001b[1;32m    146\u001b[0m     prompt: Optional[\u001b[38;5;28mstr\u001b[39m] \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mNone\u001b[39;00m,\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m    162\u001b[0m     stream: \u001b[38;5;28mbool\u001b[39m \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mFalse\u001b[39;00m,\n\u001b[1;32m    163\u001b[0m ) \u001b[38;5;241m-\u001b[39m\u001b[38;5;241m>\u001b[39m Union[Generations, StreamingGenerations]:\n\u001b[1;32m    164\u001b[0m \u001b[38;5;250m    \u001b[39m\u001b[38;5;124;03m\"\"\"Generate endpoint.\u001b[39;00m\n\u001b[1;32m    165\u001b[0m \u001b[38;5;124;03m    See https://docs.cohere.ai/reference/generate for advanced arguments\u001b[39;00m\n\u001b[1;32m    166\u001b[0m \n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m    200\u001b[0m \u001b[38;5;124;03m            >>>     print(token)\u001b[39;00m\n\u001b[1;32m    201\u001b[0m \u001b[38;5;124;03m    \"\"\"\u001b[39;00m\n\u001b[1;32m    202\u001b[0m     json_body \u001b[38;5;241m=\u001b[39m {\n\u001b[1;32m    203\u001b[0m         \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mmodel\u001b[39m\u001b[38;5;124m\"\u001b[39m: model,\n\u001b[1;32m    204\u001b[0m         \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mprompt\u001b[39m\u001b[38;5;124m\"\u001b[39m: prompt,\n\u001b[1;32m    205\u001b[0m         \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mprompt_vars\u001b[39m\u001b[38;5;124m\"\u001b[39m: prompt_vars,\n\u001b[1;32m    206\u001b[0m         \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mpreset\u001b[39m\u001b[38;5;124m\"\u001b[39m: preset,\n\u001b[1;32m    207\u001b[0m         \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mnum_generations\u001b[39m\u001b[38;5;124m\"\u001b[39m: num_generations,\n\u001b[0;32m--> 208\u001b[0m         \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mmax_tokens\u001b[39m\u001b[38;5;124m\"\u001b[39m: max_tokens,\n\u001b[1;32m    209\u001b[0m         \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mtemperature\u001b[39m\u001b[38;5;124m\"\u001b[39m: temperature,\n\u001b[1;32m    210\u001b[0m         \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mk\u001b[39m\u001b[38;5;124m\"\u001b[39m: k,\n\u001b[1;32m    211\u001b[0m         \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mp\u001b[39m\u001b[38;5;124m\"\u001b[39m: p,\n\u001b[1;32m    212\u001b[0m         \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mfrequency_penalty\u001b[39m\u001b[38;5;124m\"\u001b[39m: frequency_penalty,\n\u001b[1;32m    213\u001b[0m         \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mpresence_penalty\u001b[39m\u001b[38;5;124m\"\u001b[39m: presence_penalty,\n\u001b[1;32m    214\u001b[0m         \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mend_sequences\u001b[39m\u001b[38;5;124m\"\u001b[39m: end_sequences,\n\u001b[1;32m    215\u001b[0m         \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mstop_sequences\u001b[39m\u001b[38;5;124m\"\u001b[39m: stop_sequences,\n\u001b[1;32m    216\u001b[0m         \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mreturn_likelihoods\u001b[39m\u001b[38;5;124m\"\u001b[39m: return_likelihoods,\n\u001b[1;32m    217\u001b[0m         \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mtruncate\u001b[39m\u001b[38;5;124m\"\u001b[39m: truncate,\n\u001b[1;32m    218\u001b[0m         \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mlogit_bias\u001b[39m\u001b[38;5;124m\"\u001b[39m: logit_bias,\n\u001b[1;32m    219\u001b[0m         \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mstream\u001b[39m\u001b[38;5;124m\"\u001b[39m: stream,\n\u001b[1;32m    220\u001b[0m     }\n\u001b[1;32m    221\u001b[0m     response \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_request(cohere\u001b[38;5;241m.\u001b[39mGENERATE_URL, json\u001b[38;5;241m=\u001b[39mjson_body, stream\u001b[38;5;241m=\u001b[39mstream)\n\u001b[1;32m    222\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m stream:\n",
      "File \u001b[0;32m/usr/lib/python3.10/concurrent/futures/_base.py:621\u001b[0m, in \u001b[0;36mExecutor.map.<locals>.result_iterator\u001b[0;34m()\u001b[0m\n\u001b[1;32m    618\u001b[0m \u001b[38;5;28;01mwhile\u001b[39;00m fs:\n\u001b[1;32m    619\u001b[0m     \u001b[38;5;66;03m# Careful not to keep a reference to the popped future\u001b[39;00m\n\u001b[1;32m    620\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m timeout \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n\u001b[0;32m--> 621\u001b[0m         \u001b[38;5;28;01myield\u001b[39;00m \u001b[43m_result_or_cancel\u001b[49m\u001b[43m(\u001b[49m\u001b[43mfs\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mpop\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    622\u001b[0m     \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[1;32m    623\u001b[0m         \u001b[38;5;28;01myield\u001b[39;00m _result_or_cancel(fs\u001b[38;5;241m.\u001b[39mpop(), end_time \u001b[38;5;241m-\u001b[39m time\u001b[38;5;241m.\u001b[39mmonotonic())\n",
      "File \u001b[0;32m/usr/lib/python3.10/concurrent/futures/_base.py:319\u001b[0m, in \u001b[0;36m_result_or_cancel\u001b[0;34m(***failed resolving arguments***)\u001b[0m\n\u001b[1;32m    317\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[1;32m    318\u001b[0m     \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[0;32m--> 319\u001b[0m         \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mfut\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mresult\u001b[49m\u001b[43m(\u001b[49m\u001b[43mtimeout\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    320\u001b[0m     \u001b[38;5;28;01mfinally\u001b[39;00m:\n\u001b[1;32m    321\u001b[0m         fut\u001b[38;5;241m.\u001b[39mcancel()\n",
      "File \u001b[0;32m/usr/lib/python3.10/concurrent/futures/_base.py:458\u001b[0m, in \u001b[0;36mFuture.result\u001b[0;34m(self, timeout)\u001b[0m\n\u001b[1;32m    456\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m CancelledError()\n\u001b[1;32m    457\u001b[0m \u001b[38;5;28;01melif\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_state \u001b[38;5;241m==\u001b[39m FINISHED:\n\u001b[0;32m--> 458\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m__get_result\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    459\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[1;32m    460\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mTimeoutError\u001b[39;00m()\n",
      "File \u001b[0;32m/usr/lib/python3.10/concurrent/futures/_base.py:403\u001b[0m, in \u001b[0;36mFuture.__get_result\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m    401\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_exception:\n\u001b[1;32m    402\u001b[0m     \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[0;32m--> 403\u001b[0m         \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_exception\n\u001b[1;32m    404\u001b[0m     \u001b[38;5;28;01mfinally\u001b[39;00m:\n\u001b[1;32m    405\u001b[0m         \u001b[38;5;66;03m# Break a reference cycle with the exception in self._exception\u001b[39;00m\n\u001b[1;32m    406\u001b[0m         \u001b[38;5;28mself\u001b[39m \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mNone\u001b[39;00m\n",
      "File \u001b[0;32m/usr/lib/python3.10/concurrent/futures/thread.py:58\u001b[0m, in \u001b[0;36m_WorkItem.run\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m     55\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m\n\u001b[1;32m     57\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[0;32m---> 58\u001b[0m     result \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mfn\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m     59\u001b[0m \u001b[38;5;28;01mexcept\u001b[39;00m \u001b[38;5;167;01mBaseException\u001b[39;00m \u001b[38;5;28;01mas\u001b[39;00m exc:\n\u001b[1;32m     60\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mfuture\u001b[38;5;241m.\u001b[39mset_exception(exc)\n",
      "File \u001b[0;32m/media/nayereh/F01C24171C23D77E1/ubuntu/mine_projects/LLMs/.venv/lib/python3.10/site-packages/cohere/client.py:211\u001b[0m, in \u001b[0;36m<lambda>\u001b[0;34m(text_batch)\u001b[0m\n\u001b[1;32m    144\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;21mgenerate\u001b[39m(\n\u001b[1;32m    145\u001b[0m     \u001b[38;5;28mself\u001b[39m,\n\u001b[1;32m    146\u001b[0m     prompt: Optional[\u001b[38;5;28mstr\u001b[39m] \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mNone\u001b[39;00m,\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m    162\u001b[0m     stream: \u001b[38;5;28mbool\u001b[39m \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mFalse\u001b[39;00m,\n\u001b[1;32m    163\u001b[0m ) \u001b[38;5;241m-\u001b[39m\u001b[38;5;241m>\u001b[39m Union[Generations, StreamingGenerations]:\n\u001b[1;32m    164\u001b[0m \u001b[38;5;250m    \u001b[39m\u001b[38;5;124;03m\"\"\"Generate endpoint.\u001b[39;00m\n\u001b[1;32m    165\u001b[0m \u001b[38;5;124;03m    See https://docs.cohere.ai/reference/generate for advanced arguments\u001b[39;00m\n\u001b[1;32m    166\u001b[0m \n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m    200\u001b[0m \u001b[38;5;124;03m            >>>     print(token)\u001b[39;00m\n\u001b[1;32m    201\u001b[0m \u001b[38;5;124;03m    \"\"\"\u001b[39;00m\n\u001b[1;32m    202\u001b[0m     json_body \u001b[38;5;241m=\u001b[39m {\n\u001b[1;32m    203\u001b[0m         \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mmodel\u001b[39m\u001b[38;5;124m\"\u001b[39m: model,\n\u001b[1;32m    204\u001b[0m         \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mprompt\u001b[39m\u001b[38;5;124m\"\u001b[39m: prompt,\n\u001b[1;32m    205\u001b[0m         \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mprompt_vars\u001b[39m\u001b[38;5;124m\"\u001b[39m: prompt_vars,\n\u001b[1;32m    206\u001b[0m         \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mpreset\u001b[39m\u001b[38;5;124m\"\u001b[39m: preset,\n\u001b[1;32m    207\u001b[0m         \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mnum_generations\u001b[39m\u001b[38;5;124m\"\u001b[39m: num_generations,\n\u001b[1;32m    208\u001b[0m         \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mmax_tokens\u001b[39m\u001b[38;5;124m\"\u001b[39m: max_tokens,\n\u001b[1;32m    209\u001b[0m         \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mtemperature\u001b[39m\u001b[38;5;124m\"\u001b[39m: temperature,\n\u001b[1;32m    210\u001b[0m         \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mk\u001b[39m\u001b[38;5;124m\"\u001b[39m: k,\n\u001b[0;32m--> 211\u001b[0m         \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mp\u001b[39m\u001b[38;5;124m\"\u001b[39m: p,\n\u001b[1;32m    212\u001b[0m         \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mfrequency_penalty\u001b[39m\u001b[38;5;124m\"\u001b[39m: frequency_penalty,\n\u001b[1;32m    213\u001b[0m         \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mpresence_penalty\u001b[39m\u001b[38;5;124m\"\u001b[39m: presence_penalty,\n\u001b[1;32m    214\u001b[0m         \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mend_sequences\u001b[39m\u001b[38;5;124m\"\u001b[39m: end_sequences,\n\u001b[1;32m    215\u001b[0m         \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mstop_sequences\u001b[39m\u001b[38;5;124m\"\u001b[39m: stop_sequences,\n\u001b[1;32m    216\u001b[0m         \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mreturn_likelihoods\u001b[39m\u001b[38;5;124m\"\u001b[39m: return_likelihoods,\n\u001b[1;32m    217\u001b[0m         \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mtruncate\u001b[39m\u001b[38;5;124m\"\u001b[39m: truncate,\n\u001b[1;32m    218\u001b[0m         \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mlogit_bias\u001b[39m\u001b[38;5;124m\"\u001b[39m: logit_bias,\n\u001b[1;32m    219\u001b[0m         \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mstream\u001b[39m\u001b[38;5;124m\"\u001b[39m: stream,\n\u001b[1;32m    220\u001b[0m     }\n\u001b[1;32m    221\u001b[0m     response \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_request(cohere\u001b[38;5;241m.\u001b[39mGENERATE_URL, json\u001b[38;5;241m=\u001b[39mjson_body, stream\u001b[38;5;241m=\u001b[39mstream)\n\u001b[1;32m    222\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m stream:\n",
      "File \u001b[0;32m/media/nayereh/F01C24171C23D77E1/ubuntu/mine_projects/LLMs/.venv/lib/python3.10/site-packages/cohere/base_client.py:1107\u001b[0m, in \u001b[0;36membed\u001b[0;34m(self, texts, images, model, input_type, embedding_types, truncate, request_options)\u001b[0m\n",
      "File \u001b[0;32m/media/nayereh/F01C24171C23D77E1/ubuntu/mine_projects/LLMs/.venv/lib/python3.10/site-packages/cohere/raw_base_client.py:1710\u001b[0m, in \u001b[0;36membed\u001b[0;34m(self, texts, images, model, input_type, embedding_types, truncate, request_options)\u001b[0m\n",
      "\u001b[0;31mTooManyRequestsError\u001b[0m: headers: {'access-control-expose-headers': 'X-Debug-Trace-ID', 'cache-control': 'no-cache, no-store, no-transform, must-revalidate, private, max-age=0', 'content-type': 'application/json', 'expires': 'Thu, 01 Jan 1970 00:00:00 GMT', 'pragma': 'no-cache', 'vary': 'Origin', 'x-accel-expires': '0', 'x-debug-trace-id': '1f5dacff4e3a4b05c61391ad491f13ec', 'x-endpoint-monthly-call-limit': '1000', 'x-trial-endpoint-call-limit': '100', 'x-trial-endpoint-call-remaining': '78', 'date': 'Mon, 21 Jul 2025 10:22:44 GMT', 'content-length': '124', 'x-envoy-upstream-service-time': '518', 'server': 'envoy', 'via': '1.1 google', 'alt-svc': 'h3=\":443\"; ma=2592000,h3-29=\":443\"; ma=2592000'}, status_code: 429, body: {'id': '00cd6509-11f2-45c5-a2af-965d0da25669', 'message': 'trial token rate limit exceeded, limit is 100000 tokens per minute'}"
     ]
    }
   ],
   "source": [
    "# TODO: Make a vectorstore and add the documents to it\n",
    "# Don't forget to install langchain-chroma package\n",
    "from langchain_chroma import Chroma\n",
    "\n",
    "vector_store = Chroma.from_documents(\n",
    "    documents = all_docs,\n",
    "    embedding = embeddings,\n",
    "    collection_name = \"librechat\",\n",
    "    persist_directory = \"./collections\",\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<h2 dir=rtl align=right style=\"line-height:200%;font-family:vazir;color:#0099cc\">\n",
    "<font face=\"vazir\" color=\"#0099cc\">\n",
    "مدل پرسش‌وپاسخ\n",
    "</font>\n",
    "</h2>\n",
    "\n",
    "<p dir=rtl style=\"direction: rtl; text-align: justify; line-height:200%; font-family:vazir; font-size:medium\">\n",
    "<font face=\"vazir\">\n",
    "اکنون می‌توانید به هر روشی که علاقه دارید یک زنجیره‌ی <code>LangChain</code> طراحی کنید که بتواند به پرسش کاربر در قالب خواسته‌شده پاسخ دهد. قاعدتاً این زنجیره باید شامل بازیابی اسناد به‌کمک مخزن برداری نیز باشد. همچنین می‌توانید یک دستور سفارشی‌شده و مناسب با خواسته‌های مسئله بنویسید و سعی کنید با بهبود آن کیفیت پاسخ‌های مدل را نیز افزایش دهید. با این حال، مهم‌ترین نکته در این بخش فرمت خروجی مدل است که در ادامه به شرح آن می‌پردازیم. برای رعایت این فرمت احتمالاً نیاز به استفاده از تجزیه‌کننده (Parser) در زنجیره‌ی خود خواهید داشت.\n",
    "</font>\n",
    "</p>\n",
    "\n",
    "<h3 dir=rtl align=right style=\"line-height:200%;font-family:vazir;color:#0099cc\">\n",
    "<font face=\"vazir\" color=\"#0099cc\">\n",
    "سوالات و فرمت خروجی\n",
    "</font>\n",
    "</h3>\n",
    "\n",
    "<p dir=rtl style=\"direction: rtl; text-align: justify; line-height:200%; font-family:vazir; font-size:medium\">\n",
    "<font face=\"vazir\">\n",
    "با این‌که مدل شما قادر است به‌صورت کامل‌تر و نزدیک‌تر به زبان انسان به پرسش‌های کاربر پاسخ دهد اما از آن‌جا که  بتوانیم عملکرد مدل شما را به‌صورت خودکار توسط سیستم داوری ارزیابی کنیم یک سری سوال مشخص در اختیارتان قرار داده‌ایم که پاسخ‌هایی تک یا چند کلمه‌ای دارند. سیستم داوری وجود عبارت پاسخ درست (یا معادل‌های آن) را در خروجی‌های شما جست‌وجو می‌کند و اگر آن را پیدا کند به‌عنوان پاسخی درست در نظر می‌گیرد. با این حال توجه داشته باشید اگر خروجی مدل شما <u>بیش از ۴ کلمه</u> باشد به‌عنوان یک متن طولانی در نظر گرفته می‌شود و <span style=\"color:red\">نادرست</span> تشخیص داده می‌شود زیرا تمام پاسخ‌ها کوتاه و مشخص هستند.\n",
    "</font>\n",
    "</p>\n",
    "\n",
    "<p dir=rtl style=\"direction: rtl; text-align: justify; line-height:200%; font-family:vazir; font-size:medium\">\n",
    "<font face=\"vazir\">\n",
    "خروجی نهایی شما به‌ازای هر سوال باید یک دیکشنری شامل دو کلید <code>question_number</code> و <code>answer</code> باشد که به‌ترتیب از جنس <code>int</code> و <code>str</code> هستند. در این دیکشنری شماره‌ی سوال به‌عنوان مقدار کلید <code>question_number</code> و پاسخ به‌عنوان مقدار کلید <code>answer</code> قرار می‌گیرد. به‌عنوان مثال اگر پاسخ پرسش شماره‌ی ۱۲، کوئرا باشد دیکشنری مربوط به آن به‌صورت زیر خواهد بود:\n",
    "\n",
    "```python\n",
    "{\n",
    "    \"question_number\": 12,\n",
    "    \"answer\": \"کوئرا\"\n",
    "}\n",
    "```\n",
    "</font>\n",
    "</p>\n",
    "\n",
    "<p dir=rtl style=\"direction: rtl; text-align: justify; line-height:200%; font-family:vazir; font-size:medium\">\n",
    "<font face=\"vazir\">\n",
    "در انتهای نت‌بوک تمام این دیکشنری‌ها (از متغیر <code>answer1</code> تا <code>answer16</code>) را داخل یک لیست واحد ریخته و به‌صورت یک فایل <code>JSON</code> ذخیره خواهیم کرد تا بتوانید آن را در سامانه‌ی داوری آپلود کرده و نتایج کار خود را مشاهده کنید.\n",
    "</font>\n",
    "</p>\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "rag_chain = None # TODO: Define a RAG chain"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "query = \"پرسش ۱: توروالدز برای کار در چه موسسه‌ای دانشگاه هلسینکی را ترک گفت؟\"\n",
    "answer1 = None"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "query = \"پرسش ۲: آندرو تاننباوم استاد کدام دانشگاه است؟\"\n",
    "answer2 = None"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "query = \"پرسش ۳: در سال ۲۰۰۶ چند درصد از هسته لینوکس توسط توروالدز نوشته شد (به عدد)؟\"\n",
    "answer3 = None"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "query = \"پرسش ۴: چه کسی بنیاد نرم‌افزارهای آزاد را بنا نهاد؟\"\n",
    "answer4 = None"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "query = \"پرسش ۵: ریچارد استالمن در ۲۱ سالگی در کدام شرکت کار می‌کرد؟\"\n",
    "answer5 = None"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "query = \"پرسش ۶: یکی از مشهورترین پروژه‌هایی که در ابتدا پروژه‌ی آزاد و آکادمیک بود اما بعد وارد محیط بسته‌ی تجاری شد چه بود؟\"\n",
    "answer6 = None"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "query = \"پرسش ۷: لینکدین در سانسور کردن حساب‌ها به درخواست چه کشوری مشهور است؟\"\n",
    "answer7 = None"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "query = \"پرسش ۸: ریچارد استالمن پیشنهاد می‌کند به‌جای گوگل مپ از چه سرویسی استفاده کنیم؟\"\n",
    "answer8 = None"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "query = \"پرسش ۹: آزادی صفرم در نرم‌افزار آزاد چه عنوانی دارد؟\"\n",
    "answer9 = None"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "query = \"پرسش ۱۰: آیا یک نرم‌افزار آزاد لزوماً رایگان است (بله یا خیر)؟\"\n",
    "answer10 = None"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "query = \"پرسش ۱۱: استاندارد ناظر بر فایل‌ها و دایرکتوری‌ها به‌اختصار چه نامیده می‌شود؟\"\n",
    "answer11 = None"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "query = \"پرسش ۱۲: اولین ریپلای به ایمیل درخواست کار چیست؟\"\n",
    "answer12 = None"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "query = \"پرسش ۱۳: اگر امروز که از شنبه ورزش می‌کنم در واقع دچار چه بایاسی شده‌ایم؟\"\n",
    "answer13 = None"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "query = \"پرسش ۱۴: دنبال یاد گرفتن کدوم یکی باشیم: برنامه‌نویسی یا دستور زبان یک زبان خاص؟\"\n",
    "answer14 = None"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "query = \"پرسش ۱۵: اگه هدف‌مون اینه که بریم گوگل کار کنیم اول از همه چه‌چیزی رو سرچ کنیم؟\"\n",
    "answer15 = None"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "query = \"پرسش ۱۶: در بیانیه‌ی هکرها گفته شده که جرم آن‌ها در یک کلمه چیست؟\"\n",
    "answer16 = None"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<h2 dir=rtl align=right style=\"line-height:200%;font-family:vazir;color:#0099cc\">\n",
    "<font face=\"vazir\" color=\"#0099cc\">\n",
    "نحوه‌ی امتیازدهی\n",
    "</font>\n",
    "</h2>\n",
    "\n",
    "<p dir=rtl style=\"direction: rtl; text-align: justify; line-height:200%; font-family:vazir; font-size:medium\">\n",
    "<font face=\"vazir\">\n",
    "برای آن‌که بتوانید با <span style=\"color:green\">موفقیت</span> امتیاز این پروژه را کسب کنید نیاز است که مدل شما از بین این ۱۶ پرسش حداقل به <u>۱۲ مورد</u> پاسخ درست داده باشد.\n",
    "</font>\n",
    "</p>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<h2 dir=rtl align=right style=\"line-height:200%;font-family:vazir;color:#0099cc\">\n",
    "<font face=\"vazir\" color=\"#0099cc\">\n",
    "<b>سلول جواب‌ساز</b>\n",
    "</font>\n",
    "</h2>\n",
    "\n",
    "<p dir=rtl style=\"direction: rtl; text-align: justify; line-height:200%; font-family:vazir; font-size:medium\">\n",
    "<font face=\"vazir\">\n",
    "در سلول‌های بعدی فایل‌های پاسخ شما را تولید می‌کنیم تا بتوانید در نهایت یک فایل فشرده با نام <code>result.zip</code> تحویل بگیرید که حاوی فایل‌های مورد نیاز جهت داوری خواهد بود. ابتدا نیاز است که پاسخ‌های شما یعنی متغیرهای <code>answer1</code> تا <code>answer16</code> را داخل یک لیست واحد ذخیره کنیم. سپس این لیست را به‌صورت یک فایل <code>JSON</code> ذخیره می‌کنیم. لطفاً کد زیر را <span style=\"color:red\">بدون تغییر</span> اجرا کنید.\n",
    "</font>\n",
    "</p>\n",
    "\n",
    "<p dir=rtl style=\"direction: rtl; text-align: justify; line-height:200%; font-family:vazir; font-size:medium\">\n",
    "<font face=\"vazir\" size=3>\n",
    "    برای ساخته‌شدن فایل <code>result.zip</code> سلول زیر را اجرا کنید. توجه داشته باشید که پیش از اجرای سلول زیر تغییرات اعمال شده در نت‌بوک را ذخیره کرده باشید (<code>ctrl+s</code>) تا در صورت نیاز به پشتیبانی امکان بررسی کد شما وجود داشته باشد. همچنین اگر از گوگل کولب استفاده می‌کنید، در صورت نیاز به پشتیبانی حتماً آخرین نسخه از نت‌بوک را به‌صورت دستی دانلود کرده و داخل فایل ارسالی قرار دهید یا لینک کولب را با ما به‌اشتراک بگذارید.\n",
    "</font>\n",
    "</p>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import zipfile\n",
    "import os\n",
    "import json\n",
    "\n",
    "# Make a list of the answers\n",
    "answers = [globals()[f'answer{i}'] for i in range(1, 17)]\n",
    "\n",
    "# Save the answers to a JSON file\n",
    "with open('answers.json', 'w') as f:\n",
    "    json.dump(answers, f, ensure_ascii=False, indent=4)\n",
    "\n",
    "notebook_path = 'librechat.ipynb'\n",
    "\n",
    "# Check if the notebook exists in the current directory and export it if it doesn't (for Colab)\n",
    "if not os.path.exists(os.path.join(os.getcwd(), notebook_path)):\n",
    "    %notebook -e librechat.ipynb\n",
    "\n",
    "# Compress the files into a zip archive\n",
    "def compress(file_names):\n",
    "    print(\"File Paths:\")\n",
    "    print(file_names)\n",
    "    compression = zipfile.ZIP_DEFLATED\n",
    "    with zipfile.ZipFile(\"result.zip\", mode=\"w\") as zf:\n",
    "        for file_name in file_names:\n",
    "            zf.write('./' + file_name, file_name, compress_type=compression)\n",
    "\n",
    "file_names = ['answers.json', notebook_path]\n",
    "compress(file_names)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<p dir=rtl style=\"direction: rtl; text-align: justify; line-height:200%; font-family:vazir; font-size:medium\">\n",
    "<font face=\"vazir\">\n",
    "اکنون کافیست فایل <code>result.zip</code> را داخل سامانه داوری ارسال کنید تا امتیاز شما محاسبه شود.\n",
    "</font>\n",
    "</p>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<p dir=rtl align=center style=\"line-height:200%;font-family:vazir;color:#0099cc\">\n",
    "<font face=\"vazir\" color=\"#0099cc\">\n",
    "© <a href=\"https://quera.org/\" target=\"_blank\">کوئرا | Quera</a>\n",
    "</font>\n",
    "</p>"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
