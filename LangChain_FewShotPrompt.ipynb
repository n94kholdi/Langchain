{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Get API key"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import getpass\n",
    "\n",
    "# Set the environment variable\n",
    "os.environ[\"COHERE_API_KEY\"] = getpass.getpass(\"Enter your Cohere API key: \")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# nt9wg84wNjGfVEwC9ysQuAVdEJlT9bDYjtMeMA8g"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "nt9wg84wNjGfVEwC9ysQuAVdEJlT9bDYjtMeMA8g\n"
     ]
    }
   ],
   "source": [
    "cohere_api_key = os.environ[\"COHERE_API_KEY\"]\n",
    "print(cohere_api_key)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## load Cohere model "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "from langchain_cohere.llms import Cohere\n",
    "\n",
    "# model = Cohere(temperature=0.1)\n",
    "model = Cohere(cohere_api_key=cohere_api_key, model=\"command\", temperature=0.1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "from langchain_cohere import ChatCohere\n",
    "\n",
    "chat_model = ChatCohere(cohere_api_key=cohere_api_key, model=\"command-r-plus\", temperature=0.1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "from langchain_core.prompts import ChatPromptTemplate\n",
    "from langchain_core.prompts import FewShotChatMessagePromptTemplate\n",
    "from langchain_core.output_parsers import StrOutputParser"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Zero-shot prompt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "این جمله بیانگر احساس ناامیدی و بی‌علاقگی است.\n"
     ]
    }
   ],
   "source": [
    "without_few_shot = ChatPromptTemplate.from_messages(\n",
    "    [\n",
    "        (\"system\", \"احساس متن زیر رو دسته بندی کن\"),\n",
    "        (\"human\", \"{question}\")\n",
    "    ]\n",
    ")\n",
    "\n",
    "chain_without_few_shot = without_few_shot | chat_model #| StrOutputParser()\n",
    "\n",
    "response = chain_without_few_shot.invoke({\"question\": \"آخه کی می‌ره این فیلمو ببینه؟\"})\n",
    "print(response.content)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Few-Shot Prompt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {},
   "outputs": [],
   "source": [
    "examples = [\n",
    "    {\"question\": \"من عاشق این فیلمم!\", \n",
    "     \"answer\":  \"مثبت\"},\n",
    "    {\"question\": \"از این صندلی خوشم نمی‌اد\",\n",
    "     \"answer\":  \"منفی\"},\n",
    "     {\"question\": \"این بهترین کتابیه که خوندم!\", \"answer\": \"مثبت\"},\n",
    "    {\"question\": \"غذای رستوران افتضاح بود\", \"answer\": \"منفی\"},\n",
    "    {\"question\": \"خیلی کیف کردم از بازی\", \"answer\": \"مثبت\"},\n",
    "    {\"question\": \"اصلاً خوشم نیومد، حیف وقت\", \"answer\": \"منفی\"}\n",
    "    ]\n",
    "\n",
    "example_prompt = ChatPromptTemplate.from_messages(\n",
    "    [\n",
    "        (\"human\", \"{question}\"),\n",
    "        (\"ai\", \"{answer}\")\n",
    "    ]\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {},
   "outputs": [],
   "source": [
    "few_shot_prompt = FewShotChatMessagePromptTemplate(\n",
    "    example_prompt=example_prompt,\n",
    "    examples=examples\n",
    ")\n",
    "\n",
    "## use base prompt, examples and ask for same question\n",
    "final_prompt_few_shot = ChatPromptTemplate.from_messages(\n",
    "    [(\"system\", \"احساس متن زیر رو دسته بندی کن\"),\n",
    "     few_shot_prompt,\n",
    "     (\"human\", \"{question}\")\n",
    "    ]\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "منفی\n"
     ]
    }
   ],
   "source": [
    "chain_with_few_shot =  final_prompt_few_shot | chat_model\n",
    "\n",
    "response = chain_with_few_shot.invoke({\"question\": \"آخه کی می‌ره این فیلمو ببینه\"})\n",
    "\n",
    "print(response.content)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Dynamic Few-shot prompt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "from langchain_chroma import Chroma\n",
    "from langchain_core.example_selectors import SemanticSimilarityExampleSelector\n",
    "from langchain_cohere import CohereEmbeddings"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "examples = [\n",
    "    {\n",
    "        \"question\": \"خوشحال\",\n",
    "        \"answer\": \"ناراحت\"\n",
    "    },\n",
    "    {\n",
    "        \"question\": \"مادر\",\n",
    "        \"answer\": \"مهربان\"\n",
    "    },\n",
    "    {\n",
    "        \"question\": \"روز\",\n",
    "        \"answer\": \"خورشید\"\n",
    "    },\n",
    "]\n",
    "\n",
    "embeddings = CohereEmbeddings(model='embed-multilingual-v3.0')\n",
    "to_vectorize = [' '.join(example.values()) for example in examples]\n",
    "VectorStore = Chroma.from_texts(to_vectorize, embedding=embeddings, metadatas=examples)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "example_selector = SemanticSimilarityExampleSelector(\n",
    "    vectorstore=VectorStore,\n",
    "    k=2\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[{'answer': 'ناراحت', 'question': 'خوشحال'},\n",
       " {'answer': 'مهربان', 'question': 'مادر'}]"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "example_selector.select_examples({'question': 'مضطرب'})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "آرام\n",
      "قوی\n"
     ]
    }
   ],
   "source": [
    "few_shot_prompt = FewShotChatMessagePromptTemplate(\n",
    "    input_variables=[\"question\"],\n",
    "    example_selector=example_selector,\n",
    "    example_prompt=ChatPromptTemplate.from_messages(\n",
    "        [(\"human\", \"{question}\"), (\"ai\", \"{answer}\")]\n",
    "    )\n",
    ")\n",
    "\n",
    "final_prompt_few_shot = ChatPromptTemplate.from_messages([\n",
    "    few_shot_prompt,\n",
    "    ('human', \"{question}\")\n",
    "])\n",
    "\n",
    "chain = final_prompt_few_shot | chat_model\n",
    "\n",
    "response = chain.invoke({\"question\": \"مضطرب\"})\n",
    "print(response.content)\n",
    "\n",
    "response = chain.invoke({\"question\": \"پدر\"})\n",
    "print(response.content)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Selectors:\n",
    "\n",
    "- semantic\n",
    "- Ngram\n",
    "- MaxMargin\n",
    "- length-based"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "ename": "AttributeError",
     "evalue": "'ChatPromptTemplate' object has no attribute 'get'",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mAttributeError\u001b[0m                            Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[23], line 16\u001b[0m\n\u001b[1;32m      5\u001b[0m examples \u001b[38;5;241m=\u001b[39m [\n\u001b[1;32m      6\u001b[0m     {\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mquestion\u001b[39m\u001b[38;5;124m\"\u001b[39m: \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mمن عاشق این فیلمم!\u001b[39m\u001b[38;5;124m\"\u001b[39m, \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124manswer\u001b[39m\u001b[38;5;124m\"\u001b[39m: \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mمثبت\u001b[39m\u001b[38;5;124m\"\u001b[39m},\n\u001b[1;32m      7\u001b[0m     {\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mquestion\u001b[39m\u001b[38;5;124m\"\u001b[39m: \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mاز این صندلی خوشم نمیاد\u001b[39m\u001b[38;5;124m\"\u001b[39m, \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124manswer\u001b[39m\u001b[38;5;124m\"\u001b[39m: \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mمنفی\u001b[39m\u001b[38;5;124m\"\u001b[39m},\n\u001b[1;32m      8\u001b[0m     {\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mquestion\u001b[39m\u001b[38;5;124m\"\u001b[39m: \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mغذای رستوران افتضاح بود\u001b[39m\u001b[38;5;124m\"\u001b[39m, \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124manswer\u001b[39m\u001b[38;5;124m\"\u001b[39m: \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mمنفی\u001b[39m\u001b[38;5;124m\"\u001b[39m}\n\u001b[1;32m      9\u001b[0m ]\n\u001b[1;32m     11\u001b[0m example_prompt \u001b[38;5;241m=\u001b[39m ChatPromptTemplate\u001b[38;5;241m.\u001b[39mfrom_messages([\n\u001b[1;32m     12\u001b[0m     (\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mhuman\u001b[39m\u001b[38;5;124m\"\u001b[39m, \u001b[38;5;124m\"\u001b[39m\u001b[38;5;132;01m{question}\u001b[39;00m\u001b[38;5;124m\"\u001b[39m),\n\u001b[1;32m     13\u001b[0m     (\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mai\u001b[39m\u001b[38;5;124m\"\u001b[39m, \u001b[38;5;124m\"\u001b[39m\u001b[38;5;132;01m{answer}\u001b[39;00m\u001b[38;5;124m\"\u001b[39m)\n\u001b[1;32m     14\u001b[0m ])\n\u001b[0;32m---> 16\u001b[0m example_selector \u001b[38;5;241m=\u001b[39m \u001b[43mLengthBasedExampleSelector\u001b[49m\u001b[43m(\u001b[49m\n\u001b[1;32m     17\u001b[0m \u001b[43m    \u001b[49m\u001b[43mexamples\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mexamples\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m     18\u001b[0m \u001b[43m    \u001b[49m\u001b[43mexample_prompt\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mexample_prompt\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m     19\u001b[0m \u001b[43m    \u001b[49m\u001b[43mmax_length\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;241;43m25\u001b[39;49m\u001b[43m  \u001b[49m\u001b[38;5;66;43;03m# max length for examples (based on token length usually)\u001b[39;49;00m\n\u001b[1;32m     20\u001b[0m \u001b[43m)\u001b[49m\n\u001b[1;32m     22\u001b[0m dynamic_prompt \u001b[38;5;241m=\u001b[39m FewShotChatMessagePromptTemplate(\n\u001b[1;32m     23\u001b[0m     example_selector\u001b[38;5;241m=\u001b[39mexample_selector,\n\u001b[1;32m     24\u001b[0m     example_prompt\u001b[38;5;241m=\u001b[39mexample_prompt,\n\u001b[1;32m     25\u001b[0m     input_variables\u001b[38;5;241m=\u001b[39m[\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mquestion\u001b[39m\u001b[38;5;124m\"\u001b[39m]\n\u001b[1;32m     26\u001b[0m )\n",
      "    \u001b[0;31m[... skipping hidden 1 frame]\u001b[0m\n",
      "File \u001b[0;32m~/Documents/Courses/LLMs/.venv/lib/python3.10/site-packages/langchain_core/prompts/prompt.py:85\u001b[0m, in \u001b[0;36mPromptTemplate.pre_init_validation\u001b[0;34m(cls, values)\u001b[0m\n\u001b[1;32m     81\u001b[0m \u001b[38;5;129m@model_validator\u001b[39m(mode\u001b[38;5;241m=\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mbefore\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n\u001b[1;32m     82\u001b[0m \u001b[38;5;129m@classmethod\u001b[39m\n\u001b[1;32m     83\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;21mpre_init_validation\u001b[39m(\u001b[38;5;28mcls\u001b[39m, values: \u001b[38;5;28mdict\u001b[39m) \u001b[38;5;241m-\u001b[39m\u001b[38;5;241m>\u001b[39m Any:\n\u001b[1;32m     84\u001b[0m \u001b[38;5;250m    \u001b[39m\u001b[38;5;124;03m\"\"\"Check that template and input variables are consistent.\"\"\"\u001b[39;00m\n\u001b[0;32m---> 85\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m \u001b[43mvalues\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mget\u001b[49m(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mtemplate\u001b[39m\u001b[38;5;124m\"\u001b[39m) \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n\u001b[1;32m     86\u001b[0m         \u001b[38;5;66;03m# Will let pydantic fail with a ValidationError if template\u001b[39;00m\n\u001b[1;32m     87\u001b[0m         \u001b[38;5;66;03m# is not provided.\u001b[39;00m\n\u001b[1;32m     88\u001b[0m         \u001b[38;5;28;01mreturn\u001b[39;00m values\n\u001b[1;32m     90\u001b[0m     \u001b[38;5;66;03m# Set some default values based on the field defaults\u001b[39;00m\n",
      "File \u001b[0;32m~/Documents/Courses/LLMs/.venv/lib/python3.10/site-packages/pydantic/main.py:891\u001b[0m, in \u001b[0;36mBaseModel.__getattr__\u001b[0;34m(self, item)\u001b[0m\n\u001b[1;32m    888\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28msuper\u001b[39m()\u001b[38;5;241m.\u001b[39m\u001b[38;5;21m__getattribute__\u001b[39m(item)  \u001b[38;5;66;03m# Raises AttributeError if appropriate\u001b[39;00m\n\u001b[1;32m    889\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[1;32m    890\u001b[0m     \u001b[38;5;66;03m# this is the current error\u001b[39;00m\n\u001b[0;32m--> 891\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mAttributeError\u001b[39;00m(\u001b[38;5;124mf\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;132;01m{\u001b[39;00m\u001b[38;5;28mtype\u001b[39m(\u001b[38;5;28mself\u001b[39m)\u001b[38;5;241m.\u001b[39m\u001b[38;5;18m__name__\u001b[39m\u001b[38;5;132;01m!r}\u001b[39;00m\u001b[38;5;124m object has no attribute \u001b[39m\u001b[38;5;132;01m{\u001b[39;00mitem\u001b[38;5;132;01m!r}\u001b[39;00m\u001b[38;5;124m'\u001b[39m)\n",
      "\u001b[0;31mAttributeError\u001b[0m: 'ChatPromptTemplate' object has no attribute 'get'"
     ]
    }
   ],
   "source": [
    "from langchain_core.example_selectors import LengthBasedExampleSelector\n",
    "from langchain.prompts import ChatPromptTemplate, FewShotChatMessagePromptTemplate\n",
    "\n",
    "# Assume examples is already defined\n",
    "examples = [\n",
    "    {\"question\": \"من عاشق این فیلمم!\", \"answer\": \"مثبت\"},\n",
    "    {\"question\": \"از این صندلی خوشم نمیاد\", \"answer\": \"منفی\"},\n",
    "    {\"question\": \"غذای رستوران افتضاح بود\", \"answer\": \"منفی\"}\n",
    "]\n",
    "\n",
    "example_prompt = ChatPromptTemplate.from_messages([\n",
    "    (\"human\", \"{question}\"),\n",
    "    (\"ai\", \"{answer}\")\n",
    "])\n",
    "\n",
    "example_selector = LengthBasedExampleSelector(\n",
    "    examples=examples,\n",
    "    example_prompt=example_prompt,\n",
    "    max_length=25  # max length for examples (based on token length usually)\n",
    ")\n",
    "\n",
    "dynamic_prompt = FewShotChatMessagePromptTemplate(\n",
    "    example_selector=example_selector,\n",
    "    example_prompt=example_prompt,\n",
    "    input_variables=[\"question\"]\n",
    ")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
